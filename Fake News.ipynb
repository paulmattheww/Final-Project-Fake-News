{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from TextCleaner import *\n",
    "from helpers import binary_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{wang2018eann,\n",
    "  title={EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection},\n",
    "  author={Wang, Yaqing and Ma, Fenglong and Jin, Zhiwei and Yuan, Ye and Xun, Guangxu and Jha, Kishlay and Su, Lu and Gao, Jing},\n",
    "  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining},\n",
    "  pages={849--857},\n",
    "  year={2018},\n",
    "  organization={ACM}\n",
    "}\n",
    "\n",
    "https://arxiv.org/abs/1803.11175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  20800.000000  20800.000000\n",
       "mean   10399.500000      0.500625\n",
       "std     6004.587135      0.500012\n",
       "min        0.000000      0.000000\n",
       "25%     5199.750000      0.000000\n",
       "50%    10399.500000      1.000000\n",
       "75%    15599.250000      1.000000\n",
       "max    20799.000000      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word2vec(post, word_id_map, W):\n",
    "#     \"\"\"Cited from https://github.com/yaqingwang/EANN-KDD18\n",
    "#     Generates word2vec embeddings.\n",
    "    \n",
    "#     INPUTS:\n",
    "    \n",
    "#     RETURN:\n",
    "#     \"\"\"\n",
    "#     word_embedding = []\n",
    "#     mask = []\n",
    "#     for sentence in post:\n",
    "#         sen_embedding = []\n",
    "#         seq_len = len(sentence) - 1\n",
    "#         mask_seq = np.zeros(args.sequence_len, dtype=np.float32)\n",
    "#         mask_seq[:len(sentence)] = 1.0\n",
    "#         for i, word in enumerate(sentence):\n",
    "#             sen_embedding.append(word_id_map[word])\n",
    "\n",
    "#         while len(sen_embedding) < args.sequence_len:\n",
    "#             sen_embedding.append(0)\n",
    "#         word_embedding.append(copy.deepcopy(sen_embedding))\n",
    "#         mask.append(copy.deepcopy(mask_seq))\n",
    "#     return word_embedding, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "# # read in data and preprocess\n",
    "# train_df = pd.read_csv('c:/users/washburp/documents/kaggle/arthur/data/train_df.csv')\n",
    "\n",
    "# # drop missing descriptions\n",
    "# train_df.dropna(inplace=True, subset=['desc_of_operations'])\n",
    "\n",
    "# # derive length of description & filter long/short ones\n",
    "# train_df['len_description'] = train_df.desc_of_operations.apply(len)\n",
    "# reasonable_sized_texts = (train_df.len_description.astype(int) >= 1) | (train_df.len_description.astype(int) <= 200)\n",
    "# train_df = train_df.loc[reasonable_sized_texts]\n",
    "\n",
    "# # clean up text\n",
    "# from text_cleanup import TextCleaner\n",
    "\n",
    "# train_df['clean_desc'] = TextCleaner().transform(train_df.desc_of_operations.values)\n",
    "# train_df.head()\n",
    "\n",
    "# sentences = []\n",
    "# for description in train_df.clean_desc.tolist():\n",
    "#     sentences.append(description.split())\n",
    "    \n",
    "# sentences[:1]\n",
    "\n",
    "# import gensim\n",
    "\n",
    "# model = gensim.models.Word2Vec(iter=1, min_count=10, size=150, workers=4)\n",
    "# model.build_vocab(sentences)\n",
    "# model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# topn = 20\n",
    "\n",
    "# dat = model.most_similar(['salon'], topn=topn)\n",
    "# df = pd.DataFrame(dat, columns=['word', 'prob']).set_index('word')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "#help(DefaultTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(UnigramTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     House Dem Aide: We Didn’t Even See C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>title     FLYNN: Hillary Clinton, Big Woman on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>title                     Why the Truth Might ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     15 Civilians Killed In Single US Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     Iranian woman jailed for fictional u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                       combined_text  \n",
       "0  title     House Dem Aide: We Didn’t Even See C...  \n",
       "1  title     FLYNN: Hillary Clinton, Big Woman on...  \n",
       "2  title                     Why the Truth Might ...  \n",
       "3  title     15 Civilians Killed In Single US Air...  \n",
       "4  title     Iranian woman jailed for fictional u...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine columnt texts\n",
    "df['combined_text'] = df[['title', 'author', 'text']].apply(lambda x: ''.join(str(x)), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGING URLS to TLDS...  0 seconds\n",
      "REMOVING PUNCTUATION AND DIGITS... 0 seconds\n",
      "PARSING TEXT WITH SPACY... "
     ]
    }
   ],
   "source": [
    "# combine columnt texts\n",
    "df['combined_text'] = TextCleaner(custom_stopwords=['title', 'author', 'text']).transform(df['combined_text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df['combined_text'].str.split().astype(str).tolist()\n",
    "txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tag import UnigramTagger, DefaultTagger\n",
    "# from nltk.corpus import treebank\n",
    "# tagger = DefaultTagger('NN')\n",
    "# #tagger.tag(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def fetch_universal_sentence_embeddings(messages, verbose=0):\n",
    "    \"\"\"Fetches universal sentence embeddings from Google's\n",
    "    research paper https://arxiv.org/pdf/1803.11175.pdf.\n",
    "    \n",
    "    INPUTS:\n",
    "    RETURNS:\n",
    "    \"\"\"\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed = hub.Module(module_url)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(messages))\n",
    "        embeddings = list()\n",
    "        for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "            if verbose:\n",
    "                print(\"Message: {}\".format(messages[i]))\n",
    "                print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "                message_embedding_snippet = \", \".join(\n",
    "                    (str(x) for x in message_embedding[:3]))\n",
    "                print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "            embeddings.append(message_embedding)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = fetch_universal_sentence_embeddings(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = embeddings, df.label.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def binary_confusion_matrix(y, y_hat, as_pct=False, verbose=True):\n",
    "    cm = pd.DataFrame(confusion_matrix(y, y_hat),\n",
    "                      columns=['(+) actual', '(-) actual'],\n",
    "                      index=['(+) predicted', '(-) predicted'])\n",
    "    if as_pct:\n",
    "        cm = cm / cm.sum().sum()\n",
    "\n",
    "    P = cm['(+) actual'].sum()\n",
    "    N = cm['(-) actual'].sum()\n",
    "    total = P + N\n",
    "    TP = cm.loc['(+) predicted', '(+) actual']\n",
    "    FP = cm.loc['(+) predicted', '(-) actual']\n",
    "    TN = cm.loc['(-) predicted', '(-) actual']\n",
    "    FN = cm.loc['(-) predicted', '(+) actual']\n",
    "    TPR = TP / (TP + FN)          # recall/sensitivity\n",
    "    TNR = TN / (TN + FP)   # specificity\n",
    "    FPR = FP / (FP + TN)   # fall-out\n",
    "    FNR = FN / (FN + TP)   # miss rate\n",
    "    PPV = TP / (TP + FP)   # precision\n",
    "    NPV = TN / (TN + FN)   # neg predictive value\n",
    "\n",
    "    if verbose:\n",
    "        print('''\n",
    "        Condition Positive:                        %i\n",
    "        Condition Negative:                        %i\n",
    "        Total Observations:                        %i\n",
    "\n",
    "        True Positive:                             %i\n",
    "        True Negative:                             %i\n",
    "        False Positive:                            %i\n",
    "        False Negative                             %i\n",
    "\n",
    "        True Positive Rate (recall):               %.2f%%\n",
    "        True Negative Rate (specificity):          %.2f%%\n",
    "        False Positive Rate (fall-out):            %.2f%%\n",
    "        False Negative Rate (miss rate):           %.2f%%\n",
    "\n",
    "        Positive Predictive Value (precision):     %.2f%%\n",
    "        Negative Predictive Value:                 %.2f%%\n",
    "        ''' %(P, N, total,\n",
    "             TP, TN, FP, FN,\n",
    "             TPR*100, TNR*100, FPR*100, FNR*100,\n",
    "             PPV*100, NPV*100))\n",
    "\n",
    "    metrics = {'P': P, 'N': N, 'total': total,\n",
    "              'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN,\n",
    "              'TPR': TPR, 'TNR': TNR, 'FPR': FPR, 'FNR': FNR, 'PPV': PPV, 'NPV': NPV}\n",
    "\n",
    "    return cm, metrics\n",
    "\n",
    "\n",
    "yhat_val = pipeline.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, yhat_val)\n",
    "yhat_train = pipeline.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, yhat_train) \n",
    "\n",
    "print(f'''\n",
    "Training Accuracy: {round(train_acc, 4)}\n",
    "Validation Accuracy: {round(val_acc, 4)}\n",
    "''')\n",
    "\n",
    "_, __ = binary_confusion_matrix(y_val, yhat_val)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(code, n_code, phase_train):\n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        with variable_scope(\"hidden_1\"):\n",
    "            hidden_1 = layer(code, [n_code, n_decoder_hidden_1], \n",
    "                            [n_decoder_hidden_1],  phase_train)\n",
    "            \n",
    "        with tf.variable_scope(\"hidden_2\"):\n",
    "            hidden_2 = layer(hidden_1, [n_decoder_hidden_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
