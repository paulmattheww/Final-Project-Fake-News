{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from TextCleaner import TextCleaner\n",
    "from helpers import binary_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas_profiling as pr\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{wang2018eann,\n",
    "  title={EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection},\n",
    "  author={Wang, Yaqing and Ma, Fenglong and Jin, Zhiwei and Yuan, Ye and Xun, Guangxu and Jha, Kishlay and Su, Lu and Gao, Jing},\n",
    "  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining},\n",
    "  pages={849--857},\n",
    "  year={2018},\n",
    "  organization={ACM}\n",
    "}\n",
    "\n",
    "https://arxiv.org/abs/1803.11175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df = df.loc[(~df.text.isnull()) | (~df.title.isnull())]\n",
    "df.fillna('MISSING', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<meta charset=\"UTF-8\">\n",
       "\n",
       "<style>\n",
       "\n",
       "        .variablerow {\n",
       "            border: 1px solid #e1e1e8;\n",
       "            border-top: hidden;\n",
       "            padding-top: 2em;\n",
       "            padding-bottom: 2em;\n",
       "            padding-left: 1em;\n",
       "            padding-right: 1em;\n",
       "        }\n",
       "\n",
       "        .headerrow {\n",
       "            border: 1px solid #e1e1e8;\n",
       "            background-color: #f5f5f5;\n",
       "            padding: 2em;\n",
       "        }\n",
       "        .namecol {\n",
       "            margin-top: -1em;\n",
       "            overflow-x: auto;\n",
       "        }\n",
       "\n",
       "        .dl-horizontal dt {\n",
       "            text-align: left;\n",
       "            padding-right: 1em;\n",
       "            white-space: normal;\n",
       "        }\n",
       "\n",
       "        .dl-horizontal dd {\n",
       "            margin-left: 0;\n",
       "        }\n",
       "\n",
       "        .ignore {\n",
       "            opacity: 0.4;\n",
       "        }\n",
       "\n",
       "        .container.pandas-profiling {\n",
       "            max-width:975px;\n",
       "        }\n",
       "\n",
       "        .col-md-12 {\n",
       "            padding-left: 2em;\n",
       "        }\n",
       "\n",
       "        .indent {\n",
       "            margin-left: 1em;\n",
       "        }\n",
       "\n",
       "        .center-img {\n",
       "            margin-left: auto !important;\n",
       "            margin-right: auto !important;\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        /* Table example_values */\n",
       "            table.example_values {\n",
       "                border: 0;\n",
       "            }\n",
       "\n",
       "            .example_values th {\n",
       "                border: 0;\n",
       "                padding: 0 ;\n",
       "                color: #555;\n",
       "                font-weight: 600;\n",
       "            }\n",
       "\n",
       "            .example_values tr, .example_values td{\n",
       "                border: 0;\n",
       "                padding: 0;\n",
       "                color: #555;\n",
       "            }\n",
       "\n",
       "        /* STATS */\n",
       "            table.stats {\n",
       "                border: 0;\n",
       "            }\n",
       "\n",
       "            .stats th {\n",
       "                border: 0;\n",
       "                padding: 0 2em 0 0;\n",
       "                color: #555;\n",
       "                font-weight: 600;\n",
       "            }\n",
       "\n",
       "            .stats tr {\n",
       "                border: 0;\n",
       "            }\n",
       "\n",
       "            .stats td{\n",
       "                color: #555;\n",
       "                padding: 1px;\n",
       "                border: 0;\n",
       "            }\n",
       "\n",
       "\n",
       "        /* Sample table */\n",
       "            table.sample {\n",
       "                border: 0;\n",
       "                margin-bottom: 2em;\n",
       "                margin-left:1em;\n",
       "            }\n",
       "            .sample tr {\n",
       "                border:0;\n",
       "            }\n",
       "            .sample td, .sample th{\n",
       "                padding: 0.5em;\n",
       "                white-space: nowrap;\n",
       "                border: none;\n",
       "\n",
       "            }\n",
       "\n",
       "            .sample thead {\n",
       "                border-top: 0;\n",
       "                border-bottom: 2px solid #ddd;\n",
       "            }\n",
       "\n",
       "            .sample td {\n",
       "                width:100%;\n",
       "            }\n",
       "\n",
       "\n",
       "        /* There is no good solution available to make the divs equal height and then center ... */\n",
       "            .histogram {\n",
       "                margin-top: 3em;\n",
       "            }\n",
       "        /* Freq table */\n",
       "\n",
       "            table.freq {\n",
       "                margin-bottom: 2em;\n",
       "                border: 0;\n",
       "            }\n",
       "            table.freq th, table.freq tr, table.freq td {\n",
       "                border: 0;\n",
       "                padding: 0;\n",
       "            }\n",
       "\n",
       "            .freq thead {\n",
       "                font-weight: 600;\n",
       "                white-space: nowrap;\n",
       "                overflow: hidden;\n",
       "                text-overflow: ellipsis;\n",
       "\n",
       "            }\n",
       "\n",
       "            td.fillremaining{\n",
       "                width:auto;\n",
       "                max-width: none;\n",
       "            }\n",
       "\n",
       "            td.number, th.number {\n",
       "                text-align:right ;\n",
       "            }\n",
       "\n",
       "        /* Freq mini */\n",
       "            .freq.mini td{\n",
       "                width: 50%;\n",
       "                padding: 1px;\n",
       "                font-size: 12px;\n",
       "\n",
       "            }\n",
       "            table.freq.mini {\n",
       "                 width:100%;\n",
       "            }\n",
       "            .freq.mini th {\n",
       "                overflow: hidden;\n",
       "                text-overflow: ellipsis;\n",
       "                white-space: nowrap;\n",
       "                max-width: 5em;\n",
       "                font-weight: 400;\n",
       "                text-align:right;\n",
       "                padding-right: 0.5em;\n",
       "            }\n",
       "\n",
       "            .missing {\n",
       "                color: #a94442;\n",
       "            }\n",
       "            .alert, .alert > th, .alert > td {\n",
       "                color: #a94442;\n",
       "            }\n",
       "\n",
       "\n",
       "        /* Bars in tables */\n",
       "            .freq .bar{\n",
       "                float: left;\n",
       "                width: 0;\n",
       "                height: 100%;\n",
       "                line-height: 20px;\n",
       "                color: #fff;\n",
       "                text-align: center;\n",
       "                background-color: #337ab7;\n",
       "                border-radius: 3px;\n",
       "                margin-right: 4px;\n",
       "            }\n",
       "            .other .bar {\n",
       "                background-color: #999;\n",
       "            }\n",
       "            .missing .bar{\n",
       "                background-color: #a94442;\n",
       "            }\n",
       "            .tooltip-inner {\n",
       "                width: 100%;\n",
       "                white-space: nowrap;\n",
       "                text-align:left;\n",
       "            }\n",
       "\n",
       "            .extrapadding{\n",
       "                padding: 2em;\n",
       "            }\n",
       "\n",
       "            .pp-anchor{\n",
       "\n",
       "            }\n",
       "\n",
       "</style>\n",
       "\n",
       "<div class=\"container pandas-profiling\">\n",
       "    <div class=\"row headerrow highlight\">\n",
       "        <h1>Overview</h1>\n",
       "    </div>\n",
       "    <div class=\"row variablerow\">\n",
       "    <div class=\"col-md-6 namecol\">\n",
       "        <p class=\"h4\">Dataset info</p>\n",
       "        <table class=\"stats\" style=\"margin-left: 1em;\">\n",
       "            <tbody>\n",
       "            <tr>\n",
       "                <th>Number of variables</th>\n",
       "                <td>5 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Number of observations</th>\n",
       "                <td>20800 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Total Missing (%)</th>\n",
       "                <td>0.0% </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Total size in memory</th>\n",
       "                <td>975.0 KiB </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Average record size in memory</th>\n",
       "                <td>48.0 B </td>\n",
       "            </tr>\n",
       "            </tbody>\n",
       "        </table>\n",
       "    </div>\n",
       "    <div class=\"col-md-6 namecol\">\n",
       "        <p class=\"h4\">Variables types</p>\n",
       "        <table class=\"stats\" style=\"margin-left: 1em;\">\n",
       "            <tbody>\n",
       "            <tr>\n",
       "                <th>Numeric</th>\n",
       "                <td>1 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Categorical</th>\n",
       "                <td>3 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Boolean</th>\n",
       "                <td>1 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Date</th>\n",
       "                <td>0 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Text (Unique)</th>\n",
       "                <td>0 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Rejected</th>\n",
       "                <td>0 </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Unsupported</th>\n",
       "                <td>0 </td>\n",
       "            </tr>\n",
       "            </tbody>\n",
       "        </table>\n",
       "    </div>\n",
       "    <div class=\"col-md-12\" style=\"padding-left: 1em;\">\n",
       "        \n",
       "        <p class=\"h4\">Warnings</p>\n",
       "        <ul class=\"list-unstyled\"><li><a href=\"#pp_var_author\"><code>author</code></a> has a high cardinality: 4202 distinct values  <span class=\"label label-warning\">Warning</span></li><li><a href=\"#pp_var_text\"><code>text</code></a> has a high cardinality: 20387 distinct values  <span class=\"label label-warning\">Warning</span></li><li><a href=\"#pp_var_title\"><code>title</code></a> has a high cardinality: 19804 distinct values  <span class=\"label label-warning\">Warning</span></li> </ul>\n",
       "    </div>\n",
       "</div>\n",
       "    <div class=\"row headerrow highlight\">\n",
       "        <h1>Variables</h1>\n",
       "    </div>\n",
       "    <div class=\"row variablerow\">\n",
       "    <div class=\"col-md-3 namecol\">\n",
       "        <p class=\"h4 pp-anchor\" id=\"pp_var_author\">author<br/>\n",
       "            <small>Categorical</small>\n",
       "        </p>\n",
       "    </div><div class=\"col-md-3\">\n",
       "    <table class=\"stats \">\n",
       "        <tr class=\"alert\">\n",
       "            <th>Distinct count</th>\n",
       "            <td>4202</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Unique (%)</th>\n",
       "            <td>20.2%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (%)</th>\n",
       "            <td>0.0%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (n)</th>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-6 collapse in\" id=\"minifreqtable6019699777323553017\">\n",
       "    <table class=\"mini freq\">\n",
       "        <tr class=\"\">\n",
       "    <th>MISSING</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:11%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 9.4%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        1957\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>Pam Key</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:2%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 1.2%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        243\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>admin</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:2%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.9%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        193\n",
       "    </td>\n",
       "</tr><tr class=\"other\">\n",
       "    <th>Other values (4199)</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:100%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 88.5%\">\n",
       "            18407\n",
       "        </div>\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-12 text-right\">\n",
       "    <a role=\"button\" data-toggle=\"collapse\" data-target=\"#freqtable6019699777323553017, #minifreqtable6019699777323553017\"\n",
       "       aria-expanded=\"true\" aria-controls=\"collapseExample\">\n",
       "        Toggle details\n",
       "    </a>\n",
       "</div>\n",
       "<div class=\"col-md-12 extrapadding collapse\" id=\"freqtable6019699777323553017\">\n",
       "    \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">MISSING</td>\n",
       "        <td class=\"number\">1957</td>\n",
       "        <td class=\"number\">9.4%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:12%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Pam Key</td>\n",
       "        <td class=\"number\">243</td>\n",
       "        <td class=\"number\">1.2%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:2%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">admin</td>\n",
       "        <td class=\"number\">193</td>\n",
       "        <td class=\"number\">0.9%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:2%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Jerome Hudson</td>\n",
       "        <td class=\"number\">166</td>\n",
       "        <td class=\"number\">0.8%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Charlie Spiering</td>\n",
       "        <td class=\"number\">141</td>\n",
       "        <td class=\"number\">0.7%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">John Hayward</td>\n",
       "        <td class=\"number\">140</td>\n",
       "        <td class=\"number\">0.7%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Katherine Rodriguez</td>\n",
       "        <td class=\"number\">124</td>\n",
       "        <td class=\"number\">0.6%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Warner Todd Huston</td>\n",
       "        <td class=\"number\">122</td>\n",
       "        <td class=\"number\">0.6%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Ian Hanchett</td>\n",
       "        <td class=\"number\">119</td>\n",
       "        <td class=\"number\">0.6%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Breitbart News</td>\n",
       "        <td class=\"number\">118</td>\n",
       "        <td class=\"number\">0.6%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"other\">\n",
       "        <td class=\"fillremaining\">Other values (4192)</td>\n",
       "        <td class=\"number\">17477</td>\n",
       "        <td class=\"number\">84.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>\n",
       "</div><div class=\"row variablerow\">\n",
       "    <div class=\"col-md-3 namecol\">\n",
       "        <p class=\"h4 pp-anchor\" id=\"pp_var_id\">id<br/>\n",
       "            <small>Numeric</small>\n",
       "        </p>\n",
       "    </div><div class=\"col-md-6\">\n",
       "    <div class=\"row\">\n",
       "        <div class=\"col-sm-6\">\n",
       "            <table class=\"stats \">\n",
       "                <tr>\n",
       "                    <th>Distinct count</th>\n",
       "                    <td>20800</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <th>Unique (%)</th>\n",
       "                    <td>100.0%</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Missing (%)</th>\n",
       "                    <td>0.0%</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Missing (n)</th>\n",
       "                    <td>0</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Infinite (%)</th>\n",
       "                    <td>0.0%</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Infinite (n)</th>\n",
       "                    <td>0</td>\n",
       "                </tr>\n",
       "            </table>\n",
       "\n",
       "        </div>\n",
       "        <div class=\"col-sm-6\">\n",
       "            <table class=\"stats \">\n",
       "\n",
       "                <tr>\n",
       "                    <th>Mean</th>\n",
       "                    <td>10400</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <th>Minimum</th>\n",
       "                    <td>0</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <th>Maximum</th>\n",
       "                    <td>20799</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Zeros (%)</th>\n",
       "                    <td>0.0%</td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n",
       "<div class=\"col-md-3 collapse in\" id=\"minihistogram7836336778611965321\">\n",
       "    <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAABLCAYAAAA1fMjoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD%2BnaQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAPpJREFUeJzt1TENQgEQREE%2BQRIi8ESNJ0Tg6agh5LVHMaNgm5c9ZmZOwE/n7QHwzy7bA75d78/tCSx6PW7bEz54EAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBIBAIAoEgEAgCgSAQCAKBcMzMbI%2BAf%2BVBIAgEgkAgCASCQCAIBIJAIAgEgkAgCASCQCAIBIJAIAgEgkAgCASCQCAIBIJAIAgEgkAgCASCQCAIBIJAILwB%2BwILj9G2cTUAAAAASUVORK5CYII%3D\">\n",
       "\n",
       "</div>\n",
       "<div class=\"col-md-12 text-right\">\n",
       "    <a role=\"button\" data-toggle=\"collapse\" data-target=\"#descriptives7836336778611965321,#minihistogram7836336778611965321\"\n",
       "       aria-expanded=\"false\" aria-controls=\"collapseExample\">\n",
       "        Toggle details\n",
       "    </a>\n",
       "</div>\n",
       "<div class=\"row collapse col-md-12\" id=\"descriptives7836336778611965321\">\n",
       "    <ul class=\"nav nav-tabs\" role=\"tablist\">\n",
       "        <li role=\"presentation\" class=\"active\"><a href=\"#quantiles7836336778611965321\"\n",
       "                                                  aria-controls=\"quantiles7836336778611965321\" role=\"tab\"\n",
       "                                                  data-toggle=\"tab\">Statistics</a></li>\n",
       "        <li role=\"presentation\"><a href=\"#histogram7836336778611965321\" aria-controls=\"histogram7836336778611965321\"\n",
       "                                   role=\"tab\" data-toggle=\"tab\">Histogram</a></li>\n",
       "        <li role=\"presentation\"><a href=\"#common7836336778611965321\" aria-controls=\"common7836336778611965321\"\n",
       "                                   role=\"tab\" data-toggle=\"tab\">Common Values</a></li>\n",
       "        <li role=\"presentation\"><a href=\"#extreme7836336778611965321\" aria-controls=\"extreme7836336778611965321\"\n",
       "                                   role=\"tab\" data-toggle=\"tab\">Extreme Values</a></li>\n",
       "\n",
       "    </ul>\n",
       "\n",
       "    <div class=\"tab-content\">\n",
       "        <div role=\"tabpanel\" class=\"tab-pane active row\" id=\"quantiles7836336778611965321\">\n",
       "            <div class=\"col-md-4 col-md-offset-1\">\n",
       "                <p class=\"h4\">Quantile statistics</p>\n",
       "                <table class=\"stats indent\">\n",
       "                    <tr>\n",
       "                        <th>Minimum</th>\n",
       "                        <td>0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>5-th percentile</th>\n",
       "                        <td>1040</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Q1</th>\n",
       "                        <td>5199.8</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Median</th>\n",
       "                        <td>10400</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Q3</th>\n",
       "                        <td>15599</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>95-th percentile</th>\n",
       "                        <td>19759</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Maximum</th>\n",
       "                        <td>20799</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Range</th>\n",
       "                        <td>20799</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Interquartile range</th>\n",
       "                        <td>10400</td>\n",
       "                    </tr>\n",
       "                </table>\n",
       "            </div>\n",
       "            <div class=\"col-md-4 col-md-offset-2\">\n",
       "                <p class=\"h4\">Descriptive statistics</p>\n",
       "                <table class=\"stats indent\">\n",
       "                    <tr>\n",
       "                        <th>Standard deviation</th>\n",
       "                        <td>6004.6</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Coef of variation</th>\n",
       "                        <td>0.57739</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Kurtosis</th>\n",
       "                        <td>-1.2</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Mean</th>\n",
       "                        <td>10400</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>MAD</th>\n",
       "                        <td>5200</td>\n",
       "                    </tr>\n",
       "                    <tr class=\"\">\n",
       "                        <th>Skewness</th>\n",
       "                        <td>0</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Sum</th>\n",
       "                        <td>216309600</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Variance</th>\n",
       "                        <td>36055000</td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th>Memory size</th>\n",
       "                        <td>965.0 KiB</td>\n",
       "                    </tr>\n",
       "                </table>\n",
       "            </div>\n",
       "        </div>\n",
       "        <div role=\"tabpanel\" class=\"tab-pane col-md-8 col-md-offset-2\" id=\"histogram7836336778611965321\">\n",
       "            <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAYAAAByNR6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD%2BnaQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt4VNWh/vE3yUQyCUiCIXh59ICQ0AJiIphwM0fASBG5SIJjRYoX6KlEIpRLpYAgVykRETlQRSyF8BwjCFU0ipeDSDkQkEaL1GACRPBEyYQEmitJyP794S9zHIMlmsUMM3w/zzPP46y199prZbnZ77PXnpkAy7IsAQAAwJhAb3cAAADA3xCwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhNm934HLhdJYZbzMwMEBt2oSppKRC9fWW8fbRfMzRpY85uvQxR5e2S31%2B2rZt5ZXjcgfLhwUGBiggIECBgQHe7gp%2BAHN06WOOLn3M0aWN%2BTk/AhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGGbzdgfQPD1nvuPtLgAA0GxvT%2Brr7S4YxR0sAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYJjPBqzc3Fw99NBDio%2BPV9%2B%2BfTV9%2BnSVlJRIkj799FONGjVKcXFxGjBggDZt2uS279atW5WUlKTY2FiNHDlSOTk5rrpz585pyZIl6tOnj%2BLi4vToo4%2BqqKjIo2MDAAC%2BzScDVnV1tcaNG6e4uDj99a9/1ZtvvqnTp0/r97//vc6cOaNf//rXGjFihPbv36%2BFCxdq8eLF%2Bvvf/y5Jys7O1vz58/X0009r//79GjZsmB599FFVVVVJklavXq3du3frtdde065duxQSEqJZs2Z5c7gAAMDH%2BGTAKiws1M9%2B9jOlpqbqiiuuUEREhBwOh/bv3693331X4eHhGj16tGw2m3r37q2hQ4dq48aNkqRNmzZpyJAh6tGjh4KDg/Xggw8qIiJCWVlZrvrx48frmmuuUcuWLTVz5kx99NFHOnHihDeHDAAAfIhPBqwbb7xRL730koKCglxl27dvV9euXZWXl6eYmBi37Tt16qTc3FxJUn5%2B/g/Wl5WV6ZtvvnGrj4yMVOvWrXX48OGLOCIAAOBPfP6ncizL0vLly7Vjxw5lZGRo/fr1stvtbtuEhISosrJSklRRUfGD9RUVFZKk0NDQRvUNdU1RVFQkp9PpVmazhSoqKqrJbTRFUJBP5mMAABqx2fzrmubTAau8vFwzZszQoUOHlJGRoc6dO8tut6usrMxtu%2BrqaoWFhUmS7Ha7qqurG9VHRES4glfD81jn278pMjMztXLlSrey1NRUpaWlNbkNAAAuJxERTb/O%2BgKfDVjHjx/X%2BPHjde2112rz5s1q06aNJCkmJka7d%2B922zY/P1/R0dGSpOjoaOXl5TWqT0xMVOvWrdWuXTu3ZUSn06nTp083Wlb8VxwOhwYMGOBWZrOFqrS06XfBmoI7WAAAf2H6GtnAW8HNJ6/QZ86c0dixY3XLLbdo7dq1rnAlSUlJSSouLta6detUW1urvXv3atu2bUpOTpYkpaSkaNu2bdq7d69qa2u1bt06nTp1SklJSZKkkSNHavXq1Tpx4oTKy8u1aNEixcfH64Ybbmhy/6KiotS1a1e3V5s2kaqrqzf6Oneu3uwfFgAALzF9jWx4eYtP3sHasmWLCgsL9fbbb%2Budd95xq8vJydHLL7%2BshQsXasWKFWrTpo1mzZqlXr16SZJ69%2B6tOXPmaO7cuTp58qQ6deqkNWvWKDw8XNK3S3l1dXUaPXq0KioqlJCQoOXLl3t8jAAAwHcFWJZlebsTlwOns%2BzCG/1INlugktJ3GW8XAABPe3tS34vSbtu2rS5Kuxfik0uEAAAAlzICFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMNs3u5Ac5WUlMjhcGjBggVKSEjQk08%2BqW3btrltU11drT59%2Bmjt2rWqr69Xjx49ZFmWAgICXNvs3r1boaGhOnXqlGbPnq19%2B/YpKChIw4YN0%2B9%2B9zvZbD7/pwIAAB7i03ewDhw4IIfDoePHj7vK5s2bp5ycHNfr%2Beef15VXXqknnnhCkpSfn6/a2lrt27fPbbvQ0FBJ0qRJkxQaGqpdu3Zp8%2BbN2rNnj9atW%2BeN4QEAAB/lswFr69atmjp1qiZPnvyD25SUlGjq1KmaOXOmoqOjJUkHDx5U586ddcUVVzTa/ssvv9S%2Bffs0bdo02e12XX/99ZowYYI2btx40cYBAAD8j88GrH79%2Bum9997TXXfd9YPbpKenq1u3bho2bJir7ODBgzp79qySk5PVq1cvjR49Wn/7298kSXl5eQoPD1e7du1c23fs2FGFhYX65z//efEGAwAA/IrPPljUtm3bf1l/4sQJvfHGG9q0aZNbeUhIiLp3767HH39crVu31saNG/XII4/ojTfeUEVFhex2u9v2De8rKyt15ZVXNqlvRUVFcjqdbmU2W6iioqKatH9TBQX5bD4GAMCNzeZf1zSfDVgX8tprrykuLk4///nP3cobnsVq8Mgjj2jLli3auXOn2rVrp6qqKrf6hvdhYWFNPnZmZqZWrlzpVpaamqq0tLQfMwQAAC4bERFNv876Ar8NWO%2B%2B%2B64efvjhRuXPPvusBg0apC5durjKampq1KJFC0VHR%2Bv06dMqLi5WZGSkJOnIkSO6%2Buqr1apVqyYf2%2BFwaMCAAW5lNluoSksrfuJozo87WAAAf2H6GtnAW8HNLwNWaWmpjhw5oltvvbVR3RdffKGPP/5Yy5cvV%2BvWrfXiiy%2BqvLxcSUlJCg8PV48ePbRo0SLNmzdPpaWlWrVqlVJSUn7U8aOiohotBzqdZaqrq2/WuAAA8Ff%2Bdo30y1sgX331lSS5PazeYPHixbrhhhs0fPhwJSQkaN%2B%2BffrTn/6k8PBwSdKKFStUV1engQMH6t5779Vtt92mCRMmeLT/AADAtwVYlmV5uxOXA6ezzHibNlugktJ3GW8XAABPe3tS34vSbtu2TX/ExyS/vIMFAADgTQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhvl8wCopKVFSUpKys7NdZXPmzFG3bt0UFxfnemVmZrrq16xZo8TERMXGxmrMmDE6evSoq66yslIzZsxQQkKCevTooenTp6uiosKjYwIAAL7NpwPWgQMH5HA4dPz4cbfygwcPav78%2BcrJyXG9HA6HJGnr1q3asGGD1q5dq%2BzsbHXt2lVpaWmyLEuSNH/%2BfH399dfavn273n33XX399ddKT0/3%2BNgAAIDv8tmAtXXrVk2dOlWTJ092K6%2BpqdEXX3yhbt26nXe/V199Vffff7%2Bio6PVokULTZkyRYWFhcrOzlZVVZW2bdumtLQ0hYeH66qrrtLUqVO1ZcsWVVVVeWJYAADAD9i83YGfql%2B/fho6dKhsNptbyMrNzVVdXZ1WrFihAwcOqFWrVkpOTta4ceMUGBio/Px8jR8/3rV9cHCw2rdvr9zcXIWHh6u2tlYxMTGu%2Bo4dO6q6uloFBQX6%2Bc9/3qS%2BFRUVyel0upXZbKGKiopq5qjdBQX5bD4GAMCNzeZf1zSfDVht27Y9b3lZWZni4%2BM1ZswYLVu2TJ9//rlSU1MVGBiocePGqaKiQna73W2fkJAQVVZWqry8XJIUGhrqqmvY9sc8h5WZmamVK1e6laWmpiotLa3JbQAAcDmJiAjzdheM8tmA9UP69u2rvn37ut53795dY8eOVVZWlsaNGye73a7q6mq3faqrqxUWFuYKVlVVVQoLC3P9tyS1bNmyyX1wOBwaMGCAW5nNFqrSUrMPy3MHCwDgL0xfIxt4K7j5XcB6//33VVxcrPvuu89VVlNTo5CQEElSdHS08vLy1L9/f0lSbW2tCgoKFBMTow4dOig4OFj5%2Bfm6%2BeabJUlHjhxxLSM2VVRUVKPlQKezTHV19c0cHQAA/snfrpF%2BdwvEsiwtXrxYe/bskWVZysnJ0fr1612fIkxOTlZGRoZyc3N19uxZPfPMM4qMjFTPnj1lt9s1ePBgpaenq6SkRCUlJUpPT9fdd9/tCmgAAAAX4nd3sJKSkjRjxgzNnTtXJ0%2BeVGRkpCZOnKjhw4dLklJSUlRWVqbU1FSVlJTopptu0gsvvKDg4GBJ336H1pIlSzR06FDV1tZq4MCBmj17tjeHBAAAfEyA1fAFULionM4y423abIFKSt9lvF0AADzt7Ul9L7zRT9C2bauL0u6F%2BN0SIQAAgLcRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMMzjAevcuXOePiQAAIBHeTxgJSYm6g9/%2BIPy8/M9fWgAAACP8HjAeuyxx/S3v/1Nd999t0aNGqVXXnlFZWVlnu4GAADARRNgWZbljQMXFBRo69atevPNN1VcXKw77rhDycnJ6tOnjze6c9E5neZDpM0WqKT0XcbbBQDA096e1PeitNu2bauL0u6FeC1gNaitrdWf/vQnrVq1SmfPntU111yjMWPG6Fe/%2BpWCgoK82TWjCFgAAPwwfwtYNq8cVdKnn36qv/zlL8rKylJNTY2SkpI0cuRInTx5Us8995wOHjyoZcuWeat7AAAAP5nHA9aqVav0%2Buuv68svv9RNN92kyZMn6%2B6771bLli1d2wQFBenJJ59sUnslJSVyOBxasGCBEhISJEnbt2/XqlWrdOLECYWHh2vkyJGaMGGCAgO/feRs8ODBKiwsdL2XpM2bN6tjx46qrKzU/Pnz9d///d%2Bqq6vTwIEDNWfOHIWFhRn8KwAAAH/m8YCVkZGhYcOGKSUlRZ06dTrvNh07dtTUqVMv2NaBAwf0xBNP6Pjx466yzz77TNOnT9fy5cv17//%2B7zp27JjGjx%2Bv0NBQPfzwwyovL9exY8f0wQcf6LrrrmvU5vz58/X1119r%2B/btOnfunCZNmqT09HTNmTPnpw8aAABcVjz%2BKcKPPvpIv/nNb2Sz/V%2B2y8rKUmlpqet9ly5dNHr06H/ZztatWzV16lRNnjzZrfx///d/dd9996l///4KDAxUx44dlZSUpP3790v6NoCFh4efN1xVVVVp27ZtSktLU3h4uK666ipNnTpVW7ZsUVVVVXOGDQAALiMeD1j/%2BMc/NGjQIGVmZrrKli5dqqFDh%2BqLL75ocjv9%2BvXTe%2B%2B9p7vuusutfNCgQZoxY4brfXV1tT788EN17dpVknTw4EHZ7XY98MADSkhI0MiRI7Vjxw5J0pdffqna2lrFxMS49u/YsaOqq6tVUFDwU4YLAAAuQx5fIvzDH/6gO%2B%2B80%2B3O0/vvv6/Zs2fr6aef1ssvv9ykdtq2bXvBbcrLy/X4448rJCREDz74oCQpICBAN910k37729/q2muv1TvvvKOJEycqIyNDdXV1kqTQ0FBXG3a7XZJUUVHR1CGqqKhITqfTrcxmC1VUVFST22iKoCB%2B6QgA4B9sNv%2B6pnk8YB06dEiLFy/WFVdc4SoLCgrSr3/9a40cOdLYcY4ePaq0tDRdddVVWr9%2Bvesh%2BnHjxrltN2zYML355pvavn27hg4dKunbpcKGh9oblga/%2BxD%2BhWRmZmrlypVuZampqUpLS/vJ4wEAwJ9FRPjXh8k8HrBatmyp48eP6/rrr3cr/%2BabbxQSEmLkGDt37tRvf/tb3XvvvZoyZYrb815r165Vly5d1Lt3b1dZTU2NWrRooQ4dOig4OFj5%2Bfm6%2BeabJUlHjhxRcHCw2rdv3%2BTjOxwODRgwwK3MZgtVaWnT74I1BXewAAD%2BwvQ1soG3gpvHA9agQYM0d%2B5cPfXUU%2BrevbsCAgJ08OBBzZs3T0lJSc1u/5NPPlFqaqrmzp2rlJSURvVff/21Nm3apDVr1uiaa67RX/7yF%2BXk5Oipp56S3W7X4MGDlZ6erueee06SlJ6errvvvvtHhb%2BoqKhGy4FOZ5nq6uqbNzgAAPyUv10jPR6wpkyZohMnTujhhx9WQECAqzwpKUnTp09vdvt//OMfVVdXp4ULF2rhwoWu8h49euill17S9OnTFRgYqPvvv19lZWXq1KmTXnzxRf3bv/2bJGnOnDlasmSJhg4dqtraWg0cOFCzZ89udr8AAMDlw2s/lXPs2DEdPnxYwcHB6tix449agvNF/FQOAAA/jJ/KMaRDhw7q0KGDtw4PAABw0Xg8YB07dkzz5s3TgQMHVFtb26j%2B888/93SXAAAAjPJ4wJo7d64KCws1depUtWrlndt2AAAAF5PHA1ZOTo7%2B/Oc/Ky4uztOHBgAA8AiPf5FSRESE60s8AQAA/JHHA9aYMWO0bNkylZWZ/1QdAADApcDjS4Q7d%2B7UJ598ooSEBF111VVuP5kjSR988IGnuwQAAGCUxwNWQkKCEhISPH1YAAAAj/F4wHrsscc8fUgAAACP8sqvBefm5mrGjBm67777dPLkSW3cuFHZ2dne6AoAAIBxHg9Yn332mUaNGqWvvvpKn332mWpqavT555/r4Ycf1o4dOzzdHQAAAOM8HrDS09P18MMPa8OGDQoODpYkLViwQL/61a%2B0cuVKT3cHAADAOK/cwRoxYkSj8l/%2B8pc6evSop7sDAABgnMcDVnBwsMrLyxuVFxYWym63e7o7AAAAxnk8YN1xxx165plnVFpa6io7cuSIFi5cqNtvv93T3QEAADDO4wHrd7/7naqrq9WnTx9VVVVp5MiRuvvuu2Wz2TR9%2BnRPdwcAAMA4j38PVsuWLfXKK69oz549%2Bsc//qH6%2BnrFxMTotttuU2CgV741AgAAwCiPB6wGvXv3Vu/evb11eAAAgIvG4wFrwIABCggI%2BMF6fosQAAD4Oo8HrHvuucctYNXW1urLL7/URx99pEmTJnm6OwAAAMZ5PGBNnDjxvOUZGRk6cOCAfvWrX3m4RwAAAGZdMk%2BV9%2B/fXzt37vR2NwAAAJrtkglY%2B/btU4sWLbzdDQAAgGbz%2BBLh95cALctSeXm5Dh8%2BzPIgAADwCx4PWNdee22jTxEGBwdr7NixGjp0qKe7AwAAYJzHA9bTTz/t6UMCAAB4lMcD1v79%2B5u87a233noRewIAAHBxeDxgPfjgg7Isy/Vq0LBs2FAWEBCgzz///ILtlZSUyOFwaMGCBUpISJAkffrpp1qwYIHy8/MVERGhRx99VKNGjXLts3XrVq1atUpOp1M33nijZs%2Berbi4OEnSuXPnlJ6ertdff11VVVXq1auXnnrqKUVFRRn7GwAAAP/m8U8RPv/887ruuuv0/PPP6%2BOPP9ann36q9evXq0OHDpo5c6Y%2B%2BOADffDBB3r//fcv2NaBAwfkcDh0/PhxV9mZM2f061//WiNGjND%2B/fu1cOFCLV68WH//%2B98lSdnZ2Zo/f76efvpp7d%2B/X8OGDdOjjz6qqqoqSdLq1au1e/duvfbaa9q1a5dCQkI0a9asi/PHAAAAfsnjAWvJkiWaM2eO7rjjDrVs2VItWrRQfHy85s2bp5dfflnXXXed6/WvbN26VVOnTtXkyZPdyt99912Fh4dr9OjRstls6t27t4YOHaqNGzdKkjZt2qQhQ4aoR48eCg4O1oMPPqiIiAhlZWW56sePH69rrrlGLVu21MyZM/XRRx/pxIkTF%2BcPAgAA/I7HlwiLiop0zTXXNCpv2bKlSktLm9xOv379NHToUNlsNreQlZeXp5iYGLdtO3XqpM2bN0uS8vPzlZyc3Kg%2BNzdXZWVl%2Buabb9z2j4yMVOvWrXX48GFdf/31TR6j0%2Bl0K7PZQo0vMwYFXTJfYwYAQLPYbP51TfN4wIqNjdWyZcu0ZMkStWzZUpJ0%2BvRpLV26VL17925yO23btj1veUVFhex2u1tZSEiIKisrL1hfUVEhSQoNDW1U31DXFJmZmVq5cqVbWWpqqtLS0prcBgAAl5OIiDBvd8EojwesWbNmaezYsUpMTFT79u0lSceOHVPbtm21fv36Zrdvt9tVVlbmVlZdXa2wsDBXfXV1daP6iIgIV/BqeB7rfPs3hcPh0IABA9zKbLZQlZY2PaQ1BXewAAD%2BwvQ1soG3gpvHA1bHjh2VlZWlbdu26ciRI5Kk%2B%2B%2B/X0OGDGl0Z%2BmniImJ0e7du93K8vPzFR0dLUmKjo5WXl5eo/rExES1bt1a7dq1U35%2BvmuZ0Ol06vTp042WHf%2BVqKioRsuBTmeZ6urqf8qQAADwe/52jfTKLZArr7xSo0aN0gMPPKAZM2Zo%2BPDhRsKVJCUlJam4uFjr1q1TbW2t9u7dq23btrmeu0pJSdG2bdu0d%2B9e1dbWat26dTp16pSSkpIkSSNHjtTq1at14sQJlZeXa9GiRYqPj9cNN9xgpH8AAMD/efwOlmVZeuaZZ7RhwwbV1tZq%2B/btevbZZ9WiRQvNmzdPwcHBzWo/IiJCL7/8shYuXKgVK1aoTZs2mjVrlnr16iVJ6t27t%2BbMmaO5c%2Bfq5MmT6tSpk9asWaPw8HBJ3z4rVVdXp9GjR6uiokIJCQlavnx5s8cNAAAuHwHWd7/t0wPWr1%2BvNWvWaPLkyZo3b562bdumgwcP6qmnntKoUaM0depUT3bHY5zOsgtv9CPZbIFKSt9lvF0AADzt7Ul9L0q7bdu2uijtXojHlwgzMzP15JNPauTIka5vb7/rrru0cOFCvfXWW57uDgAAgHEeD1hfffWVfv7znzcq79y5s4qLiz3dHQAAAOM8HrCuu%2B4618/WfNfOnTub/EWeAAAAlzKPP%2BT%2ByCOP6KmnntLJkydlWZb27NmjV155RRs2bNCMGTM83R0AAADjPB6wkpOTVVdXp9WrV6u6ulpPPvmkrrrqKk2ePFm//OUvPd0dAAAA4zwesN544w394he/kMPhUElJiSzL0lVXXeXpbgAAAFw0Hn8Ga8GCBa6H2du0aUO4AgAAfsfjAat9%2B/Y6fPiwpw8LAADgMR5fIoyOjtbUqVP10ksvqX379mrRooVb/eLFiz3dJQAAAKM8HrCOHz%2BuHj16SPr2h5QBAAD8jUcC1uLFi/X4448rNDRUGzZs8MQhAQAAvMYjz2CtX79eVVVVbmWPPPKIioqKPHF4AAAAj/JIwDrf70n/7W9/09mzZz1xeAAAAI/y%2BKcIAQAA/B0BCwAAwDCPBayAgABPHQoAAMCrPPY1DQsWLHD7zqva2lotXbpUYWFhbtvxPVgAAMDXeSRg3XrrrY2%2B8youLk6lpaUqLS31RBcAAAA8xiMBi%2B%2B%2BAgAAlxMecgcAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAY5rGfyvGkN954Q3PmzHErq62tlSR99tlnGjdunLKzs2Wz/d/wn3vuOSUmJurcuXNKT0/X66%2B/rqqqKvXq1UtPPfWUoqKiPDoGAADgu/wyYA0bNkzDhg1zvT958qSSk5M1bdo0Sd%2BGrLVr1yo%2BPr7RvqtXr9bu3bv12muvqVWrVpo9e7ZmzZqlF1980WP9BwAAvs3vlwgty9K0adN0%2B%2B23a/jw4Tpx4oTOnDmjLl26nHf7TZs2afz48brmmmvUsmVLzZw5Ux999JFOnDjh4Z4DAABf5Zd3sL7r9ddfV35%2BvlatWiVJOnjwoMLCwjR58mQdPHhQkZGRevDBB5WSkqKysjJ98803iomJce0fGRmp1q1b6/Dhw7r%2B%2BuubdMyioqJGP25ts4UaX2YMCvL7fAwAuEzYbP51TfPrgFVfX6/Vq1frN7/5jVq2bClJqqmpUWxsrCZPnqzo6GhlZ2dr4sSJCgsLU1xcnCQpNDTUrZ2QkBBVVFQ0%2BbiZmZlauXKlW1lqaqrS0tKaOSIAAPxTRESYt7tglF8HrOzsbBUVFSklJcVVNmLECI0YMcL1vl%2B/fhoxYoTefvtt9enTR5JUVVXl1k51dbXCwpo%2B8Q6HQwMGDHArs9lCVVra9JDWFNzBAgD4C9PXyAbeCm5%2BHbC2b9%2BupKQktztSmzdvVlhYmAYPHuwqq6mpUYsWLdS6dWu1a9dO%2Bfn5rmVCp9Op06dPuy0bXkhUVFSj5UCns0x1dfXNHBEAAP7J366Rfn0L5MCBA7r11lvdysrLyzV//nz94x//UH19vT788EO9%2BeabcjgckqSRI0dq9erVOnHihMrLy7Vo0SLFx8frhhtu8MYQAACAD/LrO1hfffVVoztJY8eOVWVlpR577DGdOnVK119/vZYsWaKePXtK%2BvZZqbq6Oo0ePVoVFRVKSEjQ8uXLvdF9AADgowIsy7K83YnLgdNZZrxNmy1QSem7jLcLAICnvT2p70Vpt23bVhel3Qvx6yVCAAAAbyBgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDDp%2BjvjAAAS20lEQVQCFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGOa3ASsrK0tdunRRXFyc6zVt2jRJ0s6dOzV06FDFxsZq8ODB2rFjh9u%2Ba9asUWJiomJjYzVmzBgdPXrUG0MAAAA%2Bym8D1sGDBzV8%2BHDl5OS4XkuXLlVBQYEmTpyoxx9/XB9//LEmTpyoSZMm6eTJk5KkrVu3asOGDVq7dq2ys7PVtWtXpaWlybIsL48IAAD4Cr8OWN26dWtUvnXrVvXs2VN33HGHbDab7rrrLt16663KzMyUJL366qu6//77FR0drRYtWmjKlCkqLCxUdna2p4cAAAB8lF8GrPr6eh06dEgffvih%2Bvfvr8TERM2ePVtnzpxRfn6%2BYmJi3Lbv1KmTcnNzJalRfXBwsNq3b%2B%2BqBwAAuBCbtztwMZSUlKhLly4aNGiQVqxYodLSUv3ud7/TtGnTVFNTI7vd7rZ9SEiIKisrJUkVFRX/sr4pioqK5HQ63cpstlBFRUX9xBGdX1CQX%2BZjAMBlyGbzr2uaXwasyMhIbdy40fXebrdr2rRpuvfee5WQkKDq6mq37aurqxUWFuba9l/VN0VmZqZWrlzpVpaamqq0tLQfOxQAAC4LERFNv876Ar8MWLm5uXrzzTc1ZcoUBQQESJJqamoUGBio7t276/PPP3fbPj8/3/W8VnR0tPLy8tS/f39JUm1trQoKChotK/4rDodDAwYMcCuz2UJVWlrRnGE1wh0sAIC/MH2NbOCt4OaXASs8PFwbN25U69at9dBDD6moqEhLly7VPffcoxEjRujPf/6zsrKydOedd%2Brdd9/Vvn37NHPmTElScnKynn/%2BeSUmJqpDhw569tlnFRkZqZ49ezb5%2BFFRUY2WA53OMtXV1RsdJwAA/sLfrpF%2BGbCuvvpqvfDCC1q2bJlWr16tFi1aaMiQIZo2bZpatGih//zP/1R6erpmzpyp6667Ts8//7w6dOggSUpJSVFZWZlSU1NVUlKim266SS%2B88IKCg4O9PCoAAOArAiy%2B4MkjnM4y423abIFKSt9lvF0AADzt7Ul9L0q7bdu2uijtXggP8QAAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGCY3was3NxcPfTQQ4qPj1ffvn01ffp0lZSUSJLmzJmjbt26KS4uzvXKzMx07btmzRolJiYqNjZWY8aM0dGjR701DAAA4IP8MmBVV1dr3LhxiouL01//%2Ble9%2BeabOn36tH7/%2B99Lkg4ePKj58%2BcrJyfH9XI4HJKkrVu3asOGDVq7dq2ys7PVtWtXpaWlybIsbw4JAAD4EL8MWIWFhfrZz36m1NRUXXHFFYqIiJDD4dD%2B/ftVU1OjL774Qt26dTvvvq%2B%2B%2Bqruv/9%2BRUdHq0WLFpoyZYoKCwuVnZ3t4VEAAABfZfN2By6GG2%2B8US%2B99JJb2fbt29W1a1fl5uaqrq5OK1as0IEDB9SqVSslJydr3LhxCgwMVH5%2BvsaPH%2B/aLzg4WO3bt1dubq569erVpOMXFRXJ6XS6ldlsoYqKimr%2B4L4jKMgv8zEA4DJks/nXNc0vA9Z3WZal5cuXa8eOHcrIyFBxcbHi4%2BM1ZswYLVu2TJ9//rlSU1MVGBiocePGqaKiQna73a2NkJAQVVZWNvmYmZmZWrlypVtZamqq0tLSjIwJAAB/ExER5u0uGOXXAau8vFwzZszQoUOHlJGRoc6dO6tz587q27eva5vu3btr7NixysrK0rhx42S321VdXe3WTnV1tcLCmj7xDodDAwYMcCuz2UJVWlrRvAF9D3ewAAD%2BwvQ1soG3gpvfBqzjx49r/Pjxuvbaa7V582a1adNGkvT%2B%2B%2B%2BruLhY9913n2vbmpoahYSESJKio6OVl5en/v37S5Jqa2tVUFCgmJiYJh87Kiqq0XKg01mmurr65g4LAAC/5G/XSL%2B8BXLmzBmNHTtWt9xyi9auXesKV9K3S4aLFy/Wnj17ZFmWcnJytH79etenCJOTk5WRkaHc3FydPXtWzzzzjCIjI9WzZ09vDQcAAPgYv7yDtWXLFhUWFurtt9/WO%2B%2B841aXk5OjGTNmaO7cuTp58qQiIyM1ceJEDR8%2BXJKUkpKisrIypaamqqSkRDfddJNeeOEFBQcHe2MoAADABwVYfMGTRzidZcbbtNkClZS%2By3i7AAB42tuT%2Bl54o5%2BgbdtWF6XdC/HLJUIAAABvImABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYBgBCwAAwDACFgAAgGEELAAAAMMIWAAAAIYRsAAAAAwjYAEAABhGwAIAADCMgAUAAGAYAQsAAMAwAhYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsA6j1OnTmnChAnq2bOnEhIStHDhQtXV1Xm7WwAAwEcQsM5j0qRJCg0N1a5du7R582bt2bNH69at83a3AACAjyBgfc%2BXX36pffv2adq0abLb7br%2B%2Bus1YcIEbdy40dtdAwAAPoKA9T15eXkKDw9Xu3btXGUdO3ZUYWGh/vnPf3qxZwAAwFfYvN2BS01FRYXsdrtbWcP7yspKXXnllRdso6ioSE6n063MZgtVVFSUuY5KCgoiHwMA/IPN5l/XNALW94SGhqqqqsqtrOF9WFhYk9rIzMzUypUr3coee%2BwxTZw40Uwn/7%2BioiKNvTpPDofDeHiDGUVFRcrMzGSOLmHM0aWPObq0MT/n519x0YDo6GidPn1axcXFrrIjR47o6quvVqtWrZrUhsPh0JYtW9xeDofDeF%2BdTqdWrlzZ6G4ZLh3M0aWPObr0MUeXNubn/LiD9T3t27dXjx49tGjRIs2bN0%2BlpaVatWqVUlJSmtxGVFQUKR4AgMsYd7DOY8WKFaqrq9PAgQN177336rbbbtOECRO83S0AAOAjuIN1HpGRkVqxYoW3uwEAAHxU0Ny5c%2Bd6uxP46cLCwhQfH9/kB/DheczRpY85uvQxR5c25qexAMuyLG93AgAAwJ/wDBYAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAKWjzp16pQmTJignj17KiEhQQsXLlRdXZ23u%2BXXsrKy1KVLF8XFxble06ZNkyTt3LlTQ4cOVWxsrAYPHqwdO3a47btmzRolJiYqNjZWY8aM0dGjR111lZWVmjFjhhISEtSjRw9Nnz5dFRUVHh2bryspKVFSUpKys7NdZZ9%2B%2BqlGjRqluLg4DRgwQJs2bXLbZ%2BvWrUpKSlJsbKxGjhypnJwcV925c%2Be0ZMkS9enTR3FxcXr00UdVVFTkquf8%2B/HON0dz5sxRt27d3M6pzMxMV31zzptjx45p7NixiouLU79%2B/fTHP/7RMwP1Mbm5uXrooYcUHx%2Bvvn37avr06SopKZHEOdRsFnzSAw88YE2ZMsWqrKy0jh8/bg0ZMsRas2aNt7vl155%2B%2BmnriSeeaFR%2B7Ngx66abbrLee%2B89q7a21nrrrbes7t27W998841lWZa1ZcsW67bbbrO%2B%2BOILq7q62lq8eLE1ZMgQq76%2B3rIsy3riiSessWPHWqWlpVZxcbH1wAMPWHPnzvXo2HzZxx9/bN1xxx1WTEyMtXfvXsuyLOv06dNWfHy8lZGRYdXW1lr/8z//Y8XFxVmffvqpZVmWtXfvXisuLs76%2BOOPrZqaGutPf/qTlZCQYFVWVlqWZVnPP/%2B8NXToUKuwsNAqKyuzJk2aZI0fP951TM6/H%2Bd8c2RZlnXPPfdYW7ZsOe8%2BzTlvampqrDvvvNNaunSpdfbsWevQoUNWv379rKysrIs/WB9SVVVl9e3b13ruueess2fPWiUlJdb48eOt//iP/%2BAcMoCA5YMKCgqsmJgY1wXcsizrrbfesm6//XYv9sr/jR492srIyGhUvmzZMuuhhx5yK3vkkUes5557zrIsy7rvvvus1atXu%2BpqamqsuLg4a8%2BePVZlZaXVtWtX68CBA676Tz75xOrevbvrHyr8sC1btli333679dZbb7ldvF999VXrzjvvdNv2ySeftKZPn25ZlmVNmTLFmjVrllv9L37xC2vz5s2WZVlWYmKi9cYbb7jqnE6n1blzZ%2Bv48eOcfz/SD83R2bNnra5du1pffPHFefdrznmze/duKzY21jp79qyr/oUXXrBGjx59kUbpm44cOWI98sgjVl1dnavs/ffft2655RbOIQNYIvRBeXl5Cg8PV7t27VxlHTt2VGFhof75z396sWf%2Bq76%2BXocOHdKHH36o/v37KzExUbNnz9aZM2eUn5%2BvmJgYt%2B07deqk3NxcSWpUHxwcrPbt2ys3N1dffvmlamtr3eo7duyo6upqFRQUeGRsvqxfv3567733dNddd7mV5%2BXl/ag5%2BW59WVmZvvnmG7f6yMhItW7dWocPH%2Bb8%2B5F%2BaI5yc3NVV1enFStWqE%2BfPho0aJBefPFF1dfXS2reeZOXl6cOHTroiiuucNV/d/7xrRtvvFEvvfSSgoKCXGXbt29X165dOYcMIGD5oIqKCtntdreyhveVlZXe6JLfKykpUZcuXTRo0CBlZWXplVdeUUFBgaZNm3be%2BQgJCXHNxb%2BqLy8vlySFhoa66hq25TmsC2vbtq1sNluj8ubMScPf/btz0lBfUVHB%2Bfcj/dAclZWVKT4%2BXmPGjNHOnTu1dOlSbdiwQS%2B//LKk5p03PzRHzM8PsyxLzz77rHbs2KGZM2dyDhnQ%2BP96XPJCQ0NVVVXlVtbwPiwszBtd8nuRkZHauHGj673dbte0adN07733KiEhQdXV1W7bV1dXu%2BbCbrf/YH3DP0BVVVWu7RvmsmXLlhdtPP7ObrerrKzMrawpcxIREeH6h/7751jD/pZlcf4Z0LdvX/Xt29f1vnv37ho7dqyysrI0bty4Zp03P/RvJPNzfuXl5ZoxY4YOHTqkjIwMde7cmXPIAO5g%2BaDo6GidPn1axcXFrrIjR47o6quvVqtWrbzYM/%2BVm5ur9PR0WZblKqupqVFgYKC6d%2B%2BuvLw8t%2B3z8/MVHR0t6dv5%2Bm59bW2tCgoKFBMTow4dOig4OFj5%2Bfmu%2BiNHjriWQ/DTxMTE/Kg5%2BW5969at1a5dO7c5cTqdOn36tGJiYjj/DHn//ff1yiuvuJXV1NQoJCREUvPOm%2BjoaBUUFLh9Ku2784//c/z4cSUnJ6u8vFybN29W586dJXEOmUDA8kHt27dXjx49tGjRIpWXl%2BvEiRNatWqVUlJSvN01vxUeHq6NGzfqpZdeUl1dnQoLC7V06VLdc889GjFihPbt26esrCzV1dUpKytL%2B/bt0/DhwyVJycnJysjIUG5urs6ePatnnnlGkZGR6tmzp%2Bx2uwYPHqz09HSVlJSopKRE6enpuvvuu10XGvx4SUlJKi4u1rp161RbW6u9e/dq27ZtSk5OliSlpKRo27Zt2rt3r2pra7Vu3TqdOnVKSUlJkqSRI0dq9erVOnHihMrLy7Vo0SLFx8frhhtu4PwzxLIsLV68WHv27JFlWcrJydH69evlcDgkNe%2B8SUhIUEREhJ555hmdPXtWubm52rBhA3P0PWfOnNHYsWN1yy23aO3atWrTpo2rjnPIAG8%2BYY%2Bfzul0WhMnTrTi4%2BOtXr16WU8//bTbJ0FgXnZ2tuVwOKy4uDirV69e1vz5863q6mrLsizro48%2BsoYNG2bFxsZaQ4YMsT788EPXfvX19dbatWutAQMGWLGxsdaYMWOso0ePuurLysqsWbNmWX369LFuvfVW64knnrAqKio8Pj5f9/2vAPj73//umq%2BBAwdar732mtv2f/nLX6xBgwZZsbGxVkpKivXJJ5%2B46mpqaqylS5dat912m3XLLbdYjz76qFVcXOyq5/z7ab4/R//1X/9l3XnnndbNN99sDRw40O1Tus09bwoKCqyHH37Y6tGjh3XbbbdZL7zwgmcG6UNefvllKyYmxrr55put2NhYt5dlcQ41V4BlfWfNAwAAAM3GEiEAAIBhBCwAAADDCFgAAACGEbAAAAAMI2ABAAAYRsACAAAwjIAFAABgGAELAADAMAIWAACAYQQsAAAAwwhYAAAAhhGwAAAADCNgAQAAGEbAAgAAMIyABQAAYNj/A4spZ9tIkfMUAAAAAElFTkSuQmCC\"/>\n",
       "        </div>\n",
       "        <div role=\"tabpanel\" class=\"tab-pane col-md-12\" id=\"common7836336778611965321\">\n",
       "            \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">2047</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">677</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">4743</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">19084</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">17037</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">10896</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">8849</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">14994</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">12947</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">2708</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"other\">\n",
       "        <td class=\"fillremaining\">Other values (20790)</td>\n",
       "        <td class=\"number\">20790</td>\n",
       "        <td class=\"number\">100.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "        </div>\n",
       "        <div role=\"tabpanel\" class=\"tab-pane col-md-12\"  id=\"extreme7836336778611965321\">\n",
       "            <p class=\"h4\">Minimum 5 values</p>\n",
       "            \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">0</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">1</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">2</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">3</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">4</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "            <p class=\"h4\">Maximum 5 values</p>\n",
       "            \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">20795</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">20796</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">20797</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">20798</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">20799</td>\n",
       "        <td class=\"number\">1</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n",
       "</div><div class=\"row variablerow\">\n",
       "    <div class=\"col-md-3 namecol\">\n",
       "        <p class=\"h4 pp-anchor\" id=\"pp_var_label\">label<br/>\n",
       "            <small>Boolean</small>\n",
       "        </p>\n",
       "    </div><div class=\"col-md-6\">\n",
       "    <div class=\"row\">\n",
       "        <div class=\"col-sm-6\">\n",
       "            <table class=\"stats \">\n",
       "                <tr class=\"\">\n",
       "                    <th>Distinct count</th>\n",
       "                    <td>2</td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <th>Unique (%)</th>\n",
       "                    <td>0.0%</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Missing (%)</th>\n",
       "                    <td>0.0%</td>\n",
       "                </tr>\n",
       "                <tr class=\"ignore\">\n",
       "                    <th>Missing (n)</th>\n",
       "                    <td>0</td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "        <div class=\"col-sm-6\">\n",
       "            <table class=\"stats \">\n",
       "                <tr>\n",
       "                    <th>Mean</th>\n",
       "                    <td>0.50062</td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n",
       "<div class=\"col-md-3 collapse in\" id=\"minifreqtable5065188049752066516\">\n",
       "    <table class=\"mini freq\">\n",
       "        <tr class=\"\">\n",
       "    <th>1</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:100%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 50.1%\">\n",
       "            10413\n",
       "        </div>\n",
       "        \n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>0</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:99%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 49.9%\">\n",
       "            10387\n",
       "        </div>\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-12 text-right\">\n",
       "    <a role=\"button\" data-toggle=\"collapse\" data-target=\"#freqtable5065188049752066516, #minifreqtable5065188049752066516\"\n",
       "        aria-expanded=\"true\" aria-controls=\"collapseExample\">\n",
       "        Toggle details\n",
       "    </a>\n",
       "</div>\n",
       "<div class=\"col-md-12 extrapadding collapse\" id=\"freqtable5065188049752066516\">\n",
       "    \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">1</td>\n",
       "        <td class=\"number\">10413</td>\n",
       "        <td class=\"number\">50.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">0</td>\n",
       "        <td class=\"number\">10387</td>\n",
       "        <td class=\"number\">49.9%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:99%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>\n",
       "</div><div class=\"row variablerow\">\n",
       "    <div class=\"col-md-3 namecol\">\n",
       "        <p class=\"h4 pp-anchor\" id=\"pp_var_text\">text<br/>\n",
       "            <small>Categorical</small>\n",
       "        </p>\n",
       "    </div><div class=\"col-md-3\">\n",
       "    <table class=\"stats \">\n",
       "        <tr class=\"alert\">\n",
       "            <th>Distinct count</th>\n",
       "            <td>20387</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Unique (%)</th>\n",
       "            <td>98.0%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (%)</th>\n",
       "            <td>0.0%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (n)</th>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-6 collapse in\" id=\"minifreqtable-1732881872364346124\">\n",
       "    <table class=\"mini freq\">\n",
       "        <tr class=\"\">\n",
       "    <th> </th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:1%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.4%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        75\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>MISSING</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:1%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.2%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        39\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>Leave a Reply Click here to get more info on formatting (1) Leave the name field empty if you want to post as Anonymous. It's preferable that you choose a name so it becomes clear who said what. E-mail address is not mandatory either. The website automatically checks for spam. Please refer to our moderation policies for more details. We check to make sure that no comment is mistakenly marked as spam. This takes time and effort, so please be patient until your comment appears. Thanks. (2) 10 replies to a comment are the maximum. (3) Here are formating examples which you can use in your writing:<b>bold text</b> results in bold text <i>italic text</i> results in italic text (You can also combine two formating tags with each other, for example to get bold-italic text.)<em>emphasized text</em> results in emphasized text <strong>strong text</strong> results in strong text <q>a quote text</q> results in a quote text (quotation marks are added automatically) <cite>a phrase or a block of text that needs to be cited</cite> results in: a phrase or a block of text that needs to be cited <blockquote>a heavier version of quoting a block of text...</blockquote> results in: a heavier version of quoting a block of text that can span several lines. Use these possibilities appropriately. They are meant to help you create and follow the discussions in a better way. They can assist in grasping the content value of a comment more quickly. and last but not least:<a href=''http://link-address.com''>Name of your link</a> results in Name of your link (4) No need to use this special character in between paragraphs:  ; You do not need it anymore. Just write as you like and your paragraphs will be separated. The \"Live Preview\" appears automatically when you start typing below the text area and it will show you how your comment will look like before you send it. (5) If you now think that this is too confusing then just ignore the code above and write as you like. Name:</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:1%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.1%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        28\n",
       "    </td>\n",
       "</tr><tr class=\"other\">\n",
       "    <th>Other values (20384)</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:100%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 99.3%\">\n",
       "            20658\n",
       "        </div>\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-12 text-right\">\n",
       "    <a role=\"button\" data-toggle=\"collapse\" data-target=\"#freqtable-1732881872364346124, #minifreqtable-1732881872364346124\"\n",
       "       aria-expanded=\"true\" aria-controls=\"collapseExample\">\n",
       "        Toggle details\n",
       "    </a>\n",
       "</div>\n",
       "<div class=\"col-md-12 extrapadding collapse\" id=\"freqtable-1732881872364346124\">\n",
       "    \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\"> </td>\n",
       "        <td class=\"number\">75</td>\n",
       "        <td class=\"number\">0.4%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">MISSING</td>\n",
       "        <td class=\"number\">39</td>\n",
       "        <td class=\"number\">0.2%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Leave a Reply Click here to get more info on formatting (1) Leave the name field empty if you want to post as Anonymous. It's preferable that you choose a name so it becomes clear who said what. E-mail address is not mandatory either. The website automatically checks for spam. Please refer to our moderation policies for more details. We check to make sure that no comment is mistakenly marked as spam. This takes time and effort, so please be patient until your comment appears. Thanks. (2) 10 replies to a comment are the maximum. (3) Here are formating examples which you can use in your writing:<b>bold text</b> results in bold text <i>italic text</i> results in italic text (You can also combine two formating tags with each other, for example to get bold-italic text.)<em>emphasized text</em> results in emphasized text <strong>strong text</strong> results in strong text <q>a quote text</q> results in a quote text (quotation marks are added automatically) <cite>a phrase or a block of text that needs to be cited</cite> results in: a phrase or a block of text that needs to be cited <blockquote>a heavier version of quoting a block of text...</blockquote> results in: a heavier version of quoting a block of text that can span several lines. Use these possibilities appropriately. They are meant to help you create and follow the discussions in a better way. They can assist in grasping the content value of a comment more quickly. and last but not least:<a href=''http://link-address.com''>Name of your link</a> results in Name of your link (4) No need to use this special character in between paragraphs:  ; You do not need it anymore. Just write as you like and your paragraphs will be separated. The \"Live Preview\" appears automatically when you start typing below the text area and it will show you how your comment will look like before you send it. (5) If you now think that this is too confusing then just ignore the code above and write as you like. Name:</td>\n",
       "        <td class=\"number\">28</td>\n",
       "        <td class=\"number\">0.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Click Here To Learn More About Alexandra's Personalized Essences Psychic Protection Click Here for More Information on Psychic Protection! Implant Removal Series Click here to listen to the IRP and SA/DNA Process Read The Testimonials Click Here To Read What Others Are Experiencing! Copyright © 2012 by Galactic Connection. All Rights Reserved. \n",
       "Excerpts may be used, provided that full and clear credit is given to Alexandra Meadors and www.galacticconnection.com with appropriate and specific direction to the original content. Unauthorized use and/or duplication of any material on this website without express and written permission from its author and owner is strictly prohibited. Thank you. \n",
       "Privacy Policy \n",
       "By subscribing to GalacticConnection.com you acknowledge that your name and e-mail address will be added to our database. As with all other personal information, only working affiliates of GalacticConnection.com have access to this data. We do not give GalacticConnection.com addresses to outside companies, nor will we ever rent or sell your email address. Any e-mail you send to GalacticConnection.com is completely confidential. Therefore, we will not add your name to our e-mail list without your permission. Continue reading... Galactic Connection 2016 | Design & Development by AA at Superluminal Systems Sign Up forOur Newsletter \n",
       "Join our newsletter to receive exclusive updates, interviews, discounts, and more. Join Us!</td>\n",
       "        <td class=\"number\">26</td>\n",
       "        <td class=\"number\">0.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">source Add To The Conversation Using Facebook Comments</td>\n",
       "        <td class=\"number\">26</td>\n",
       "        <td class=\"number\">0.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Nation Puts 2016 Election Into Perspective By Reminding Itself Some Species Of Sea Turtles Get Eaten By Birds Just Seconds After They Hatch WASHINGTON—Saying they felt anxious and overwhelmed just days before heading to the polls to decide a historically fraught presidential race, Americans throughout the country reportedly took a moment Thursday to put the 2016 election into perspective by reminding themselves that some species of sea turtles are eaten by birds just seconds after they hatch. Cleveland Indians Worried Team Cursed After Building Franchise On Old Native American Stereotype CLEVELAND—Having watched in horror as their team crumbled after a 3-1 World Series lead, members of the Cleveland Indians expressed concern Thursday that the organization has been cursed for building their franchise on an incredibly old Native American stereotype. Report: Election Day Most Americans’ Only Time In 2016 Being In Same Room With Person Supporting Other Candidate WASHINGTON—According to a report released Thursday by the Pew Research Center, Election Day 2016 will, for the majority of Americans, mark the only time this year they will occupy the same room as a person who supports a different presidential candidate. Nurse Reminds Elderly Man She’s Just Down The Hall If He Starts To Die DES PLAINES, IL—Assuring him that she’d be at his side in a jiffy, local nurse Wendy Kaufman reminded an elderly resident at the Briarwood Assisted Living Community that she was just down the hall if he started to die, sources reported Tuesday. </td>\n",
       "        <td class=\"number\">11</td>\n",
       "        <td class=\"number\">0.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Hillary Clinton Waiting In Wings Of Stage Since 6 A.M. For DNC Speech PHILADELPHIA—Saying she arrived hours before any of the members of the production crew, sources confirmed Thursday that presidential nominee Hillary Clinton has been waiting in the wings of the Wells Fargo Center stage since six o’clock this morning to deliver her speech at the Democratic National Convention. Depressed, Butter-Covered Tom Vilsack Enters Sixth Day Of Corn Bender After Losing VP Spot WASHINGTON—Saying she has grown increasingly concerned about her husband’s mental and physical well-being since last Friday, Christie Vilsack, the wife of Agriculture Secretary Tom Vilsack, told reporters Thursday that the despondent, butter-covered cabinet member has entered the sixth day of a destructive corn bender after being passed over for the Democratic vice presidential spot. DNC Speech: ‘I Am Proud To Say I Walked In On Bill And Hillary Having Sex’ A friend of the Clinton family describes a Hillary who America never gets to see: the one he saw having sex. Trump Sick And Tired Of Mainstream Media Always Trying To Put His Words Into Some Sort Of Context NEW YORK—Emphasizing that the practice was just more evidence of journalists’ bias against him, Republican presidential nominee Donald Trump stated Thursday that he was sick and tired of the mainstream media always attempting to place his words into some kind of context. Who’s Speaking At The DNC: Day 4 Here is a guide to the major speakers who will be addressing attendees on the final night of the 2016 Democratic National Convention Bound, Gagged Joaquin Castro Horrified By What His Identical Twin Brother Might Be Doing Out On DNC Floor PHILADELPHIA—Struggling to free himself from the tightly wound lengths of rope binding his wrists and ankles together, bruised and gagged Texas congressman Joaquin Castro was reportedly horrified by what his identical twin brother, Secretary of Housing and Urban Development Julian Castro, might be out doing on the floor of the DNC Thursday. Obama: ‘Hillary Will Fight To Protect My Legacy, Even The Truly Detestable Parts’ PHILADELPHIA—Emphasizing the former secretary of state’s competence and tenacity during his Democratic National Convention address Wednesday night, President Barack Obama praised Hillary Clinton as someone who would work tirelessly to defend and advance the legacy he had built, even the “truly repugnant parts.” Tim Kaine Clearly Tuning Out In Middle Of Boring Vice Presidential Acceptance Speech PHILADELPHIA—Describing the look of total disinterest on his face and noting how he kept peering down at his watch as the speech progressed, sources at the Democratic National Convention said that Virginia senator Tim Kaine clearly began tuning out partway through the boring vice presidential acceptance address Wednesday night. Cannon Overshoots Tim Kaine Across Wells Fargo Center PHILADELPHIA—Noting that the vice presidential nominee had been launched nearly 100 feet into the air during his entrance into the Democratic National Convention Wednesday night, sources reported that the cannon at the back of the Wells Fargo Center had accidentally overshot Tim Kaine across the arena, sending him crashing to the stage several dozen feet beyond the erected safety net. Biden Regales DNC With Story Of ’80s Girl Band Vixen Breaking Hard Rock’s Glass Ceiling PHILADELPHIA—Devoting a large portion of his speech to the “pioneering, stiffy-inducing” all-female quartet, Vice President Joe Biden regaled the Democratic National Convention Wednesday night with the rousing story of the metal band Vixen breaking hard rock’s glass ceiling in the late 1980s. </td>\n",
       "        <td class=\"number\">10</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Notify me of follow-up comments by email. Notify me of new posts by email. PLEASE DONATE TO KEEP BARE NAKED ISLAM UP AND RUNNING. Choose DONATE for one-time donation or SUBSCRIBE for monthly donations Payment Options GET ALL NEW BNI POSTS/LINKS ON TWITTER Subscribe to Blog via Email \n",
       "Enter your email address to subscribe to this blog and receive notifications of new posts by email. Email Address</td>\n",
       "        <td class=\"number\">9</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">A leading US senator: US Supporting War in Syria\n",
       "A leading US senator said the war in Syria would have been over by now if the US had put an end to its intervention when Russia entered the war-ravaged country.\n",
       "“If the United States had just stayed out of it at that point, the war would be over by now; people would be rebuilding, refugees would be returning back to Syria, but the United States rushed anti-Tank missiles, and we used these so-called moderate rebels as a conduit to supply al-Nusra Front (also known as Fatah al-Sham Front), which is al-Qaeda in Syria,” republican member of the Virginia State in US Senate, Richard Hayden Black said in an exclusive interview with Press TV.\n",
       "“If we were not supporting the war in Syria, I believe that the Syrians, combined with their allied forces from Iran, Lebanon and Russia… would move very steadily and restore the borders of Syria.”\n",
       "The senate member, who visited Syria in April, refused to distinguish between militants and terrorists fighting the government of President Bashar al-Assad, saying, the two are “thoroughly integrated.”\n",
       "“They really are one and the same, they’re part of the same army,” he said, citing a US defense intelligence agency’s investigation in 2013, which showed Washington’s ties with the terror group.\n",
       "The outspoken state senator referred to plans by the CIA to transfer arms from Libya to Turkey and from there to Syria to supply the militants, noting that the move “evolved into an indiscriminate program of supplying all militant groups, including specifically ISIL and al-Qaeda.”\n",
       "“We do it indirectly because it’s unlawful to do it directly,” he said, adding that the US keeps “extremely violent organizations… off the terrorist watch list because these are the agents that take our weapons and then distribute them to ISIL and al-Qaeda.”\n",
       "In response to a question on why Iran and Russia are portrayed as the “bad guys,” while they are the ones really fighting terrorism there, as put recently by GOP presidential candidate Donald Trump, Black said the Republican candidate has a “clear understanding of what’s happening over there.”\n",
       "“Sometimes, his rhetoric has to match the political mood of the moment… but I know a number of his advisers and they believe that our determination to topple the government in Syria is suicidal, that it threatens not only the entire Middle East but literally the entire world.”\n",
       "He further warned that the US itself could be “threatened,” arguing that, “if Syria falls, it will be dominated by some al-Qaeda-related organization; Lebanon will fall; Jordan will fall and the entire area will be destabilized.”\n",
       "The Vietnam war veteran also elaborated on his personal definition of the Middle East “axis of evil,” naming Qatar, Saudi Arabia, and “particularly” Turkey over their support for terrorism.\n",
       "“Probably, three quarters of the rebels are not Syrian at all, they are mercenaries recruited by Turkey, Qatar and Saudi Arabia,” he asserted, describing the three countries as “the primary force behind the terrorist movement.”\n",
       "“Turkey has invaded Iraq and Syria with heavy military forces. Turkey has really become a rogue nation,” he added, referring to a 1923 treaty that set the border between Turkey and Greece, saying that was even being questioned by President Rececp Tayyip Erdogan.\n",
       "“And now you see this emerging threat against Western Europe by Turkey,” he noted, further adding that Erdogan “has made it clear that he looks to resurrection of the Ottoman Empire.”\n",
       "“He has become more and more aggressive; he’s crushed the military, the free press; every powerful institution of the Turkish government has come under his iron fist and he’s now a total dictator. He’s a man who has said that he wants the constitution amended so that he will have power similar to those of Adolf Hilter… This is our great ally; we’re allied with a man who would be Hitler.”\n",
       "He also blasted Washington’s alliance with Saudi Arabia, “where women are not allowed to walk out in the front yard to pick up the newspaper without a man’s permission; they can’t drive a car!”\n",
       "“Somehow, this is part of the liberalization that we seek to impose on the Middle East,” he said ironically, calling it “bizarre.”\n",
       "He also praised the resistance against the Saudi aggression by the people of Yemen, saying, “God bless them! The Yemenis are giving the Saudis a bloody nose,” despite being a “tiny little, poor nation.”\n",
       "“I think the world recognizes that Saudi Arabia has just embarked in massive war crimes in Yemen,” he said, voicing regret over the US support for the monarchy.\n",
       "“We don’t pay too much attention to them while engaged in war crimes because they’re our good allies,” he said, concluding that Washington is on a “suicidal course of action.”\n",
       "“Saudi money pays the very top politicians in many Western nations. And they really have co-opted the American military into acting as mercenaries for Wahhabism.”Black referred to the Western media’s portrayal of Iran as a supporter of terrorism, saying, “The fact of the matter is that if you really look at global terrorism, it all emanates from Saudi Arabia.”\n",
       "He exemplified various terrorists attack, including the 9/11, the Boston bombing, and the Brussels attacks, noting that they are all a “reflection of the Wahhabi philosophy.”</td>\n",
       "        <td class=\"number\">7</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Same people all the time , i dont know how you can fix this corruption http://www.fromthewilderness.com/free/ww3/10_09_01_krongard.html</td>\n",
       "        <td class=\"number\">6</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"other\">\n",
       "        <td class=\"fillremaining\">Other values (20377)</td>\n",
       "        <td class=\"number\">20563</td>\n",
       "        <td class=\"number\">98.9%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>\n",
       "</div><div class=\"row variablerow\">\n",
       "    <div class=\"col-md-3 namecol\">\n",
       "        <p class=\"h4 pp-anchor\" id=\"pp_var_title\">title<br/>\n",
       "            <small>Categorical</small>\n",
       "        </p>\n",
       "    </div><div class=\"col-md-3\">\n",
       "    <table class=\"stats \">\n",
       "        <tr class=\"alert\">\n",
       "            <th>Distinct count</th>\n",
       "            <td>19804</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Unique (%)</th>\n",
       "            <td>95.2%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (%)</th>\n",
       "            <td>0.0%</td>\n",
       "        </tr>\n",
       "        <tr class=\"ignore\">\n",
       "            <th>Missing (n)</th>\n",
       "            <td>0</td>\n",
       "        </tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-6 collapse in\" id=\"minifreqtable8636375295661843734\">\n",
       "    <table class=\"mini freq\">\n",
       "        <tr class=\"\">\n",
       "    <th>MISSING</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:3%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 2.7%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        558\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>The Dark Agenda Behind Globalism And Open Borders</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:1%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.0%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        5\n",
       "    </td>\n",
       "</tr><tr class=\"\">\n",
       "    <th>Get Ready For Civil Unrest: Survey Finds That Most Americans Are Concerned About Election Violence</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:1%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 0.0%\">\n",
       "            &nbsp;\n",
       "        </div>\n",
       "        5\n",
       "    </td>\n",
       "</tr><tr class=\"other\">\n",
       "    <th>Other values (19801)</th>\n",
       "    <td>\n",
       "        <div class=\"bar\" style=\"width:100%\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\"\n",
       "             data-delay=500 title=\"Percentage: 97.3%\">\n",
       "            20232\n",
       "        </div>\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "    </table>\n",
       "</div>\n",
       "<div class=\"col-md-12 text-right\">\n",
       "    <a role=\"button\" data-toggle=\"collapse\" data-target=\"#freqtable8636375295661843734, #minifreqtable8636375295661843734\"\n",
       "       aria-expanded=\"true\" aria-controls=\"collapseExample\">\n",
       "        Toggle details\n",
       "    </a>\n",
       "</div>\n",
       "<div class=\"col-md-12 extrapadding collapse\" id=\"freqtable8636375295661843734\">\n",
       "    \n",
       "<table class=\"freq table table-hover\">\n",
       "    <thead>\n",
       "    <tr>\n",
       "        <td class=\"fillremaining\">Value</td>\n",
       "        <td class=\"number\">Count</td>\n",
       "        <td class=\"number\">Frequency (%)</td>\n",
       "        <td style=\"min-width:200px\">&nbsp;</td>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tr class=\"\">\n",
       "        <td class=\"fillremaining\">MISSING</td>\n",
       "        <td class=\"number\">558</td>\n",
       "        <td class=\"number\">2.7%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:3%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">The Dark Agenda Behind Globalism And Open Borders</td>\n",
       "        <td class=\"number\">5</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Get Ready For Civil Unrest: Survey Finds That Most Americans Are Concerned About Election Violence</td>\n",
       "        <td class=\"number\">5</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">The Fix Is In: NBC Affiliate Accidentally Posts Election Results A Week Early: Hillary Wins Presidency 42% to Trump’s 40%</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Thomas Frank Explores Whether Hillary Clinton and the Democratic Party Will Address Inequality</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Schools All Over America Are Closing On Election Day Due To Fears Of Violence</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Michael Moore Owes Me $4.99</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">If Hillary Clinton Is Charged With Obstruction Of Justice She Could Go To Prison For 20 Years</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Let’s Be Clear – A Vote For Warmonger Hillary Clinton Is A Vote For World War 3</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"\">\n",
       "        <td class=\"fillremaining\">Televisión: lo más visto ayer</td>\n",
       "        <td class=\"number\">4</td>\n",
       "        <td class=\"number\">0.0%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:1%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr><tr class=\"other\">\n",
       "        <td class=\"fillremaining\">Other values (19794)</td>\n",
       "        <td class=\"number\">20204</td>\n",
       "        <td class=\"number\">97.1%</td>\n",
       "        <td>\n",
       "            <div class=\"bar\" style=\"width:100%\">&nbsp;</div>\n",
       "        </td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "    <div class=\"row headerrow highlight\">\n",
       "        <h1>Correlations</h1>\n",
       "    </div>\n",
       "    <div class=\"row variablerow\">\n",
       "    <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAk0AAAIBCAYAAABUYItPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD%2BnaQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtUVXXi/vHnIMTNC06C5m0wBJ3RCgTDTC1Rl1l5mTSZ8lqhjQpq6dQ0XWwiMyeapiSbciy/XiYpL311ctLfaKNOo2KBRioGmEZCApIplyMg5/eHy/PtDKhbN3iA/X6tdZaez774OR%2BX8PjsfQ42h8PhEAAAAC7Jw90TAAAAaAwITQAAAAYQmgAAAAwgNAEAABhAaAIAADCA0AQAAGAAoQkAAMAAQhMAAIABhCYAAAADPN09AcBqvvvuOw0aNOii2728vNS8eXMFBwfrzjvv1Pjx49W8efNrOEMAQG1s/BgV4Nr6aWgKCwurEYgqKytVXFys48ePS5Lat2%2BvZcuW6ec///k1nysA4P8QmoBr7Kehafny5YqOjq51vz179mj69OkqKSlRRESEVq9efS2nCQD4L9zTBDRQ0dHRevzxxyVJ6enp%2Buqrr9w8IwCwNkIT0IANGTLE%2Bfv9%2B/e7cSYAAG4EBxqwFi1aOH9fWlrqsm3v3r1asWKF0tLSdOrUKbVs2VLh4eGaMGGCbrvttlrPd/r0aa1evVrbt29Xdna2SkpK5Ovrq86dO2vgwIGaOHGiWrVq5XJMt27dJEmfffaZXn75ZW3dulUeHh7q0aOH3n33XXl6emr//v1atmyZDh48qPz8fHl7e6tLly4aPHiwHnzwwVpvZLfb7Vq9erU2bdqk7OxsVVZWqm3bturbt68efvhhBQcHu%2By/Z88eTZw4UbfccotWrVqlFStW6KOPPtKxY8fk5eWlHj16aMKECRo8ePDVLDUAXBahCWjAjh075vx9u3btnL9PSkrSkiVLJEmtWrVSWFiYCgoKtHXrVm3dulVxcXH67W9/63Kuo0ePavLkycrPz5enp6c6d%2B6sDh066Pjx4zpw4IAOHDigjz/%2BWGvXrpW/v3%2BNuSQkJCg9PV1hYWEqLi5WYGCgPD09tWXLFj322GOqqqpS69at1bVrV5WWlurLL7/U/v37tWHDBq1evdolOH3//fd66KGHdOTIEUlScHCw/P39lZOTo5SUFH300Ud6%2BeWXdffdd9eYR2VlpaZMmaJdu3apdevWCgkJ0TfffKPdu3dr9%2B7dev755/XAAw%2BYW3gAqI0DwDWVm5vrCAsLc4SFhTl27959yX2feOIJR1hYmKNHjx6OwsJCh8PhcLz//vuOsLAwR1RUlON///d/nftWV1c7Pv74Y0d4eLgjLCzM8cEHH7ica/z48Y6wsDDH2LFjHSdOnHA5bv369Y7u3bs7wsLCHCtXrnQ57sJce/bs6UhNTXU4HA7HuXPnHD/88IPj3Llzjttvv90RFhbmWLJkiaOqqsp53FdffeXo06ePIywszPH22287x6uqqhwjR450hIWFOYYOHeo4dOiQc9uZM2ccTz/9tPM179u3z7lt9%2B7dzrmEh4c7NmzY4Nx2%2BvRpx6RJkxxhYWGOW2%2B91VFZWXnJdQWAq8E9TUADY7fbdfDgQc2bN08fffSRJGny5Mlq06aNKioqtGjRIknSSy%2B9pBEjRjiPs9lsuvvuu50N06JFi1RVVSVJOnnypLKysiRJiYmJCgoKcjlu1KhRuvXWWyVJhw8frnVew4YNU%2B/evSVJHh4eCggIUHFxsQoLCyVJY8eOVbNmzZz79%2BjRQ4899pgGDx6sgIAA5/gnn3yiQ4cOydvbW0uWLFH37t2d25o3b64XX3xR/fv3V2VlpV577bVa5zJz5kwNHz7c%2BbxFixbO133q1Cl98803F1ldALh6XJ4D3GjixImX3ef%2B%2B%2B/XrFmzJJ1/F11RUZH8/f0v%2BgGZI0aMUGJiok6cOKGDBw/q5ptv1vXXX6/du3fLbrfLx8enxjHnzp1zXj6z2%2B21njcyMrLGWOvWrdWqVSv9%2BOOPmjt3rqZNm6ZbbrlFHh7n/z82duxYjR071uWYbdu2SZJiYmLUqVOnWv%2Bshx56SDt37lRqaqrOnDnjcm%2BXJA0cOLDGMSEhIc7fnz59utbzAoAZhCbAjf77wy1tNpu8vb0VEBCgbt26afDgweratatz%2B4W2qLKyUuPGjbvoeZs1a6bq6modOXJEN998s3Pcx8dH%2Bfn52r9/v7799lvl5uYqJydHhw4dUllZmSSpurq61nMGBgbW%2BufMnTtXzz77rLZv367t27erVatWio6O1u23364777zT5V4sSc4WqEePHhed/4Vt586d07Fjx9SzZ0%2BX7W3btq1xzE/D4Llz5y56bgC4WoQmwI2eeeaZi364ZW3OnDkjSaqoqFBaWtpl9/9p43LkyBH98Y9/1Pbt212CUfPmzRUVFaWCggJlZmZe9Fy1NVTS%2BTbp5z//ud577z395z//0Y8//qgtW7Zoy5YtstlsuvPOO/X88887w1NJSYkk1WiPfuqnQfK/3zUonf9RM5fi4DN7AdQDQhPQiPj6%2Bko638SsW7fO8HEnT57U%2BPHjdfLkSbVv315jx47VL3/5S914443q2LGjbDab5syZc8nQdCnR0dGKjo6W3W7X559/rr1792rnzp06cOCAPv30U%2BXn5%2Bujjz6SzWZzvjPvQgCszU/DXm3v5AMAdyA0AY1Ily5dJJ3/%2BICqqip5etb8J%2BxwOLRnzx61a9dO7du313XXXae1a9fq5MmTCggI0Nq1a/Wzn/2sxnEnTpy44vlUVFQoNzdXJSUluuWWW%2BTj46N%2B/fqpX79%2Beuyxx/Txxx/r8ccfV2Zmpg4fPqzu3bvrxhtv1MGDB3XgwIGLnjcjI0PS%2BcuVnTt3vuJ5AUB94N1zQCPSu3dvtWjRQqWlpRdtmjZu3KhJkyZp2LBh%2Bv777yWd/3l30vkf/ltbYMrOzta%2BffskXdn9QDt27NDdd9%2BtqVOnqqKiosb2vn37On9/4bwXbuLetm2bcnNzaz3v8uXLJUnh4eFq2bKl4fkAQH0iNAGNiJ%2Bfn6ZOnSpJmj9/vtauXetyf9I///lPzZs3T9L5jwi40NLceOONkqTMzExt3rzZub/D4dCOHTsUFxenyspKSVJ5ebnh%2BQwYMECtW7fWqVOn9OSTT%2BrUqVPObaWlpVq4cKEk6YYbblBoaKgk6a677lK3bt109uxZTZkyxeWSYElJiZ599ln9%2B9//lqenp%2BbOnWt8cQCgnnF5DmhkpkyZotzcXH3wwQf6/e9/r1deeUUdO3bUiRMnVFBQIEnq1auXXnzxRecxY8aM0d/%2B9jcdO3ZMM2fOVIcOHdS6dWvl5%2Bfr5MmT8vLy0q233qrU1NQrukx33XXX6fXXX9cjjzyiTZs2aevWrercubM8PDyUm5ursrIy%2Bfr66uWXX9Z1110nSfL09NTixYs1ZcoUHTlyRCNHjnT5RPALH4vwhz/8QVFRUXW7eABgAqEJaGRsNpsSExM1dOhQrV69Wvv27XN%2BWGR4eLjuvfdexcbGOkOKdP7daGvWrNGSJUv06aef6rvvvlNRUZHatWunO%2B%2B8U5MmTZKfn58GDx6szMxM5eXlqX379obmEx0drQ8//FDvvfeevvjiCx09elSenp5q166d%2BvXrp4cffrjGuTp27Ki1a9fq/fff1yeffKKcnBx9//33uuGGG9S/f3%2BNGzeuxs%2BeAwB3szl4by4AAMBlcU8TAACAAYQmAAAAAwhNAAAABhCaAACA2xUXF2vIkCHas2fPRffZvn27hg8frvDwcA0bNkyffvqpy/YlS5ZowIABCg8P14QJE3TkyJE6nSOhCQAAuNUXX3yh2NhYffvttxfd5%2BjRo0pISNCsWbP0%2BeefKyEhQbNnz3Z%2BTMr69eu1YsUKLV26VHv27FGPHj00c%2BbMOv1ZlIQmAABw1QoKCnTgwAGXx4XPjDNi/fr1mjt3rh577LHL7hcVFaXBgwfL09NTd999t3r37q2UlBRJ0gcffKAHH3xQoaGh8vb21pw5c5SXl3fJ5upKNd3PabLZ3D0DXE6XLlJWlhQaKn3zjbtng0v5yaeOAzDJnd%2Bf6uHPTnnjDSUnJ7uMxcfHKyEhwdDx/fr10/Dhw%2BXp6XnJ4JSdna2wsDCXsa5duzp/qkB2dramTJni3Obl5aXg4GBlZmaqT58%2BRl/OJTXd0ISGLyBAatbs/K8AzLPZJD56D9dYbGysYmJiXMYCAwMNH29039LSUvn6%2BrqM%2Bfj4qKyszND2ukBoAgAAVy0oKEhBQUH1/uf4%2BvrKbre7jNntdvn7%2BxvaXhe4pwkAAKvw8Kj7xzUSFhamrKwsl7Hs7GznDwMPDQ112V5ZWamjR4/WuKRnBqEJAACraMShacSIEUpNTdWmTZtUVVWlTZs2KTU1VSNHjpQkjR49WitXrlRmZqbOnj2rV199VW3atKnTH/xNaAIAAA1SRESENmzYIEkKCQnRm2%2B%2Bqbffflu9e/fW4sWLtWjRInXp0kWSNGbMGE2ePFkzZsxQnz59dPDgQb399tvy8vKqs/k03R/Yy7vnGr6ICCktTerVS0pPd/dscCm8e65x4EbwxsGd35%2B8vev%2BnGfP1v05GyiaJgAAAAN49xwAAFZxDe9BaooITQAAWAWhyRRWDwAAwACaJgAArIKmyRRCEwAAVkFoMoXVAwAAMICmCQAAq6BpMoXVAwAAMICmCQAAq6BpMoXQBACAVRCaTGH1AAAADKBpAgDAKmiaTGH1AAAADKBpAgDAKmiaTCE0AQBgFYQmU1g9AAAAA2iaAACwCpomU1g9AAAAA2iaAACwCpomUwhNAABYBaHJFFYPAADAAJomAACsgqbJFFYPAADAAJomAACsgqbJFEITAABWQWgyhdUDAAAwgKYJAACroGkyhdUDAAAwgKYJAACroGkyhdAEAIBVEJpMYfUAAAAMoGkCAMAqaJpMYfUAAAAMoGkCAMAqaJpMITQBAGAVhCZTWD0AAAADaJoAALAKmiZTWD0AAAADaJoAALAKmiZTCE0AAFgFockUVg8AAMAAmiYAAKyCpskUQhMAAHCbkydP6tlnn1VqaqqaNWumESNG6Mknn5Snp2tEiYuL0xdffOEyVlZWptjYWL3wwgsqKirS7bffLj8/P%2Bf21q1ba9u2bXU2V0ITAABW0QCbptmzZ6tt27bauXOnioqKNG3aNC1btkxxcXEu%2B/31r391eb5mzRolJycrPj5ekpSRkaEOHTrUaUj6b4QmAACsoh5CU0FBgQoLC13GAgMDFRQUdNljjx07ptTUVO3YsUO%2Bvr7q1KmTpk%2BfrldeeaVGaPqpI0eOKDExUUuXLnX%2BORkZGerZs6e5F3MZhCYAAHDVUlJSlJyc7DIWHx%2BvhISEyx6blZWlgIAAtW3b1jkWEhKivLw8nT59Wi1btqz1uD/84Q8aNWqUoqKinGMZGRn68ccfde%2B996qoqEg33XSTnnzySXXt2vUqX1lNhCYAAKyiHpqm2NhYxcTEuIwFBgYaOra0tFS%2Bvr4uYxeel5WV1RqaPv/8c%2B3fv19JSUku4y1btlTXrl01ZcoUXXfddXr99df10EMPadOmTWrRosWVvKSLIjQBAICrFhQUZOhSXG38/PxUXl7uMnbhub%2B/f63HpKSkaNiwYTWC2auvvury/KmnntLatWv1%2Beefa%2BDAgVc1v//W8O4IAwAA9cPDo%2B4fJoSGhurUqVMqKipyjuXk5Khdu3a1tkNVVVXaunWrRowY4TJeUlKihQsX6vjx486xc%2BfOqaqqSj4%2BPqbm%2BFOEJgAArKKBhabg4GBFRkbqpZdeUklJiXJzc7V48WKNGTOm1v0PHz6ss2fPqlevXi7jzZs313/%2B8x8tXLhQZ86cUWlpqRITE9WxY0eX%2B57MIjQBAAC3eeONN1RVVaVBgwZp7Nix6t%2B/v6ZPny5JioiI0IYNG5z75ubmqlWrVvL29q5xnsWLF6u6ulqDBw9W//79VVhYqCVLlsjLy6vO5mpzOByOOjtbQ2KzuXsGuJyICCktTerVS0pPd/dscCnV1e6eAYyw2aQm%2BiW9SXHn96ehQ%2Bv%2BnJs31/05GyhuBAcAwCoa4IdbNiasHgAAgAE0TQAAWAVNkymsHgAAgAE0TQAAWAVNkymEJgAArILQZAqrBwAAYABNEwAAVkHTZAqrBwAAYABNEwAAVkHTZAqhCQAAqyA0mcLqAQAAGEDTBACAVdA0mcLqAQAAGEDTBACAVdA0mUJoAgDAKghNprB6AAAABtA0AQBgFTRNprB6AAAABtA0AQBgFTRNphCaAACwCkKTKaweAACAATRNAABYBU2TKaweAACAATRNAABYBU2TKYQmAACsgtBkCqsHAABgAE0TAABWQdNkCqsHAABgAE0TAABWQdNkCqEJAACrIDSZwuoBAAAYQNMEAIBV0DSZwuoBAAAYQNMEAIBV0DSZQmgCAMAqCE2msHoAAAAG0DQBAGAVNE2msHoAAAAG0DQBAGAVNE2mEJoAALAKQpMprB4AAIABNE0AAFgFTZMpblu9vLw8RUREKC8vr8a2devWKSYmxg2zAgCgCfPwqPuHSSdPntT06dMVFRWl6OhozZ8/X1VVVbXuGxcXp5tuukkRERHOx44dOyRJ586d08KFC9W3b19FRERo2rRpKigoMD2/n3JbaGrfvr3S09PVvn17d00BAAC42ezZs%2BXn56edO3dqzZo12rVrl5YtW1brvl999ZWWLl2q9PR052PAgAGSpLfeekufffaZ1q5dq507d8rHx0fPPPNMnc7VbZfnvvvuOw0aNEhbt27V2bNn9fzzz%2Burr75Sx44dFR0dfUXnKigoUGFhoctYYJcuCgoIqMspo6517%2B76KwCgftXD5blavwcHBiooKOiyxx47dkypqanasWOHfH191alTJ02fPl2vvPKK4uLiXPbNzc3Vjz/%2BqF/%2B8pe1nuvDDz/U3LlzdcMNN0iSnn76afXr10%2B5ubnq1KnTVb46V26/p6mqqkqPPvqoBgwYoL/%2B9a/69ttvNWXKFHlcwV9sSkqKkpOTXcbiZ81SwqxZdT1d1Ie//c3dMwCaDpvN3TOAxdT6PTg%2BXgkJCZc9NisrSwEBAWrbtq1zLCQkRHl5eTp9%2BrRatmzpHM/IyJC/v78ee%2BwxZWRkqE2bNpo8ebLGjBmjM2fO6Pvvv1dYWJhz/zZt2qhVq1Y6fPhw0wlNBQUFys/P1xNPPCFvb2%2BFhobqoYce0v/8z/8YPkdsbGyNe6AChw%2BXruAccIPu3c8HpgcflDIz3T0bXMoXX7h7BjDCZpMcDnfPApfjzmBbD01Trd%2BDAwMNHVtaWipfX1%2BXsQvPy8rKXEJTRUWFwsPD9dhjjyk0NFR79uxRQkKC/P39FRERIUny8/NzOZePj49KS0uv%2BDVdjNtDU1pamlq3bi0fHx/nWOfOna/oHEFBQTVrwG%2B%2BqYvp4VrIzJTS0909CwBo%2BuohNNX6PdggPz8/lZeXu4xdeO7v7%2B8yPmrUKI0aNcr5vF%2B/fho1apT%2B8Y9/qG/fvi7HXmC322ucxwy3v/cwKipKxcXFLknw%2B%2B%2B/d%2BOMAADAtRAaGqpTp06pqKjIOZaTk6N27dqpRYsWLvuuWbNG//jHP1zGKioq5O3trVatWqlt27bKzs52bissLNSpU6dcLtmZ5fbQFBQUpC5duujFF19UeXm5jh07pnfffdfd0wIAoOlpYB85EBwcrMjISL300ksqKSlRbm6uFi9erDFjxtTYt6SkRImJiTp48KCqq6v1r3/9S3//%2B98VGxsrSbrvvvv01ltvKTc3VyUlJXrppZd06623XvHVq0txe2jy8PDQO%2B%2B8o4KCAvXt21dxcXEaNGiQu6cFAACugTfeeENVVVUaNGiQxo4dq/79%2B2v69OmSpIiICG3YsEGSNGnSJI0fP17x8fGKiIhQUlKSFi5cqKioKEnSjBkzdMcdd2jcuHG64447dPbsWf35z3%2Bu07naHI4metcg7yBp%2BCIipLQ0qVcv7mlq6Kqr3T0DGMGN4I2DO78/LVhQ9%2Bd86qm6P2cD5fYbwQEAwDXCj1ExhdUDAAAwgKYJAACroGkyhdUDAAAwgKYJAACroGkyhdAEAIBVEJpMYfUAAAAMoGkCAMAqaJpMYfUAAAAMoGkCAMAqaJpMITQBAGAVhCZTWD0AAAADaJoAALAKmiZTWD0AAAADaJoAALAKmiZTCE0AAFgFockUVg8AAMAAmiYAAKyCpskUVg8AAMAAmiYAAKyCpskUQhMAAFZBaDKF1QMAADCApgkAAKugaTKF1QMAADCApgkAAKugaTKF0AQAgFUQmkxh9QAAAAygaQIAwCpomkxh9QAAAAygaQIAwCpomkwhNAEAYBWEJlNYPQAAAANomgAAsAqaJlMITQAAWAWhyRRWDwAAwACaJgAArIKmyRRWDwAAwACaJgAArIKmyRRCEwAAVkFoMoXVAwAAMICmCQAAq6BpMoXVAwAAMICmCQAAq6BpMoXQBACAVTTA0HTy5Ek9%2B%2ByzSk1NVbNmzTRixAg9%2BeST8vSsGVHef/99LVu2TAUFBQoKCtLEiRM1btw4SVJ1dbUiIyPlcDhks9mcx3z22Wfy8/Ork7kSmgAAgNvMnj1bbdu21c6dO1VUVKRp06Zp2bJliouLc9nvn//8p/70pz9pyZIluuWWW7Rv3z5NnTpVbdq00dChQ5Wdna3KykqlpaXpuuuuq5e5EpoAALCKemiaCgoKVFhY6DIWGBiooKCgyx577NgxpaamaseOHfL19VWnTp00ffp0vfLKKzVC04kTJzRlyhSFh4dLkiIiIhQdHa29e/dq6NChysjIULdu3eotMEmEJgAAYEJKSoqSk5NdxuLj45WQkHDZY7OyshQQEKC2bds6x0JCQpSXl6fTp0%2BrZcuWzvELl%2BEuOHnypPbu3aunnnpKkpSRkaGzZ89q9OjROn78uEJCQjRnzhz16tXLzMtzQWgCAMAq6qFpio2NVUxMjMtYYGCgoWNLS0vl6%2BvrMnbheVlZmUto%2BqnCwkI9%2Buij6tmzp%2B69915Jko%2BPj26%2B%2BWbNmjVLrVq10qpVq/TII49ow4YN6tSp05W%2BrFoRmgAAsIp6CE1BQUGGLsXVxs/PT%2BXl5S5jF577%2B/vXesy%2Bffs0a9YsRUVFacGCBc4bxn/3u9%2B57PfII49o3bp12r59u8aPH39V8/tvDe82egAAYAmhoaE6deqUioqKnGM5OTlq166dWrRoUWP/NWvWaPLkyZo0aZJeffVVl/uXXnvtNR08eNBl/4qKCnl7e9fZfAlNAABYhYdH3T9MCA4OVmRkpF566SWVlJQoNzdXixcv1pgxY2rsu3nzZj3//PNatGiRHn744Rrbv/76a82fP1%2BFhYWqqKhQcnKySkpKNGTIEFNz/ClCEwAAcJs33nhDVVVVGjRokMaOHav%2B/ftr%2BvTpks6/Q27Dhg2SpOTkZJ07d04zZ85URESE8/Hcc89JkhYsWKDOnTtr5MiRio6OVmpqqt577z0FBATU2VxtDofDUWdna0h%2B8sFWaKAiIqS0NKlXLyk93d2zwaVUV7t7BjDCZpOa6Jf0JsWd35927ar7c952W92fs4HiRnAAAKyiAX4ieGPC6gEAABhA0wQAgFXQNJnC6gEAABhA0wQAgFXQNJlCaAIAwCoITaawegAAAAbQNAEAYBU0TaawegAAAAbQNAEAYBU0TaYQmgAAsApCkymsHgAAgAE0TQAAWAVNkymsHgAAgAE0TQAAWAVNkymEJgAArILQZAqrBwAAYABNEwAAVkHTZAqrBwAAYABNEwAAVkHTZAqhCQAAqyA0mcLqAQAAGEDTBACAVdA0mcLqAQAAGEDTBACAVdA0mUJoAgDAKghNprB6AAAABtA0AQBgFTRNphCaAACwCkKTKaweAACAATRNAABYBU2TKaweAACAATRNAABYBU2TKYQmAACsgtBkCqsHAABgAE0TAABWQdNkCqsHAABgAE0TAABWQdNkCqEJAACrIDSZwuoBAAAYQNMEAIBV0DSZwuoBAAAYQNMEAIBV0DSZwuoBAGAVHh51/zDp5MmTmj59uqKiohQdHa358%2Berqqqq1n23b9%2Bu4cOHKzw8XMOGDdOnn37qsn3JkiUaMGCAwsPDNWHCBB05csT0/H6K0AQAANxm9uzZ8vPz086dO7VmzRrt2rVLy5Ytq7Hf0aNHlZCQoFmzZunzzz9XQkKCZs%2BerRMnTkiS1q9frxUrVmjp0qXas2ePevTooZkzZ8rhcNTZXAlNAABYRT00TQUFBTpw4IDLo6CgwNB0jh07ptTUVP32t7%2BVr6%2BvOnXqpOnTp2vVqlU19l2/fr2ioqI0ePBgeXp66u6771bv3r2VkpIiSfrggw/04IMPKjQ0VN7e3pozZ47y8vK0Z8%2BeOlu%2BpntPU3W1u2cAo774wt0zwOVwH0TDFxEhpaVJkZFSerq7Z4NLqcPmoyFISUlRcnKyy1h8fLwSEhIue2xWVpYCAgLUtm1b51hISIjy8vJ0%2BvRptWzZ0jmenZ2tsLAwl%2BO7du2qzMxM5/YpU6Y4t3l5eSk4OFiZmZnq06fPVb22/9Z0QxMAAHDhkK3OzxkbG6uYmBiXscDAQEPHlpaWytfX12XswvOysjKX0FTbvj4%2BPiorKzO0vS4QmgAAsIj6uAgTFBSkoKCgqzrWz89P5eXlLmMXnvv7%2B7uM%2B/r6ym63u4zZ7XbnfpfbXhfo3AEAgFuEhobq1KlTKioqco7l5OSoXbt2atGihcu%2BYWFhysrKchnLzs5WaGio81w/3V5ZWamjR4/WuKRnBqEJAACLqK6u%2B4cZwcHBioyM1EsvvaSSkhLl5uZq8eLFGjNmTI19R4wYodTUVG3atElVVVXatGmTUlNTNXLkSEnS6NGjtXLlSmVmZurs2bN69dVX1aZNG0VFRZmb5E8QmgAAgNu88cYbqqqq0qBBgzR27Fj1799f06dPlyRFRERow4YNks7fIP7mm2/q7bffVu/evbV48WItWrRIXbp0kSSNGTNGkydP1owZM9SnTx8dPHhQb7/9try8vOpsrjZHXX6AQUPSRF9Wk2Oz8XfVGPDuuYbvwrtQfv2/AAAZP0lEQVTnevXi3XMNnRu/5p09W/fn9Pau%2B3M2VNwIDgCARfBpPObw30cAAAADaJoAALAImiZzaJoAAAAMoGkCAMAiaJrMITQBAGARhCZzuDwHAABgAE0TAAAWQdNkDk0TAACAATRNAABYBE2TOYQmAAAsgtBkDpfnAAAADKBpAgDAImiazKFpAgAAMICmCQAAi6BpMofQBACARRCazOHyHAAAgAE0TQAAWARNkzmEJgAALILQZA6X5wAAAAygaQIAwCJomsyhaQIAADCApgkAAIugaTKH0AQAgEUQmszh8hwAAIABNE0AAFgETZM5NE0AAAAG0DQBAGARNE3mEJoAALAIQpM5XJ4DAAAwgKYJAACLoGkyh6YJAADAAJomAAAsgqbJHEITAAAWQWgyh8tzAAAABtA0AQBgETRN5tA0AQAAGEDTBACARdA0mUNoAgDAIghN5nB5DgAAwACaJgAALIKmyRyaJgAAAANomgAAsAiaJnMITQAAWERjC01lZWVKTEzUtm3bVFVVpUGDBmnevHny9/evdf/Nmzdr8eLFys3NVUBAgO677z5Nnz5dHh7nL6wNGzZMeXl5zueStGbNGoWEhBiaD6EJAAA0SImJicrPz9fmzZt17tw5zZ49W0lJSZo3b16Nfb/66is98cQT%2BvOf/6w77rhD33zzjaZMmSI/Pz89/PDDKikp0TfffKOtW7eqQ4cOVzUf7mkCAMAiqqvr/lFQUKADBw64PAoKCkzPtby8XBs3btTMmTMVEBCg66%2B/XnPnztW6detUXl5eY//jx4/r17/%2BtQYOHCgPDw%2BFhIRoyJAh2rt3r6TzoSogIOCqA5NE0wQAAExISUlRcnKyy1h8fLwSEhIue6zdbteJEydq3VZeXq7KykqFhYU5x0JCQmS323X06FH94he/cNl/6NChGjp0qMu5//Wvf2n48OGSpIyMDPn6%2Bmr8%2BPHKyspShw4dlJCQoIEDBxp%2BrYQmAAAsoj7uaYqNjVVMTIzLWGBgoKFj9%2B/fr4kTJ9a6bdasWZIkPz8/55ivr68kqbS09JLnLSkp0axZs%2BTj46PJkydLkmw2m2666SY9/vjjat%2B%2BvT755BMlJCRo5cqVCg8PNzRfQhMAABZRH6EpKChIQUFBV3VsdHS0Dh8%2BXOu2gwcP6vXXX1d5ebnzxu8Ll%2BWaN29%2B0XMeOXJEM2fO1PXXX6/ly5c7942Li3PZb8SIEfr73/%2BuzZs3Gw5N3NMEAAAanC5dusjLy0vZ2dnOsZycHHl5eSk4OLjWY7Zv3677779f/fv319KlS9WqVSvntqVLl2rXrl0u%2B1dUVMjb29vwnAhNAABYRH3cCF5ffH19NWzYMCUlJam4uFjFxcVKSkrSvffeKx8fnxr779u3TzNmzNBTTz2lJ598Up6erhfT8vPz9Yc//EG5ubmqqqrSmjVrlJ6erl/96leG52RzOBwO06%2BsIWqiL6vJsdn4u2oMPPj/VYMXESGlpUm9eknp6e6eDS7FjV/z/t//q/tzDhlS9%2Be8oKSkRAsXLtS2bdtUWVmpQYMG6dlnn3Xe53TPPfdo%2BPDh%2Bs1vfqPf/OY3%2Bte//uW87%2BmCyMhI/fWvf1VFRYWSkpL0j3/8Q2fOnFHXrl3129/%2BVtHR0YbnQ2iCexGaGgdCU8NHaGo83Pg1b/Pmuj/nT96w1uRxIzgAABbR2D4RvKHhv48AAAAG0DQBAGARNE3m0DQBAAAYQNMEAIBF0DSZQ2gCAMAiCE3mcHkOAADAAJomAAAsgqbJHEITAAAWQWgyh8tzAAAABtA0AQBgETRN5tA0AQAAGEDTBACARdA0mUNoAgDAIghN5nB5DgAAwACaJgAALIKmyRyaJgAAAANomgAAsAiaJnMITQAAWAShyRwuzwEAABhA0wQAgEXQNJlD0wQAAGAATRMAABZB02QOoQkAAIsgNJnD5TkAAAADaJoAALAImiZzaJoAAAAMoGkCAMAiaJrMITQBAGARhCZzuDwHAABgAE0TAAAWQdNkDk0TAACAATRNAABYBE2TOYQmAAAsgtBkDpfnAAAADKBpAgDAImiazKFpAgAAMICmCQAAi6BpMofQBACARRCazOHyHAAAgAE0TQAAWARNkzk0TQAAAAZcUWj67rvv1K1bN3333XeX3G/Pnj3q1q3bVU9qwoQJWrRo0VUfDwAAaqqurvtHfSorK9NTTz2l6OhoRUZG6oknnlBpaelF9583b5569uypiIgI5yMlJcW5fcmSJRowYIDCw8M1YcIEHTly5IrmQ9MEAIBFNLbQlJiYqPz8fG3evFlbtmxRfn6%2BkpKSLrp/RkaGEhMTlZ6e7nzExsZKktavX68VK1Zo6dKl2rNnj3r06KGZM2fK4XAYns9Vh6a0tDRNnDhR/fr100033aT77rtP%2B/btc9nnnXfe0R133KEBAwbolVdeUUVFhXPbxx9/rOHDhysyMlL33Xef/v3vf1/tVAAAQBNTXl6ujRs3aubMmQoICND111%2BvuXPnat26dSovL6%2Bxf0VFhb7%2B%2Bmv17Nmz1vN98MEHevDBBxUaGipvb2/NmTNHeXl52rNnj%2BE5XdWN4GfPntW0adM0c%2BZMPfDAA7Lb7fr973%2BvP/7xj/rb3/7m3O/rr7/Wpk2bVFRUpLi4OPn5%2BWnGjBnavn275s2bp7feeku9evXSjh07lJCQoA8%2B%2BEChoaFXPJ%2BCggIVFha6jAW2aaOgoKCreXkA/ltEhLtngMvp3t31V6AW9dEM1fo9ODDQ0Pdgu92uEydO1LqtvLxclZWVCgsLc46FhITIbrfr6NGj%2BsUvfuGyf2ZmpqqqqvTGG2/oiy%2B%2BUIsWLTR69GjFxcXJw8ND2dnZmjJlinN/Ly8vBQcHKzMzU3369DH0Wq8qNHl5eSklJUU///nPdfbsWR0/flwBAQHKyMhw7mOz2fTcc8/J399f/v7%2BiouL07vvvqsZM2Zo5cqVeuCBB9S7d29J0sCBAxUTE6PVq1fr2WefveL5pKSkKDk52WUsfsYMJcyceTUvD9eazebuGeBy0tLcPQMY9ZP/uALXQq3fg%2BPjlZCQcNlj9%2B/fr4kTJ9a6bdasWZIkPz8/55ivr68k1Xpf05kzZ3TrrbdqwoQJ%2BtOf/qRDhw5pxowZ8vDwUFxcnEpLS53HX%2BDj46OysrLLzvOCqwpNHh4e2rVrl6ZMmaKysjJ17dpVnp6eLtcFW7ZsqZYtWzqf33DDDc40efz4caWmpur99993bj937pzhpPffYmNjFRMT4zIW2KaNdAXXKeEmNht/T41BZKS7Z4DL6d79fGB68EEpM9Pds8GluPE/IfXRNNX6PTgw0NCx0dHROnz4cK3bDh48qNdff13l5eXy9/eXJOdluebNm9fY//bbb9ftt9/ufH7zzTdr0qRJ2rRpk%2BLi4uTr6yu73e5yjN1ud57biKsKTSdPnlRiYqJWr17tvHb47rvv6ptvvnHuU1JSorKyMmdCzM3NVYcOHSRJ7dq106hRozR16lTn/nl5efLx8bma6SgoKKhmDcg3YqDupKe7ewYwKjOTvy9cVH2Eplq/B9eBLl26yMvLS9nZ2brlllskSTk5Oc7Lav/tn//8p4qKivTrX//aOVZRUeHMFqGhocrKytLAgQMlSZWVlTp69KjL5b/LuaobwTMzM%2BXh4eGcyL59%2B7R8%2BXKXG73PnTunl19%2BWWVlZcrJydHSpUudL2Ts2LFavny5vvzyS0nn73a/77779Pe///1qpgMAAJoYX19fDRs2TElJSSouLlZxcbGSkpJ077331lqyOBwOLViwQLt27ZLD4VB6erqWL1/ufPfc6NGjtXLlSmVmZurs2bN69dVX1aZNG0VFRRme01U1TX379tWDDz6ocePGqbq6Wh07dtSECRP06quvqqioSJIUEBCggIAA3XHHHfL399evf/1rjRs3TpJ01113qaysTL///e%2BVl5engIAATZ48WRMmTLia6QAAAAMa2yeCz5s3TwsXLtTw4cNVWVmpQYMGudz7fM8992j48OH6zW9%2BoyFDhuipp57S888/rxMnTqhNmzZKSEjQyJEjJUljxozRmTNnNGPGDBUXF%2Bumm27S22%2B/LS8vL8PzsTmu5AMKGpMm%2BrKaHO5pahw8%2BEi3Bi8i4vy9Mr16cXmuoXPj17ynn677c86fX/fnbKj42XMAAFhEY2uaGhpCEwAAFkFoMofOHQAAwACaJgAALIKmyRxCEwAAFkFoMofLcwAAAAbQNAEAYBE0TebQNAEAABhA0wQAgEXQNJlDaAIAwCIITeZweQ4AAMAAmiYAACyCpskcmiYAAAADaJoAALAImiZzCE0AAFgEockcLs8BAAAYQNMEAIBF0DSZQ9MEAABgAE0TAAAWQdNkDqEJAACLIDSZw%2BU5AAAAA2iaAACwCJomc2iaAAAADKBpAgDAImiazCE0AQBgEYQmc7g8BwAAYABNEwAAFkHTZA5NEwAAgAE0TQAAWARNkzmEJgAALILQZA6X5wAAAAygaQIAwCJomsyhaQIAADCApgkAAIugaTKH0AQAgEUQmszh8hwAAIABNE0AAFgETZM5NE0AAAAG0DQBAGARNE3mEJoAALAIQpM5XJ4DAAAwgKYJAACLoGkyh6YJAADAAJomAAAsorE1TWVlZUpMTNS2bdtUVVWlQYMGad68efL396%2Bx73PPPaeNGze6jNntdvXt21dLly5VdXW1IiMj5XA4ZLPZnPt89tln8vPzMzQfQhMAABbR2EJTYmKi8vPztXnzZp07d06zZ89WUlKS5s2bV2PfF154QS%2B88ILz%2Bb///W/NmTNHv/vd7yRJ2dnZqqysVFpamq677rqrmg%2BX5wAAQINTXl6ujRs3aubMmQoICND111%2BvuXPnat26dSovL7/kscXFxZo7d66efvpphYaGSpIyMjLUrVu3qw5MEk0TAACWUR9NU0FBgQoLC13GAgMDFRQUdNlj7Xa7Tpw4Ueu28vJyVVZWKiwszDkWEhIiu92uo0eP6he/%2BMVFz5uUlKSePXtqxIgRzrGMjAydPXtWo0eP1vHjxxUSEqI5c%2BaoV69el53nBYQmAAAsoj5CU0pKipKTk13G4uPjlZCQcNlj9%2B/fr4kTJ9a6bdasWZLkcr%2BRr6%2BvJKm0tPSi58zNzdWGDRv04Ycfuoz7%2BPjo5ptv1qxZs9SqVSutWrVKjzzyiDZs2KBOnTpddq4SoQkAAJgQGxurmJgYl7HAwEBDx0ZHR%2Bvw4cO1bjt48KBef/11lZeXO2/8vnBZrnnz5hc959q1axUREVGjibpwb9MFjzzyiNatW6ft27dr/PjxhuZLaAIAwCLqo2kKCgoydCnuSnXp0kVeXl7Kzs7WLbfcIknKycmRl5eXgoODL3rcli1b9PDDD9cYf%2B211zR06FD98pe/dI5VVFTI29vb8Jy4ERwAADQ4vr6%2BGjZsmJKSklRcXKzi4mIlJSXp3nvvlY%2BPT63H/PDDD8rJyVHv3r1rbPv66681f/58FRYWqqKiQsnJySopKdGQIUMMz4nQBACARVRX1/2jPs2bN0/BwcEaPny47rrrLnXs2FHPPfecc/s999yjv/zlL87n3333nSSpbdu2Nc61YMECde7cWSNHjlR0dLRSU1P13nvvKSAgwPB8bA6Hw2Hi9TRcTfRlNTk2G39XjYEH/79q8CIipLQ0qVcvKT3d3bPBpbjxa95tt9X9OXftqvtzNlR8JQQAADCAG8EBALCIxvaJ4A0NTRMAAIABNE0AAFgETZM5hCYAACyC0GQOl%2BcAAAAMoGkCAMAiaJrMoWkCAAAwgKYJAACLoGkyh9AEAIBFEJrM4fIcAACAATRNAABYBE2TOTRNAAAABtA0AQBgETRN5hCaAACwCEKTOVyeAwAAMICmCQAAi6BpMoemCQAAwACaJgAALIKmyRxCEwAAFkFoMofLcwAAAAbQNAEAYBE0TebQNAEAABhA0wQAgEXQNJlDaAIAwCIITeZweQ4AAMAAmiYAACyCpskcmiYAAAADaJoAALAImiZzCE0AAFgEockcLs8BAAAYQNMEAIBF0DSZQ9MEAABgAE0TAAAWQdNkDqEJAACLIDSZw%2BU5AAAAA2iaAACwCJomcwhNAABYBKHJHC7PAQAAGEDTBACARdA0mUPTBAAAYABNEwAAFkHTZA6hCQAAiyA0mcPlOQAA0KCVl5crNjZW69atu%2BR%2B%2B/fv1/3336%2BIiAjFxMToww8/dNm%2Bfv16DRkyROHh4brvvvuUnp5%2BRfMgNAEAYBHV1XX/qG9ZWVkaN26c9u3bd8n9fvzxR02dOlWjRo3S3r17NX/%2BfC1YsEBffvmlJGnPnj1KTEzUyy%2B/rL1792rEiBGaNm2aysvLDc%2BF0AQAABqkXbt2adKkSfrVr36l9u3bX3LfLVu2KCAgQOPGjZOnp6duu%2B02DR8%2BXKtWrZIkffjhh7rnnnsUGRkpLy8vTZ48Wa1bt9amTZsMz4d7mgAAsIj6aIYKCgpUWFjoMhYYGKigoKDLHmu323XixIlatwUGBqp79%2B769NNP5e3trffee%2B%2BS58rKylJYWJjLWNeuXbVmzRpJUnZ2tkaPHl1je2Zm5mXneUHTDU02m7tngMsoKChQSkqKYmNjDf3jghs5HO6eAS6joKBAKYsWKfaTT/j3hIuqj3/KixalKDk52WUsPj5eCQkJlz12//79mjhxYq3b3nzzTQ0ePNjwPEpLS%2BXr6%2Bsy5uPjo7KyMkPbjWi6oQkNXmFhoZKTkxUTE8MXecAk/j3BXWJjYxUTE%2BMyFhgYaOjY6OhoHT58uE7m4evrqzNnzriM2e12%2Bfv7O7fb7fYa21u3bm34zyA0AQCAqxYUFNQggnpYWJg%2B%2B%2Bwzl7Hs7GyFhoZKkkJDQ5WVlVVj%2B4ABAwz/GdwIDgAAGr0hQ4aoqKhIy5YtU2VlpXbv3q2NGzc672MaM2aMNm7cqN27d6uyslLLli3TyZMnNWTIEMN/BqEJAAA0Svfcc4/%2B8pe/SJJat26td999V5988omio6P1zDPP6JlnnlGfPn0kSbfddpvmzZun559/Xrfeeqs%2B/vhjLVmyRAEBAYb/PJvDwR2ecA9uBAfqDv%2BegPpHaAIAADCAy3MAAAAGEJoAAAAMIDQBAAAYQGgCAAAwgNAEAABgAKEJAADAAEITAACAAYQmAAAAAwhNAAAABhCaAAAADCA0AQAAGODp7gnAGmJiYmSz2S65z9atW6/RbIDGLTk5%2BbL7xMfHX4OZANZCaMI1kZCQIEk6cOCAtm7dqoceekidO3dWfn6%2B3nvvPQ0aNMjNMwQajz179lxy%2B%2BX%2BgwLg6tgcDofD3ZOAdYwYMUKvvfaaQkJCnGPHjh3T1KlTtXnzZjfODACAS%2BOeJlxTubm56ty5s8tY27ZtVVBQ4KYZAY1bTk6OXnzxRcXHx%2BuHH37QypUr3T0loMkiNOGa6tmzpxYuXKiKigpJUnl5uRITExUZGenmmQGNz2effab7779fP/zwg/7zn//IbrfrzTff1DvvvOPuqQFNEpfncE0dOXJEjz76qPLz89W6dWsVFxfrxhtv1DvvvKMbbrjB3dMDGpXRo0dr5syZuuOOO9S7d2/t3btXGRkZmj17Nm%2BsAOoBN4Ljmvj%2B%2B%2B/Vrl07%2Bfj4aOnSpTpx4oTS09MVGRmpoKAgkd2BK3fs2DENGDBA0v/d/H3TTTfpxx9/dOe0gCaL0IRr4u6771ZaWprLRw84HA7ZbDbnr4cOHXLzLIHGpX379kpLS3O5vJ2RkUFrC9QTQhOuiY8//lgSn8UE1KVHH31U06ZN0wMPPKDKykotWbJEK1as0OOPP%2B7uqQFNEvc0AUAjtn37dq1atUrHjx9Xu3btNHbsWA0dOtTd0wKaJEITAACAAXzkAAA0UlVVVXrrrbd01113KSIiQsOHD9eqVavcPS2gyeKeJgBopP785z9ry5YtiouL0w033KBvv/1W7777rkpLSzV16lR3Tw9ocrg8BwCN1J133qkVK1aoU6dOzrGcnBxNmTJF27Ztc%2BPMgKaJy3MA0IgFBga6PG/fvr1KSkrcNBugaSM0AUAjNW7cOD333HPOkGS327Vw4UI98MADbp4Z0DRxeQ4AGpnu3bs7PxhWkjw8PNSiRQuVlpaqqqpKrVu31q5du9w8S6Dp4UZwAGhkli9f7u4pAJZE0wQATUxxcbF%2B9rOfuXsaQJND0wQAjdSXX36pP/7xjzpx4oSqq6slSZWVlSouLtZXX33l5tkBTQ83ggNAI/XCCy8oMDBQ/fr1U5cuXTR%2B/Hg1a9ZMc%2BbMcffUgCaJ0AQAjVRWVpYWLFigcePG6dy5c3rooYf02muvaePGje6eGtAkEZoAoJFq2bKlfHx81KlTJ2VlZUmSwsPDdfz4cTfPDGiaCE0A0EjdeOONev/99%2BXt7S0/Pz8dOnRIOTk5stls7p4a0CRxIzgANFKzZs3StGnTdPvtt%2BuRRx7R2LFj1axZMz7cEqgnfOQAADQyeXl5zt/b7XZ5eXmpWbNmKioq0uHDh9W3b1916NDBjTMEmiZCEwA0Mhc%2BEbw2DodDNptNhw4dusazApo%2BQhMANDJGbvSmaQLqHqEJAADAAN49BwAAYAChCQAAwABCEwAAgAGEJgAAAAMITQAAAAYQmgAAAAwgNAEAABjw/wHSbwSFT8sTIQAAAABJRU5ErkJggg%3D%3D\" class=\"center-img\">\n",
       "    <img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAk0AAAIBCAYAAABUYItPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD%2BnaQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XlcVXXi//H3RZHNBVPQTB0NQSstEY1yTdSHWWmWJpl7YY0L4oxNZVPZZGpOOE5KlpnluFSUy4xOln1t0WpMLNAoxQCXUIw1F3aQ%2B/ujB/fnDdSjB73AeT0fDx7F5yx87vEhvH2fzz3Y7Ha7XQAAALggN1dPAAAAoDYgNAEAABhAaAIAADCA0AQAAGAAoQkAAMAAQhMAAIABhCYAAAADCE0AAAAGEJoAAAAMqO/qCQB1SVJSktavX69du3YpIyNDxcXFuuaaaxQYGKg77rhDI0eOlKenp6unCQC4DDZ%2BjQpQPZYsWaLXXntN5eXlatiwodq2bSt3d3dlZWUpPT1dknTttdfq1Vdf1U033eTi2QIALhWhCagGGzZs0NNPPy1vb28tWLBAgwYNUr169RzbU1NT9fTTT2vv3r1q2rSptm7dqmuuucaFMwYAXCrWNAHV4PXXX5ckPfHEE7rzzjudApMkBQQE6LXXXlOzZs3066%2B/avXq1a6YJgDABEITYNLp06f1888/S5JuueWW8%2B53zTXXaODAgZKk77///qrMDQBQfVgIDphUv/7//2v0%2Beef68YbbzzvvpGRkRo/fryaNWvmGHvqqae0adMmzZ49W3369NHixYu1Z88elZSU6A9/%2BIPuu%2B8%2BPfjgg/Lw8KjynHv27NGaNWsUHx%2BvkydPqnHjxuratavGjRun22%2B/vcpjTp8%2Brffee087duxQSkqK8vLy5OXlpbZt26p///4aP368mjRp4nRMx44dJUlff/21XnrpJX366adyc3PTTTfdpLfeekvPPPOMNm3apBdffFE9evTQ0qVL9c033%2BjMmTNq3bq1HnjgAU2cOFE2m02ffPKJ/vWvf%2BnAgQMqLy9Xp06dNGXKFPXr16/SXIuKirRhwwZt375dBw8e1OnTp9WgQQO1atVKvXv31qRJk9SiRQunY8LCwnT8%2BHFt3bpVOTk5evPNN7Vv3z4VFBSodevWGjJkiB555BH5%2BPic988KAH6PNU1ANRg9erTi4%2BNls9l07733auTIkerWrVul23RVqQhN999/v7Zt26aCggIFBgaqrKxMhw4dkiSFhIRo%2BfLlatSokdOx0dHRWrFihSSpSZMmat26tTIzM5WVlSVJioiI0F/%2B8henY44cOaKJEyfqxIkTql%2B/vtq2bSsvLy8dP35cJ0%2BelCS1b99eGzZscAoVFaGpW7duSkhIUFBQkHJzcxUaGqpFixY5vY6PPvpIZWVlCggIUE5OjmM%2Bjz76qGw2m5YvX67GjRurTZs2Onz4sAoKCmSz2fTGG2%2Bob9%2B%2Bjq%2BZm5urCRMm6KeffpLNZlPbtm3VqFEjZWRkOM7ZrFkzbdy4US1btnQcVxGaJk2apFWrVqlBgwZq166dTp06pV9%2B%2BUWSFBwcrHXr1hn6MwIASZIdgGk//vijvWvXrvagoCDHR7du3eyTJ0%2B2L1%2B%2B3L5371772bNnqzz2ySefdBzTv39/%2B/79%2Bx3b4uPj7T179rQHBQXZn332Wafj3n33XXtQUJC9e/fu9v/85z%2BO8fLycvuHH37omM/777/vdNzYsWPtQUFB9lGjRtkzMjKcjtu0aZO9U6dO9qCgIPvatWudjquYY%2BfOne1xcXF2u91uP3v2rP3XX3%2Bt9DpGjx5tz8zMdOzz1FNP2YOCguydOnWyd%2BzY0b5y5UrH9cjNzbUPHz7cHhQUZB87dmyV12bQoEH2w4cPO23buXOn/ZZbbrEHBQXZX3rpJadt/fv3d8zlqaeesp8%2BfdrxGteuXevY9n//939V/pkAQFVY0wRUgxtvvFEffPCBQkJCHGN5eXnasWOHFi1apFGjRql3795avHixCgsLqzyHm5ubli1bphtuuMExFhwcrIULF0qSPvjgA2VkZEiSSkpKtHTpUknS/PnzNWzYMMcxNptNd911l6NhWrp0qcrKyiRJOTk5Sk5OliTNnTtX/v7%2BTscNHz5ct956qyTp4MGDVc5zyJAh6tGjh2POvr6%2BTtvr16%2Bvf/zjH/Lz83Ps8%2Bijj0qSysvLde%2B99%2Brhhx%2BWm9tv336aNm2q8ePHS5L279/vOE9ZWZm%2B/fZb2Ww2zZ49W%2B3atXP6On369NFdd90lSfrpp5%2BqnGunTp00f/58R0Nns9k0ZswYR2v23XffVXkcAFSF0ARUkw4dOuidd97Rv//9b02fPl3BwcFyd3d3bM/JydHrr7%2BuYcOGOW4Rneu2225Tp06dKo337t1brVu3Vnl5uT7//HNJUkJCgrKzs%2BXj46MBAwZUOZ9hw4bJzc1NGRkZjjDSrFkzffPNN9q3b5%2BCgoIqHXP27Fk1bNhQ0m9riapybjCsSseOHZ1ulUnSdddd5/j/qtYtVYS3vLw8x1j9%2BvW1fft27du3T3fccUelY%2Bx2u7y9vS841zvuuEM2m63S%2BPXXXy9JOnPmzAVfCwCci4XgQDW74YYbdMMNNygyMlKFhYWKj4/XV199pf/85z/KycnRzz//rKioKMXGxjodd/PNN5/3nB07dtSxY8d05MgRSXK0RaWlpRozZsx5j6tXr57Ky8t16NAhp/N7enrqxIkT2rdvn37%2B%2BWelpaUpNTVVBw4cUEFBgaTfWqGqVDRI53PttddWGmvQoIHj/5s2bVpp%2B7mL6X/Pw8NDOTk52rt3r44cOaJjx47p0KFDOnDggE6dOnXBuZ7bpJ2r4qnsZ8%2BePf8LAYDfITQBV5CXl5d69eqlXr16KSoqSk8//bQ%2B/PBD7d27Vz/%2B%2BKPTk8F//261c1U0KqdPn5b0/xuSkpISxcfHX3QeFcdJ0qFDh/T3v/9dO3bscAobDRs2VPfu3ZWZmamkpKTznutivwbGy8vrgtsrbssZkZWVpYULF%2Brjjz9WaWmp09fo0qWLzp49e8FbbOeGtarYeR8MgEtAaAJMeu655/TNN9/ovvvu05QpU867n6enp1544QV98sknKi0t1eHDh51CU0XDU5WK21YVjyqoCCY33XSTNm7caHiuOTk5Gjt2rHJyctSqVSuNGjVKN954o66//nq1bt1aNptNs2bNumBoulqKi4s1YcIEpaamytfXV6NHj1bnzp0VEBCgtm3bql69elq8eDHrkgBcNYQmwKTi4mIdPXpU27dvv2Bokn5rc3x8fHTy5MlKv0al4pZbVSpCTIcOHST99kgA6bfHB5SVlVV5e8tut2v37t1q2bKlWrVqpQYNGmjDhg3KycmRr6%2BvNmzYUOWvcqlYbO5q27dvV2pqqurXr6/Y2NhKC8ElVbk2DACuFBaCAyZVvHPthx9%2BuGjr89VXX%2BnkyZPy9fWt9PTwnTt3Op49dK7PP/9cJ06cUIMGDRQWFiZJ6tGjhxo1aqT8/Pzzfs0tW7ZowoQJGjJkiCNcHDt2TJLUqlWrKgNTSkqK9u7dK8n1630q5urj41NlYMrOztYXX3whyfVzBWANhCbApF69emnw4MGSpGeeeUbz5s1z/MCvUFxcrA0bNmjmzJmSpKioqEpPoy4oKNDUqVN14sQJx9ju3bs1e/ZsSb89GLLirfPe3t6Ot/HPmzdPGzZscFqftH37ds2ZM0fSb48IaNu2raT//66xpKQkbdu2zbG/3W7Xzp07FRER4Vg7dL5HI1wtFXM9deqU/vWvfzmtP9q7d68mTZrkeBinq%2BcKwBq4PQdUg%2BjoaHl7e%2Bvf//63Vq9erdWrV6tVq1Zq1qyZiouLdeTIEZWUlMjd3V2zZs3SQw89VOkc7dq104EDBzRw4EAFBQWpoKDA8W65e%2B65R4899pjT/pMnT1ZaWpref/99Pf3003r55ZfVunVrZWRkKDMzU9JvT%2B9%2B8cUXHceMHDlS77zzjo4ePaoZM2bouuuuU9OmTXXixAnl5OTI3d1dt956q%2BLi4lx%2Bmy4sLEzBwcFKSEjQ/PnztWLFCrVo0UJZWVnKyMiQzWZTz5499b///U%2BZmZmy2%2B1VPl4AAKoLoQmoBg0aNNBLL72kMWPGaOvWrdq9e7cyMjKUlJQkLy8vtW/fXr1799bIkSMdDcrvdenSRdHR0VqyZIm%2B%2B%2B471a9fX7feeqtGjx7teIjjuWw2m%2BbOnavBgwfrvffe0969e3XgwAF5eHioa9euuueeexQeHu70DrKGDRtq/fr1WrFihT7//HMdO3ZM2dnZatmype644w5NmDBB3t7eGjhwoJKSkpSenq5WrVpdset2IfXq1dOqVau0Zs0affjhh0pLS9NPP/0kPz8/3XXXXRozZoxuuukmhYaG6uTJk4qPj7/oM6QAwAx%2B9xzgYhW/s23o0KGKjo529XQAAOfBmiYAAAADCE0AAAAGEJoAAAAMIDQBAACXy83N1aBBg7R79%2B7z7rNjxw4NHTpUXbt21ZAhQxy/xLzCihUr1LdvX3Xt2lXjxo3ToUOHqnWOhCbAxV566SUdPHiQReAALOu7775TeHi4fv755/Puc%2BTIEUVGRioqKkrffvutIiMjNXPmTMfjUTZt2qQ1a9Zo5cqV2r17t2666SbNmDGjWn/HJKEJAABctszMTP34449OHxXPijNi06ZNevzxx/WnP/3povt1795dAwcOVP369XXXXXepR48eio2NlSS9//77euihhxQYGCgPDw/NmjVL6enpF2yuLlXdfU4TD7mr%2Bdq3l5KTpcBA6fBhV88GF3LO08YBmOTKn09X4GvHLlmimJgYp7Hp06crMjLS0PG9e/fW0KFDVb9%2B/QsGp5SUFAUFBTmNdejQwfG7OVNSUjR58mTHNnd3d7Vr105JSUm67bbbjL6cC6q7oQk1n6%2BvVK/eb/8FYJ7NJvHoPVxl4eHhjt%2BLWcHPz8/w8Ub3zc/Pl5eXl9OYp6enCgoKDG2vDoQmAABw2fz9/eXv73/Fv46Xl5eKioqcxoqKihy/x/Ni26sDa5oAALAKN7fq/7hKgoKClJyc7DSWkpKiwMBASVJgYKDT9tLSUh05cqTSLT0zCE0AAFhFLQ5Nw4YNU1xcnLZu3aqysjJt3bpVcXFxuvfeeyVJI0aM0Nq1a5WUlKTi4mItWrRIzZs3V/fu3attDoQmAABQIwUHB2vz5s2SpICAAL366qtavny5evTooWXLlmnp0qVq3769JGnkyJGaOHGipk2bpttuu0379%2B/X8uXL5e7uXm3zqbu/sJd3z9V8wcFSfLzUrZuUkODq2eBCePdc7cBC8NrBlT%2BfPDyq/5zFxdV/zhqKpgkAAMAA3j0HAIBVXMU1SHURoQkAAKsgNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJnC1QMAADCApgkAAKugaTKF0AQAgFUQmkzh6gEAABhA0wQAgFXQNJlCaAIAAC6Tk5OjZ599VnFxcapXr56GDRumJ598UvXrO0eUiIgIfffdd05jBQUFCg8P1wsvvKDs7Gz16tVL3t7eju1NmzbVZ599Vm1zJTQBAGAVNbBpmjlzplq0aKEvv/xS2dnZmjJlilatWqWIiAin/d58802nz9evX6%2BYmBhNnz5dkpSYmKjrrruuWkPS7xGaAACwiisQmjIzM5WVleU05ufnJ39//4see/ToUcXFxWnnzp3y8vJSmzZtNHXqVL388suVQtO5Dh06pLlz52rlypWOr5OYmKjOnTubezEXQWgCAACXLTY2VjExMU5j06dPV2Rk5EWPTU5Olq%2Bvr1q0aOEYCwgIUHp6uk6fPq3GjRtXedzf/vY3DR8%2BXN27d3eMJSYm6tSpU7rnnnuUnZ2tLl266Mknn1SHDh0u85VVRmgCAMAqrkDTFB4errCwMKcxPz8/Q8fm5%2BfLy8vLaazi84KCgipD07fffqt9%2B/YpOjraabxx48bq0KGDJk%2BerAYNGuiVV17RpEmTtHXrVjVq1OhSXtJ5EZoAAMBl8/f3N3Qrrire3t4qLCx0Gqv43MfHp8pjYmNjNWTIkErBbNGiRU6fz549Wxs2bNC3336r/v37X9b8fq/mrQgDAABXhptb9X%2BYEBgYqJMnTyo7O9sxlpqaqpYtW1bZDpWVlenTTz/VsGHDnMbz8vK0cOFCHT9%2B3DF29uxZlZWVydPT09Qcz0VoAgDAKmpYaGrXrp1CQkI0f/585eXlKS0tTcuWLdPIkSOr3P/gwYMqLi5Wt27dnMYbNmyo//3vf1q4cKHOnDmj/Px8zZ07V61bt3Za92QWoQkAALjMkiVLVFZWpgEDBmjUqFHq06ePpk6dKkkKDg7W5s2bHfumpaWpSZMm8vDwqHSeZcuWqby8XAMHDlSfPn2UlZWlFStWyN3dvdrmarPb7fZqO1tNYrO5ega4mOBgKT5e6tZNSkhw9WxwIeXlrp4BjLDZpDr6Lb1OceXPp8GDq/%2Bc27ZV/zlrKBaCAwBgFTXw4Za1CVcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFK4eAACAATRNAABYBU2TKYQmAACsgtBkClcPAADAAJomAACsgqbJFJddvfT0dAUHBys9Pb3Sto0bNyosLMwFswIAoA5zc6v%2BD5NycnI0depUde/eXaGhoZo3b57Kysqq3DciIkJdunRRcHCw42Pnzp2SpLNnz2rhwoXq2bOngoODNWXKFGVmZpqe37lcFppatWqlhIQEtWrVylVTAAAALjZz5kx5e3vryy%2B/1Pr167Vr1y6tWrWqyn1/%2BOEHrVy5UgkJCY6Pvn37SpJee%2B01ff3119qwYYO%2B/PJLeXp66plnnqnWubrs9tyxY8c0YMAAffrppyouLtbzzz%2BvH374Qa1bt1ZoaOglnSszM1NZWVlOY37t28vf17c6p4zq1qmT838BAFfWFbg9V%2BXPYD8/%2Bfv7X/TYo0ePKi4uTjt37pSXl5fatGmjqVOn6uWXX1ZERITTvmlpaTp16pRuvPHGKs/1wQcf6PHHH9e1114rSfrrX/%2Bq3r17Ky0tTW3atLnMV%2BfM5WuaysrK9Nhjj6lv375688039fPPP2vy5Mlyu4Q/2NjYWMXExDiNTY%2BKUmRUVHVPF1fCO%2B%2B4egZA3WGzuXoGsJgqfwZPn67IyMiLHpucnCxfX1%2B1aNHCMRYQEKD09HSdPn1ajRs3downJibKx8dHf/rTn5SYmKjmzZtr4sSJGjlypM6cOaNffvlFQUFBjv2bN2%2BuJk2a6ODBg3UnNGVmZurEiRN64okn5OHhocDAQE2aNEn/%2Bte/DJ8jPDy80hoov6FDpUs4B1ygU6ffAtNDD0lJSa6eDS7ku%2B9cPQMYYbNJdrurZ4GLcWWwvQJNU5U/g/38DB2bn58vLy8vp7GKzwsKCpxCU0lJibp27ao//elPCgwM1O7duxUZGSkfHx8FBwdLkry9vZ3O5enpqfz8/Et%2BTefj8tAUHx%2Bvpk2bytPT0zHWtm3bSzqHv79/5Rrw8OHqmB6uhqQkKSHB1bMAgLrvCoSmKn8GG%2BTt7a3CwkKnsYrPfXx8nMaHDx%2Bu4cOHOz7v3bu3hg8fro8%2B%2Bkg9e/Z0OrZCUVFRpfOY4fL3Hnbv3l25ublOSfCXX35x4YwAAMDVEBgYqJMnTyo7O9sxlpqaqpYtW6pRo0ZO%2B65fv14fffSR01hJSYk8PDzUpEkTtWjRQikpKY5tWVlZOnnypNMtO7NcHpr8/f3Vvn17vfjiiyosLNTRo0f11ltvuXpaAADUPTXskQPt2rVTSEiI5s%2Bfr7y8PKWlpWnZsmUaOXJkpX3z8vI0d%2B5c7d%2B/X%2BXl5friiy/03//%2BV%2BHh4ZKk%2B%2B%2B/X6%2B99prS0tKUl5en%2BfPn69Zbb73ku1cX4vLQ5ObmpjfeeEOZmZnq2bOnIiIiNGDAAFdPCwAAXAVLlixRWVmZBgwYoFGjRqlPnz6aOnWqJCk4OFibN2%2BWJE2YMEFjx47V9OnTFRwcrOjoaC1cuFDdu3eXJE2bNk39%2BvXTmDFj1K9fPxUXF%2Buf//xntc7VZrfX0VWDvIOk5gsOluLjpW7dWNNU05WXu3oGMIKF4LWDK38%2BLVhQ/eecPbv6z1lDuXwhOAAAuEr4NSqmcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpM4eoBAAAYQNMEAIBV0DSZQmgCAMAqCE2mcPUAAAAMoGkCAMAqaJpMITQBAGAVhCZTuHoAAAAG0DQBAGAVNE2mcPUAAAAMoGkCAMAqaJpMITQBAGAVhCZTuHoAAAAG0DQBAGAVNE2mcPUAAAAMoGkCAMAqaJpMITQBAGAVNTA05eTk6Nlnn1VcXJzq1aunYcOG6cknn1T9%2BpUjyrvvvqtVq1YpMzNT/v7%2BGj9%2BvMaMGSNJKi8vV0hIiOx2u2w2m%2BOYr7/%2BWt7e3tUyV0ITAABwmZkzZ6pFixb68ssvlZ2drSlTpmjVqlWKiIhw2m/79u36xz/%2BoRUrVuiWW27R3r179eijj6p58%2BYaPHiwUlJSVFpaqvj4eDVo0OCKzJXQBACAVVyBpikzM1NZWVlOY35%2BfvL397/osUePHlVcXJx27twpLy8vtWnTRlOnTtXLL79cKTRlZGRo8uTJ6tq1qyQpODhYoaGh2rNnjwYPHqzExER17NjxigUmidAEAABMiI2NVUxMjNPY9OnTFRkZedFjk5OT5evrqxYtWjjGAgIClJ6ertOnT6tx48aO8YrbcBVycnK0Z88ezZ49W5KUmJio4uJijRgxQsePH1dAQIBmzZqlbt26mXl5TghNAABYxRVomsLDwxUWFuY05ufnZ%2BjY/Px8eXl5OY1VfF5QUOAUms6VlZWlxx57TJ07d9Y999wjSfL09NTNN9%2BsqKgoNWnSROvWrdMjjzyizZs3q02bNpf6sqpEaAIAwCquQGjy9/c3dCuuKt7e3iosLHQaq/jcx8enymP27t2rqKgode/eXQsWLHAsGH/qqaec9nvkkUe0ceNG7dixQ2PHjr2s%2Bf1ezVtGDwAALCEwMFAnT55Udna2Yyw1NVUtW7ZUo0aNKu2/fv16TZw4URMmTNCiRYuc1i8tXrxY%2B/fvd9q/pKREHh4e1TZfQhMAAFbh5lb9Hya0a9dOISEhmj9/vvLy8pSWlqZly5Zp5MiRlfbdtm2bnn/%2BeS1dulQPP/xwpe0//fST5s2bp6ysLJWUlCgmJkZ5eXkaNGiQqTmei9AEAABcZsmSJSorK9OAAQM0atQo9enTR1OnTpX02zvkNm/eLEmKiYnR2bNnNWPGDAUHBzs%2BnnvuOUnSggUL1LZtW917770KDQ1VXFyc3n77bfn6%2BlbbXG12u91ebWerSc55sBVqqOBgKT5e6tZNSkhw9WxwIeXlrp4BjLDZpDr6Lb1OceXPp127qv%2Bct99e/eesoVgIDgCAVdTAJ4LXJlw9AAAAA2iaAACwCpomU7h6AAAABtA0AQBgFTRNphCaAACwCkKTKVw9AAAAA2iaAACwCpomU7h6AAAABtA0AQBgFTRNphCaAACwCkKTKVw9AAAAA2iaAACwCpomU7h6AAAABtA0AQBgFTRNphCaAACwCkKTKVw9AAAAA2iaAACwCpomU7h6AAAABtA0AQBgFTRNphCaAACwCkKTKVw9AAAAA2iaAACwCpomU7h6AAAABtA0AQBgFTRNphCaAACwCkKTKVw9AAAAA2iaAACwCpomUwhNAABYBaHJFK4eAACAATRNAABYBU2TKVw9AAAAA2iaAACwCpomUwhNAABYBaHJFK4eAACAATRNAABYBU2TKVw9AAAAA2iaAACwCpomUwhNAABYBaHJFK4eAACAATRNAABYBU2TKVw9AAAAA2iaAACwCpomU7h6AABYhZtb9X%2BYlJOTo6lTp6p79%2B4KDQ3VvHnzVFZWVuW%2BO3bs0NChQ9W1a1cNGTJEn3/%2BudP2FStWqG/fvuratavGjRunQ4cOmZ7fuQhNAADAZWbOnClvb299%2BeWXWr9%2BvXbt2qVVq1ZV2u/IkSOKjIxUVFSUvv32W0VGRmrmzJnKyMiQJG3atElr1qzRypUrtXv3bt10002aMWOG7HZ7tc2V0AQAgFVcgaYpMzNTP/74o9NHZmamoekcPXpUcXFx%2Bstf/iIvLy%2B1adNGU6dO1bp16yrtu2nTJnXv3l0DBw5U/fr1ddddd6lHjx6PAJPAAAAbXElEQVSKjY2VJL3//vt66KGHFBgYKA8PD82aNUvp6enavXt3tV2%2Burumqbzc1TOAUd995%2BoZ4GJYB1HzBQdL8fFSSIiUkODq2eBCqrH5qAliY2MVExPjNDZ9%2BnRFRkZe9Njk5GT5%2BvqqRYsWjrGAgAClp6fr9OnTaty4sWM8JSVFQUFBTsd36NBBSUlJju2TJ092bHN3d1e7du2UlJSk22677bJe2%2B/V3dAEAACc2GWr9nOGh4crLCzMaczPz8/Qsfn5%2BfLy8nIaq/i8oKDAKTRVta%2Bnp6cKCgoMba8OhCYAACziStyE8ff3l7%2B//2Ud6%2B3trcLCQqexis99fHycxr28vFRUVOQ0VlRU5NjvYturA507AABwicDAQJ08eVLZ2dmOsdTUVLVs2VKNGjVy2jcoKEjJyclOYykpKQoMDHSc69ztpaWlOnLkSKVbemYQmgAAsIjy8ur/MKNdu3YKCQnR/PnzlZeXp7S0NC1btkwjR46stO%2BwYcMUFxenrVu3qqysTFu3blVcXJzuvfdeSdKIESO0du1aJSUlqbi4WIsWLVLz5s3VvXt3c5M8B6EJAAC4zJIlS1RWVqYBAwZo1KhR6tOnj6ZOnSpJCg4O1ubNmyX9tkD81Vdf1fLly9WjRw8tW7ZMS5cuVfv27SVJI0eO1MSJEzVt2jTddttt2r9/v5YvXy53d/dqm6vNXp0PMKhJ6ujLqnNsNv6sagPePVfzVbx7rls33j1X07nwe15xcfWf08Oj%2Bs9ZU7EQHAAAi%2BBpPObwz0cAAAADaJoAALAImiZzaJoAAAAMoGkCAMAiaJrMITQBAGARhCZzuD0HAABgAE0TAAAWQdNkDk0TAACAATRNAABYBE2TOYQmAAAsgtBkDrfnAAAADKBpAgDAImiazKFpAgAAMICmCQAAi6BpMofQBACARRCazOH2HAAAgAE0TQAAWARNkzmEJgAALILQZA635wAAAAygaQIAwCJomsyhaQIAADCApgkAAIugaTKH0AQAgEUQmszh9hwAAIABNE0AAFgETZM5NE0AAAAG0DQBAGARNE3mEJoAALAIQpM53J4DAAAwgKYJAACLoGkyh6YJAADAAJomAAAsgqbJHEITAAAWQWgyh9tzAAAABtA0AQBgETRN5tA0AQAAGEDTBACARdA0mUNoAgDAIghN5nB7DgAAwACaJgAALIKmyRyaJgAAAANomgAAsAiaJnMITQAAWERtC00FBQWaO3euPvvsM5WVlWnAgAGaM2eOfHx8qtx/27ZtWrZsmdLS0uTr66v7779fU6dOlZvbbzfWhgwZovT0dMfnkrR%2B/XoFBAQYmg%2BhCQAA1Ehz587ViRMntG3bNp09e1YzZ85UdHS05syZU2nfH374QU888YT%2B%2Bc9/ql%2B/fjp8%2BLAmT54sb29vPfzww8rLy9Phw4f16aef6rrrrrus%2BbCmCQAAiygvr/6PzMxM/fjjj04fmZmZpudaWFioLVu2aMaMGfL19VWzZs30%2BOOPa%2BPGjSosLKy0//Hjx/Xggw%2Bqf//%2BcnNzU0BAgAYNGqQ9e/ZI%2Bi1U%2Bfr6XnZgkmiaAACACbGxsYqJiXEamz59uiIjIy96bFFRkTIyMqrcVlhYqNLSUgUFBTnGAgICVFRUpCNHjuiGG25w2n/w4MEaPHiw07m/%2BOILDR06VJKUmJgoLy8vjR07VsnJybruuusUGRmp/v37G36thCYAACziSqxpCg8PV1hYmNOYn5%2BfoWP37dun8ePHV7ktKipKkuTt7e0Y8/LykiTl5%2Bdf8Lx5eXmKioqSp6enJk6cKEmy2Wzq0qWL/vznP6tVq1b6%2BOOPFRkZqbVr16pr166G5ktoAgDAIq5EaPL395e/v/9lHRsaGqqDBw9WuW3//v165ZVXVFhY6Fj4XXFbrmHDhuc956FDhzRjxgw1a9ZMq1evduwbERHhtN%2BwYcP03//%2BV9u2bTMcmljTBAAAapz27dvL3d1dKSkpjrHU1FS5u7urXbt2VR6zY8cOPfDAA%2BrTp49WrlypJk2aOLatXLlSu3btctq/pKREHh4ehudEaAIAwCKuxELwK8XLy0tDhgxRdHS0cnNzlZubq%2BjoaN1zzz3y9PSstP/evXs1bdo0zZ49W08%2B%2BaTq13e%2BmXbixAn97W9/U1pamsrKyrR%2B/XolJCTovvvuMzwnm91ut5t%2BZTVRHX1ZdY7Nxp9VbeDGv69qvOBgKT5e6tZNSkhw9WxwIS78nvd//1f95xw0qPrPWSEvL08LFy7UZ599ptLSUg0YMEDPPvusY53T3XffraFDh%2BqPf/yj/vjHP%2BqLL75wrHuqEBISojfffFMlJSWKjo7WRx99pDNnzqhDhw76y1/%2BotDQUMPzITTBtQhNtQOhqeYjNNUeLvyet21b9Z/znDes1XksBAcAwCJq2xPBaxr%2B%2BQgAAGAATRMAABZB02QOTRMAAIABNE0AAFgETZM5hCYAACyC0GQOt%2BcAAAAMoGkCAMAiaJrMITQBAGARhCZzuD0HAABgAE0TAAAWQdNkDk0TAACAATRNAABYBE2TOYQmAAAsgtBkDrfnAAAADKBpAgDAImiazKFpAgAAMICmCQAAi6BpMofQBACARRCazOH2HAAAgAE0TQAAWARNkzk0TQAAAAbQNAEAYBE0TeYQmgAAsAhCkzncngMAADCApgkAAIugaTKHpgkAAMAAmiYAACyCpskcQhMAABZBaDKH23MAAAAG0DQBAGARNE3m0DQBAAAYQNMEAIBF0DSZQ2gCAMAiCE3mcHsOAADAAJomAAAsgqbJHJomAAAAA2iaAACwCJomcwhNAABYBKHJHG7PAQAAGEDTBACARdA0mUPTBAAAYMAlhaZjx46pY8eOOnbs2AX32717tzp27HjZkxo3bpyWLl162ccDAIDKysur/%2BNKKigo0OzZsxUaGqqQkBA98cQTys/PP%2B/%2Bc%2BbMUefOnRUcHOz4iI2NdWxfsWKF%2Bvbtq65du2rcuHE6dOjQJc2HpgkAAIuobaFp7ty5OnHihLZt26ZPPvlEJ06cUHR09Hn3T0xM1Ny5c5WQkOD4CA8PlyRt2rRJa9as0cqVK7V7927ddNNNmjFjhux2u%2BH5XHZoio%2BP1/jx49W7d2916dJF999/v/bu3eu0zxtvvKF%2B/fqpb9%2B%2Bevnll1VSUuLY9uGHH2ro0KEKCQnR/fffr6%2B%2B%2BupypwIAAOqYwsJCbdmyRTNmzJCvr6%2BaNWumxx9/XBs3blRhYWGl/UtKSvTTTz%2Bpc%2BfOVZ7v/fff10MPPaTAwEB5eHho1qxZSk9P1%2B7duw3P6bIWghcXF2vKlCmaMWOGRo8eraKiIj399NP6%2B9//rnfeecex308//aStW7cqOztbERER8vb21rRp07Rjxw7NmTNHr732mrp166adO3cqMjJS77//vgIDAy95PpmZmcrKynIa82veXP7%2B/pfz8gD8XnCwq2eAi%2BnUyfm/QBWuRDNU5c9gPz9DP4OLioqUkZFR5bbCwkKVlpYqKCjIMRYQEKCioiIdOXJEN9xwg9P%2BSUlJKisr05IlS/Tdd9%2BpUaNGGjFihCIiIuTm5qaUlBRNnjzZsb%2B7u7vatWunpKQk3XbbbYZe62WFJnd3d8XGxuoPf/iDiouLdfz4cfn6%2BioxMdGxj81m03PPPScfHx/5%2BPgoIiJCb731lqZNm6a1a9dq9OjR6tGjhySpf//%2BCgsL03vvvadnn332kucTGxurmJgYp7Hp06YpcsaMy3l5uNpsNlfPABcTH%2B/qGcCoc/7hClwNVf4Mnj5dkZGRFz123759Gj9%2BfJXboqKiJEne3t6OMS8vL0mqcl3TmTNndOutt2rcuHH6xz/%2BoQMHDmjatGlyc3NTRESE8vPzHcdX8PT0VEFBwUXnWeGyQpObm5t27dqlyZMnq6CgQB06dFD9%2BvWd7gs2btxYjRs3dnx%2B7bXXOtLk8ePHFRcXp3fffdex/ezZs4aT3u%2BFh4crLCzMacyveXPpEu5TwkVsNv6caoOQEFfPABfTqdNvgemhh6SkJFfPBhfiwn%2BEXImmqcqfwX5%2Bho4NDQ3VwYMHq9y2f/9%2BvfLKKyosLJSPj48kOW7LNWzYsNL%2BvXr1Uq9evRyf33zzzZowYYK2bt2qiIgIeXl5qaioyOmYoqIix7mNuKzQlJOTo7lz5%2Bq9995z3Dt86623dPjwYcc%2BeXl5KigocCTEtLQ0XXfddZKkli1bavjw4Xr00Ucd%2B6enp8vT0/NypiN/f//KNSA/iIHqk5Dg6hnAqKQk/rxwXlciNFX5M7gatG/fXu7u7kpJSdEtt9wiSUpNTXXcVvu97du3Kzs7Ww8%2B%2BKBjrKSkxJEtAgMDlZycrP79%2B0uSSktLdeTIEafbfxdzWQvBk5KS5Obm5pjI3r17tXr1aqeF3mfPntVLL72kgoICpaamauXKlY4XMmrUKK1evVrff/%2B9pN9Wu99///3673//eznTAQAAdYyXl5eGDBmi6Oho5ebmKjc3V9HR0brnnnuqLFnsdrsWLFigXbt2yW63KyEhQatXr3a8e27EiBFau3atkpKSVFxcrEWLFql58%2Bbq3r274TldVtPUs2dPPfTQQxozZozKy8vVunVrjRs3TosWLVJ2drYkydfXV76%2BvurXr598fHz04IMPasyYMZKkO%2B%2B8UwUFBXr66aeVnp4uX19fTZw4UePGjbuc6QAAAANq2xPB58yZo4ULF2ro0KEqLS3VgAEDnNY%2B33333Ro6dKj%2B%2BMc/atCgQZo9e7aef/55ZWRkqHnz5oqMjNS9994rSRo5cqTOnDmjadOmKTc3V126dNHy5cvl7u5ueD42%2B6U8oKA2qaMvq85hTVPt4MYj3Wq84ODf1sp068btuZrOhd/z/vrX6j/nvHnVf86ait89BwCARdS2pqmmITQBAGARhCZz6NwBAAAMoGkCAMAiaJrMITQBAGARhCZzuD0HAABgAE0TAAAWQdNkDk0TAACAATRNAABYBE2TOYQmAAAsgtBkDrfnAAAADKBpAgDAImiazKFpAgAAMICmCQAAi6BpMofQBACARRCazOH2HAAAgAE0TQAAWARNkzk0TQAAAAbQNAEAYBE0TeYQmgAAsAhCkzncngMAADCApgkAAIugaTKHpgkAAMAAmiYAACyCpskcQhMAABZBaDKH23MAAAAG0DQBAGARNE3m0DQBAAAYQNMEAIBF0DSZQ2gCAMAiCE3mcHsOAADAAJomAAAsgqbJHJomAAAAA2iaAACwCJomcwhNAABYBKHJHG7PAQAAGEDTBACARdA0mUPTBAAAYABNEwAAFkHTZA6hCQAAiyA0mcPtOQAAAANomgAAsAiaJnNomgAAAAygaQIAwCJqW9NUUFCguXPn6rPPPlNZWZkGDBigOXPmyMfHp9K%2Bzz33nLZs2eI0VlRUpJ49e2rlypUqLy9XSEiI7Ha7bDabY5%2Bvv/5a3t7ehuZDaAIAwCJqW2iaO3euTpw4oW3btuns2bOaOXOmoqOjNWfOnEr7vvDCC3rhhRccn3/11VeaNWuWnnrqKUlSSkqKSktLFR8frwYNGlzWfLg9BwAAapzCwkJt2bJFM2bMkK%2Bvr5o1a6bHH39cGzduVGFh4QWPzc3N1eOPP66//vWvCgwMlCQlJiaqY8eOlx2YJJomAAAs40o0TZmZmcrKynIa8/Pzk7%2B//0WPLSoqUkZGRpXbCgsLVVpaqqCgIMdYQECAioqKdOTIEd1www3nPW90dLQ6d%2B6sYcOGOcYSExNVXFysESNG6Pjx4woICNCsWbPUrVu3i86zAqEJAACLuBKhKTY2VjExMU5j06dPV2Rk5EWP3bdvn8aPH1/ltqioKElyWm/k5eUlScrPzz/vOdPS0rR582Z98MEHTuOenp66%2BeabFRUVpSZNmmjdunV65JFHtHnzZrVp0%2Baic5UITQAAwITw8HCFhYU5jfn5%2BRk6NjQ0VAcPHqxy2/79%2B/XKK6%2BosLDQsfC74rZcw4YNz3vODRs2KDg4uFITVbG2qcIjjzyijRs3aseOHRo7dqyh%2BRKaAACwiCvRNPn7%2Bxu6FXep2rdvL3d3d6WkpOiWW26RJKWmpsrd3V3t2rU773GffPKJHn744Urjixcv1uDBg3XjjTc6xkpKSuTh4WF4TiwEBwAANY6Xl5eGDBmi6Oho5ebmKjc3V9HR0brnnnvk6elZ5TG//vqrUlNT1aNHj0rbfvrpJ82bN09ZWVkqKSlRTEyM8vLyNGjQIMNzIjQBAGAR5eXV/3ElzZkzR%2B3atdPQoUN15513qnXr1nruuecc2%2B%2B%2B%2B269/vrrjs%2BPHTsmSWrRokWlcy1YsEBt27bVvffeq9DQUMXFxentt9%2BWr6%2Bv4fnY7Ha73cTrqbnq6Muqc2w2/qxqAzf%2BfVXjBQdL8fFSt25SQoKrZ4MLceH3vNtvr/5z7tpV/eesqfhOCAAAYAALwQEAsIja9kTwmoamCQAAwACaJgAALIKmyRxCEwAAFkFoMofbcwAAAAbQNAEAYBE0TebQNAEAABhA0wQAgEXQNJlDaAIAwCIITeZwew4AAMAAmiYAACyCpskcmiYAAAADaJoAALAImiZzCE0AAFgEockcbs8BAAAYQNMEAIBF0DSZQ9MEAABgAE0TAAAWQdNkDqEJAACLIDSZw%2B05AAAAA2iaAACwCJomc2iaAAAADKBpAgDAImiazCE0AQBgEYQmc7g9BwAAYABNEwAAFkHTZA5NEwAAgAE0TQAAWARNkzmEJgAALILQZA635wAAAAygaQIAwCJomsyhaQIAADCApgkAAIugaTKH0AQAgEUQmszh9hwAAIABNE0AAFgETZM5hCYAACyC0GQOt%2BcAAAAMoGkCAMAiaJrMoWkCAAAwgKYJAACLoGkyh9AEAIBFEJrM4fYcAACo0QoLCxUeHq6NGzdecL99%2B/bpgQceUHBwsMLCwvTBBx84bd%2B0aZMGDRqkrl276v7771dCQsIlzYPQBACARZSXV//HlZacnKwxY8Zo7969F9zv1KlTevTRRzV8%2BHDt2bNH8%2BbN04IFC/T9999Lknbv3q25c%2BfqpZde0p49ezRs2DBNmTJFhYWFhudCaAIAADXSrl27NGHCBN13331q1arVBff95JNP5OvrqzFjxqh%2B/fq6/fbbNXToUK1bt06S9MEHH%2Bjuu%2B9WSEiI3N3dNXHiRDVt2lRbt241PB/WNAEAYBFXohnKzMxUVlaW05ifn5/8/f0vemxRUZEyMjKq3Obn56dOnTrp888/l4eHh95%2B%2B%2B0Lnis5OVlBQUFOYx06dND69eslSSkpKRoxYkSl7UlJSRedZ4W6G5psNlfPABeRmZmp2NhYhYeHG/rLBRey2109A1xEZmamYpcuVfjHH/P3Ced1Jf4qL10aq5iYGKex6dOnKzIy8qLH7tu3T%2BPHj69y26uvvqqBAwcankd%2Bfr68vLycxjw9PVVQUGBouxF1NzShxsvKylJMTIzCwsL4Jg%2BYxN8nuEp4eLjCwsKcxvz8/AwdGxoaqoMHD1bLPLy8vHTmzBmnsaKiIvn4%2BDi2FxUVVdretGlTw1%2BD0AQAAC6bv79/jQjqQUFB%2Bvrrr53GUlJSFBgYKEkKDAxUcnJype19%2B/Y1/DVYCA4AAGq9QYMGKTs7W6tWrVJpaam%2B%2BeYbbdmyxbGOaeTIkdqyZYu%2B%2BeYblZaWatWqVcrJydGgQYMMfw1CEwAAqJXuvvtuvf7665Kkpk2b6q233tLHH3%2Bs0NBQPfPMM3rmmWd02223SZJuv/12zZkzR88//7xuvfVWffjhh1qxYoV8fX0Nfz2b3c4KT7gGC8GB6sPfJ%2BDKIzQBAAAYwO05AAAAAwhNAAAABhCaAAAADCA0AQAAGEBoAgAAMIDQBAAAYAChCQAAwABCEwAAgAGEJgAAAAMITQAAAAYQmgAAAAyo7%2BoJwBrCwsJks9kuuM%2Bnn356lWYD1G4xMTEX3Wf69OlXYSaAtRCacFVERkZKkn788Ud9%2BumnmjRpktq2basTJ07o7bff1oABA1w8Q6D22L179wW3X%2BwfKAAuj81ut9tdPQlYx7Bhw7R48WIFBAQ4xo4ePapHH31U27Ztc%2BHMAAC4MNY04apKS0tT27ZtncZatGihzMxMF80IqN1SU1P14osvavr06fr111%2B1du1aV08JqLMITbiqOnfurIULF6qkpESSVFhYqLlz5yokJMTFMwNqn6%2B//loPPPCAfv31V/3vf/9TUVGRXn31Vb3xxhuunhpQJ3F7DlfVoUOH9Nhjj%2BnEiRNq2rSpcnNzdf311%2BuNN97Qtdde6%2BrpAbXKiBEjNGPGDPXr1089evTQnj17lJiYqJkzZ/LGCuAKYCE4ropffvlFLVu2lKenp1auXKmMjAwlJCQoJCRE/v7%2BIrsDl%2B7o0aPq27evpP%2B/%2BLtLly46deqUK6cF1FmEJlwVd911l%2BLj450ePWC322Wz2Rz/PXDggItnCdQurVq1Unx8vNPt7cTERFpb4AohNOGq%2BPDDDyXxLCagOj322GOaMmWKRo8erdLSUq1YsUJr1qzRn//8Z1dPDaiTWNMEALXYjh07tG7dOh0/flwtW7bUqFGjNHjwYFdPC6iTCE0AAAAG8MgBAKilysrK9Nprr%2BnOO%2B9UcHCwhg4dqnXr1rl6WkCdxZomAKil/vnPf%2BqTTz5RRESErr32Wv3888966623lJ%2Bfr0cffdTV0wPqHG7PAUAtdccdd2jNmjVq06aNYyw1NVWTJ0/WZ5995sKZAXUTt%2BcAoBbz8/Nz%2BrxVq1bKy8tz0WyAuo3QBAC11JgxY/Tcc885QlJRUZEWLlyo0aNHu3hmQN3E7TkAqGU6derkeDCsJLm5ualRo0bKz89XWVmZmjZtql27drl4lkDdw0JwAKhlVq9e7eopAJZE0wQAdUxubq6uueYaV08DqHNomgCglvr%2B%2B%2B/197//XRkZGSovL5cklZaWKjc3Vz/88IOLZwfUPSwEB4Ba6oUXXpCfn5969%2B6t9u3ba%2BzYsapXr55mzZrl6qkBdRKhCQBqqeTkZC1YsEBjxozR2bNnNWnSJC1evFhbtmxx9dSAOonQBAC1VOPGjeXp6ak2bdooOTlZktS1a1cdP37cxTMD6iZCEwDUUtdff73effddeXh4yNvbWwcOHFBqaqpsNpurpwbUSSwEB4BaKioqSlOmTFGvXr30yCOPaNSoUapXrx4PtwSuEB45AAC1THp6uuP/i4qK5O7urnr16ik7O1sHDx5Uz549dd1117lwhkDdRGgCgFqm4ongVbHb7bLZbDpw4MBVnhVQ9xGaAKCWMbLQm6YJqH6EJgAAAAN49xwAAIABhCYAAAADCE0AAAAGEJoAAAAMIDQBAAAYQGgCAAAwgNAEAABgwP8DLj/HjBFL7iAAAAAASUVORK5CYII%3D\" class=\"center-img\">\n",
       "</div>\n",
       "    <div class=\"row headerrow highlight\">\n",
       "        <h1>Sample</h1>\n",
       "    </div>\n",
       "    <div class=\"row variablerow\">\n",
       "    <div class=\"col-md-12\" style=\"overflow:scroll; width: 100%%; overflow-y: hidden;\">\n",
       "        <table border=\"1\" class=\"dataframe sample\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "<pandas_profiling.ProfileReport at 0x134d0f128>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  20800.000000  20800.000000\n",
       "mean   10399.500000      0.500625\n",
       "std     6004.587135      0.500012\n",
       "min        0.000000      0.000000\n",
       "25%     5199.750000      0.000000\n",
       "50%    10399.500000      1.000000\n",
       "75%    15599.250000      1.000000\n",
       "max    20799.000000      1.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     House Dem Aide: We Didn’t Even See C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>title     FLYNN: Hillary Clinton, Big Woman on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>title                     Why the Truth Might ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     15 Civilians Killed In Single US Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>title     Iranian woman jailed for fictional u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1   \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1   \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1   \n",
       "\n",
       "                                       combined_text  \n",
       "0  title     House Dem Aide: We Didn’t Even See C...  \n",
       "1  title     FLYNN: Hillary Clinton, Big Woman on...  \n",
       "2  title                     Why the Truth Might ...  \n",
       "3  title     15 Civilians Killed In Single US Air...  \n",
       "4  title     Iranian woman jailed for fictional u...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine columnt texts\n",
    "df['combined_text'] = df[['title', 'author', 'text']].apply(lambda x: ''.join(str(x)), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine columnt texts\n",
    "# df['combined_text'] = TextCleaner(custom_stopwords=['title', 'author', 'text']).transform(df['combined_text'])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['House', 'Dem', 'Aide:', 'We', 'Didn’t', 'Even', 'See', 'Comey’s', 'Letter', 'Until', 'Jason', 'Chaffetz', 'Tweeted', 'It']\",\n",
       " \"['FLYNN:', 'Hillary', 'Clinton,', 'Big', 'Woman', 'on', 'Campus', '-', 'Breitbart']\",\n",
       " \"['Why', 'the', 'Truth', 'Might', 'Get', 'You', 'Fired']\",\n",
       " \"['15', 'Civilians', 'Killed', 'In', 'Single', 'US', 'Airstrike', 'Have', 'Been', 'Identified']\",\n",
       " \"['Iranian', 'woman', 'jailed', 'for', 'fictional', 'unpublished', 'story', 'about', 'woman', 'stoned', 'to', 'death', 'for', 'adultery']\"]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['title'] = TextCleaner().transform(df['title'].astype(str))\n",
    "txt = df['title'].str.split().astype(str).tolist() #combined_text got 81% accuracy\n",
    "txt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tag import UnigramTagger, DefaultTagger\n",
    "# from nltk.corpus import treebank\n",
    "# tagger = DefaultTagger('NN')\n",
    "# #tagger.tag(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "\n",
    "def fetch_universal_sentence_embeddings(messages, verbose=0):\n",
    "    \"\"\"Fetches universal sentence embeddings from Google's\n",
    "    research paper https://arxiv.org/pdf/1803.11175.pdf.\n",
    "    \n",
    "    INPUTS:\n",
    "    RETURNS:\n",
    "    \"\"\"\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed = hub.Module(module_url)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed(messages))\n",
    "        embeddings = list()\n",
    "        for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "            if verbose:\n",
    "                print(\"Message: {}\".format(messages[i]))\n",
    "                print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "                message_embedding_snippet = \", \".join(\n",
    "                    (str(x) for x in message_embedding[:3]))\n",
    "                print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "            embeddings.append(message_embedding)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = fetch_universal_sentence_embeddings(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05387789383530617,\n",
       " 0.006952833849936724,\n",
       " -0.057719238102436066,\n",
       " 0.016467709094285965,\n",
       " -0.08529816567897797,\n",
       " 0.007254021242260933,\n",
       " 0.08881591260433197,\n",
       " 0.007081518415361643,\n",
       " -0.03469545766711235,\n",
       " -0.0006816966342739761]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.500625\n",
       "0    0.499375\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.array(embeddings), df.label.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05387789,  0.00695283, -0.05771924,  0.01646771, -0.08529817])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   38.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__C': [1, 2, 3, 4, 5], 'clf__random_state': [777]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test LinearSVC model as baseline\n",
    "\n",
    "params = {'clf__C':[1, 2, 3, 4, 5], # 1 best here  [.001, .01, .1, 1, 10, 100, 1000]\n",
    "          'clf__random_state': [777]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipeline, params, cv=5, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('clf',\n",
       "   LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
       "        intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "        multi_class='ovr', penalty='l2', random_state=777, tol=0.0001,\n",
       "        verbose=0))],\n",
       " 'clf': LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=777, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'clf__C': 2,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': True,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__loss': 'squared_hinge',\n",
       " 'clf__max_iter': 1000,\n",
       " 'clf__multi_class': 'ovr',\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': 777,\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.8994\n",
      "Validation Accuracy: 0.8875\n",
      "\n",
      "\n",
      "        Condition Positive:                        1511\n",
      "        Condition Negative:                        1609\n",
      "        Total Observations:                        3120\n",
      "\n",
      "        True Positive:                             1340\n",
      "        True Negative:                             1429\n",
      "        False Positive:                            180\n",
      "        False Negative                             171\n",
      "\n",
      "        True Positive Rate (recall):               88.68%\n",
      "        True Negative Rate (specificity):          88.81%\n",
      "        False Positive Rate (fall-out):            11.19%\n",
      "        False Negative Rate (miss rate):           11.32%\n",
      "\n",
      "        Positive Predictive Value (precision):     88.16%\n",
      "        Negative Predictive Value:                 89.31%\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(+) actual</th>\n",
       "      <th>(-) actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(+) predicted</th>\n",
       "      <td>1340</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-) predicted</th>\n",
       "      <td>171</td>\n",
       "      <td>1429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               (+) actual  (-) actual\n",
       "(+) predicted        1340         180\n",
       "(-) predicted         171        1429"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binary_confusion_matrix(y, y_hat, as_pct=False, verbose=True):\n",
    "    cm = pd.DataFrame(confusion_matrix(y, y_hat),\n",
    "                      columns=['(+) actual', '(-) actual'],\n",
    "                      index=['(+) predicted', '(-) predicted'])\n",
    "    if as_pct:\n",
    "        cm = cm / cm.sum().sum()\n",
    "\n",
    "    P = cm['(+) actual'].sum()\n",
    "    N = cm['(-) actual'].sum()\n",
    "    total = P + N\n",
    "    TP = cm.loc['(+) predicted', '(+) actual']\n",
    "    FP = cm.loc['(+) predicted', '(-) actual']\n",
    "    TN = cm.loc['(-) predicted', '(-) actual']\n",
    "    FN = cm.loc['(-) predicted', '(+) actual']\n",
    "    TPR = TP / (TP + FN)          # recall/sensitivity\n",
    "    TNR = TN / (TN + FP)   # specificity\n",
    "    FPR = FP / (FP + TN)   # fall-out\n",
    "    FNR = FN / (FN + TP)   # miss rate\n",
    "    PPV = TP / (TP + FP)   # precision\n",
    "    NPV = TN / (TN + FN)   # neg predictive value\n",
    "\n",
    "    if verbose:\n",
    "        print('''\n",
    "        Condition Positive:                        %i\n",
    "        Condition Negative:                        %i\n",
    "        Total Observations:                        %i\n",
    "\n",
    "        True Positive:                             %i\n",
    "        True Negative:                             %i\n",
    "        False Positive:                            %i\n",
    "        False Negative                             %i\n",
    "\n",
    "        True Positive Rate (recall):               %.2f%%\n",
    "        True Negative Rate (specificity):          %.2f%%\n",
    "        False Positive Rate (fall-out):            %.2f%%\n",
    "        False Negative Rate (miss rate):           %.2f%%\n",
    "\n",
    "        Positive Predictive Value (precision):     %.2f%%\n",
    "        Negative Predictive Value:                 %.2f%%\n",
    "        ''' %(P, N, total,\n",
    "             TP, TN, FP, FN,\n",
    "             TPR*100, TNR*100, FPR*100, FNR*100,\n",
    "             PPV*100, NPV*100))\n",
    "\n",
    "    metrics = {'P': P, 'N': N, 'total': total,\n",
    "              'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN,\n",
    "              'TPR': TPR, 'TNR': TNR, 'FPR': FPR, 'FNR': FNR, 'PPV': PPV, 'NPV': NPV}\n",
    "\n",
    "    return cm, metrics\n",
    "\n",
    "\n",
    "yhat_val = grid.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, yhat_val)\n",
    "yhat_train = grid.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, yhat_train) \n",
    "\n",
    "print(f'''\n",
    "Training Accuracy: {round(train_acc, 4)}\n",
    "Validation Accuracy: {round(val_acc, 4)}\n",
    "''')\n",
    "\n",
    "_, __ = binary_confusion_matrix(y_val, yhat_val)\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearSVC in module sklearn.svm.classes:\n",
      "\n",
      "class LinearSVC(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  Linear Support Vector Classification.\n",
      " |  \n",
      " |  Similar to SVC with parameter kernel='linear', but implemented in terms of\n",
      " |  liblinear rather than libsvm, so it has more flexibility in the choice of\n",
      " |  penalties and loss functions and should scale better to large numbers of\n",
      " |  samples.\n",
      " |  \n",
      " |  This class supports both dense and sparse input and the multiclass support\n",
      " |  is handled according to a one-vs-the-rest scheme.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : string, 'l1' or 'l2' (default='l2')\n",
      " |      Specifies the norm used in the penalization. The 'l2'\n",
      " |      penalty is the standard used in SVC. The 'l1' leads to ``coef_``\n",
      " |      vectors that are sparse.\n",
      " |  \n",
      " |  loss : string, 'hinge' or 'squared_hinge' (default='squared_hinge')\n",
      " |      Specifies the loss function. 'hinge' is the standard SVM loss\n",
      " |      (used e.g. by the SVC class) while 'squared_hinge' is the\n",
      " |      square of the hinge loss.\n",
      " |  \n",
      " |  dual : bool, (default=True)\n",
      " |      Select the algorithm to either solve the dual or primal\n",
      " |      optimization problem. Prefer dual=False when n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-4)\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  multi_class : string, 'ovr' or 'crammer_singer' (default='ovr')\n",
      " |      Determines the multi-class strategy if `y` contains more than\n",
      " |      two classes.\n",
      " |      ``\"ovr\"`` trains n_classes one-vs-rest classifiers, while\n",
      " |      ``\"crammer_singer\"`` optimizes a joint objective over all classes.\n",
      " |      While `crammer_singer` is interesting from a theoretical perspective\n",
      " |      as it is consistent, it is seldom used in practice as it rarely leads\n",
      " |      to better accuracy and is more expensive to compute.\n",
      " |      If ``\"crammer_singer\"`` is chosen, the options loss, penalty and dual\n",
      " |      will be ignored.\n",
      " |  \n",
      " |  fit_intercept : boolean, optional (default=True)\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to false, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be already centered).\n",
      " |  \n",
      " |  intercept_scaling : float, optional (default=1)\n",
      " |      When self.fit_intercept is True, instance vector x becomes\n",
      " |      ``[x, self.intercept_scaling]``,\n",
      " |      i.e. a \"synthetic\" feature with constant value equals to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes intercept_scaling * synthetic feature weight\n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to ``class_weight[i]*C`` for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : int, (default=0)\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in liblinear that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`.\n",
      " |  \n",
      " |  max_iter : int, (default=1000)\n",
      " |      The maximum number of iterations to be run.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape = [n_features] if n_classes == 2 else [n_classes, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      ``coef_`` is a readonly property derived from ``raw_coef_`` that\n",
      " |      follows the internal memory layout of liblinear.\n",
      " |  \n",
      " |  intercept_ : array, shape = [1] if n_classes == 2 else [n_classes]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import LinearSVC\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      " |  >>> clf = LinearSVC(random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      " |       intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      " |       multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      " |       verbose=0)\n",
      " |  >>> print(clf.coef_)\n",
      " |  [[ 0.08551385  0.39414796  0.49847831  0.37513797]]\n",
      " |  >>> print(clf.intercept_)\n",
      " |  [ 0.28418066]\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller ``tol`` parameter.\n",
      " |  \n",
      " |  The underlying implementation, liblinear, uses a sparse internal\n",
      " |  representation for the data that will incur a memory copy.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  `LIBLINEAR: A Library for Large Linear Classification\n",
      " |  <http://www.csie.ntu.edu.tw/~cjlin/liblinear/>`__\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVC\n",
      " |      Implementation of Support Vector Machine classifier using libsvm:\n",
      " |      the kernel can be non-linear but its SMO algorithm does not\n",
      " |      scale to large number of samples as LinearSVC does.\n",
      " |  \n",
      " |      Furthermore SVC multi-class mode is implemented using one\n",
      " |      vs one scheme while LinearSVC uses one vs the rest. It is\n",
      " |      possible to implement one vs the rest with SVC by using the\n",
      " |      :class:`sklearn.multiclass.OneVsRestClassifier` wrapper.\n",
      " |  \n",
      " |      Finally SVC can fit dense data without memory copy if the input\n",
      " |      is C-contiguous. Sparse data will still incur memory copy though.\n",
      " |  \n",
      " |  sklearn.linear_model.SGDClassifier\n",
      " |      SGDClassifier can optimize the same cost function as LinearSVC\n",
      " |      by adjusting the penalty and loss parameters. In addition it requires\n",
      " |      less memory, allows incremental (online) learning, and implements\n",
      " |      various loss functions and regularization regimes.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearSVC\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vector, where n_samples in the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target vector relative to X\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Array of weights that are assigned to individual\n",
      " |          samples. If not provided,\n",
      " |          then each sample is given unit weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LinearSVCarSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "skplt.metrics.plot_roc_curve(y_val, grid.predict_proba(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Autoencoder to Enhance Feature Set of Text\n",
    "\n",
    "Titles of news articles worked well -- now let's combine the power of sentence embeddings on short sequences (titles) with the power of autoencoders on the entire cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module keras.layers.embeddings:\n",
      "\n",
      "class Embedding(keras.engine.topology.Layer)\n",
      " |  Turns positive integers (indexes) into dense vectors of fixed size.\n",
      " |  eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
      " |  \n",
      " |  This layer can only be used as the first layer in a model.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |    model = Sequential()\n",
      " |    model.add(Embedding(1000, 64, input_length=10))\n",
      " |    # the model will take as input an integer matrix of size (batch, input_length).\n",
      " |    # the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
      " |    # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
      " |  \n",
      " |    input_array = np.random.randint(1000, size=(32, 10))\n",
      " |  \n",
      " |    model.compile('rmsprop', 'mse')\n",
      " |    output_array = model.predict(input_array)\n",
      " |    assert output_array.shape == (32, 10, 64)\n",
      " |  ```\n",
      " |  \n",
      " |  # Arguments\n",
      " |    input_dim: int > 0. Size of the vocabulary,\n",
      " |        i.e. maximum integer index + 1.\n",
      " |    output_dim: int >= 0. Dimension of the dense embedding.\n",
      " |    embeddings_initializer: Initializer for the `embeddings` matrix\n",
      " |        (see [initializers](../initializers.md)).\n",
      " |    embeddings_regularizer: Regularizer function applied to\n",
      " |        the `embeddings` matrix\n",
      " |        (see [regularizer](../regularizers.md)).\n",
      " |    embeddings_constraint: Constraint function applied to\n",
      " |        the `embeddings` matrix\n",
      " |        (see [constraints](../constraints.md)).\n",
      " |    mask_zero: Whether or not the input value 0 is a special \"padding\"\n",
      " |        value that should be masked out.\n",
      " |        This is useful when using [recurrent layers](recurrent.md)\n",
      " |        which may take variable length input.\n",
      " |        If this is `True` then all subsequent layers\n",
      " |        in the model need to support masking or an exception will be raised.\n",
      " |        If mask_zero is set to True, as a consequence, index 0 cannot be\n",
      " |        used in the vocabulary (input_dim should equal size of\n",
      " |        vocabulary + 1).\n",
      " |    input_length: Length of input sequences, when it is constant.\n",
      " |        This argument is required if you are going to connect\n",
      " |        `Flatten` then `Dense` layers upstream\n",
      " |        (without it, the shape of the dense outputs cannot be computed).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      2D tensor with shape: `(batch_size, sequence_length)`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n",
      " |  \n",
      " |  # References\n",
      " |      - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14559, 512)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- column selector, feature union\n",
    "    - autoencoder of text in article\n",
    "        - Transform text via embeddings\n",
    "    - model on title using sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 40], [36, 29], [36, 16], [23, 29], [38], [5], [26, 16], [10, 36], [26, 29], [30, 7, 40, 4]]\n",
      "[[ 3 40  0  0]\n",
      " [36 29  0  0]\n",
      " [36 16  0  0]\n",
      " [23 29  0  0]\n",
      " [38  0  0  0]\n",
      " [ 5  0  0  0]\n",
      " [26 16  0  0]\n",
      " [10 36  0  0]\n",
      " [26 29  0  0]\n",
      " [30  7 40  4]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 69.999999\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14559, 512, 64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_sequences in module keras.preprocessing.sequence:\n",
      "\n",
      "pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n",
      "    Pads sequences to the same length.\n",
      "    \n",
      "    This function transforms a list of\n",
      "    `num_samples` sequences (lists of integers)\n",
      "    into a 2D Numpy array of shape `(num_samples, num_timesteps)`.\n",
      "    `num_timesteps` is either the `maxlen` argument if provided,\n",
      "    or the length of the longest sequence otherwise.\n",
      "    \n",
      "    Sequences that are shorter than `num_timesteps`\n",
      "    are padded with `value` at the end.\n",
      "    \n",
      "    Sequences longer than `num_timesteps` are truncated\n",
      "    so that they fit the desired length.\n",
      "    The position where padding or truncation happens is determined by\n",
      "    the arguments `padding` and `truncating`, respectively.\n",
      "    \n",
      "    Pre-padding is the default.\n",
      "    \n",
      "    # Arguments\n",
      "        sequences: List of lists, where each element is a sequence.\n",
      "        maxlen: Int, maximum length of all sequences.\n",
      "        dtype: Type of the output sequences.\n",
      "        padding: String, 'pre' or 'post':\n",
      "            pad either before or after each sequence.\n",
      "        truncating: String, 'pre' or 'post':\n",
      "            remove values from sequences larger than\n",
      "            `maxlen`, either at the beginning or at the end of the sequences.\n",
      "        value: Float, padding value.\n",
      "    \n",
      "    # Returns\n",
      "        x: Numpy array with shape `(len(sequences), maxlen)`\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case of invalid values for `truncating` or `padding`,\n",
      "            or in case of invalid shape for a `sequences` entry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "help(pad_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'House\\', \\'Dem\\', \\'Aide:\\', \\'We\\', \\'Didn’t\\', \\'Even\\', \\'See\\', \\'Comey’s\\', \\'Letter\\', \\'Until\\', \\'Jason\\', \\'Chaffetz\\', \\'Tweeted\\', \\'It\\', \\'By\\', \\'Darrell\\', \\'Lucus\\', \\'on\\', \\'October\\', \\'30,\\', \\'2016\\', \\'Subscribe\\', \\'Jason\\', \\'Chaffetz\\', \\'on\\', \\'the\\', \\'stump\\', \\'in\\', \\'American\\', \\'Fork,\\', \\'Utah\\', \\'(\\', \\'image\\', \\'courtesy\\', \\'Michael\\', \\'Jolley,\\', \\'available\\', \\'under\\', \\'a\\', \\'Creative\\', \\'Commons-BY\\', \\'license)\\', \\'With\\', \\'apologies\\', \\'to\\', \\'Keith\\', \\'Olbermann,\\', \\'there\\', \\'is\\', \\'no\\', \\'doubt\\', \\'who\\', \\'the\\', \\'Worst\\', \\'Person\\', \\'in\\', \\'The\\', \\'World\\', \\'is\\', \\'this\\', \\'week–FBI\\', \\'Director\\', \\'James\\', \\'Comey.\\', \\'But\\', \\'according\\', \\'to\\', \\'a\\', \\'House\\', \\'Democratic\\', \\'aide,\\', \\'it\\', \\'looks\\', \\'like\\', \\'we\\', \\'also\\', \\'know\\', \\'who\\', \\'the\\', \\'second-worst\\', \\'person\\', \\'is\\', \\'as\\', \\'well.\\', \\'It\\', \\'turns\\', \\'out\\', \\'that\\', \\'when\\', \\'Comey\\', \\'sent\\', \\'his\\', \\'now-infamous\\', \\'letter\\', \\'announcing\\', \\'that\\', \\'the\\', \\'FBI\\', \\'was\\', \\'looking\\', \\'into\\', \\'emails\\', \\'that\\', \\'may\\', \\'be\\', \\'related\\', \\'to\\', \\'Hillary\\', \\'Clinton’s\\', \\'email\\', \\'server,\\', \\'the\\', \\'ranking\\', \\'Democrats\\', \\'on\\', \\'the\\', \\'relevant\\', \\'committees\\', \\'didn’t\\', \\'hear\\', \\'about\\', \\'it\\', \\'from\\', \\'Comey.\\', \\'They\\', \\'found\\', \\'out\\', \\'via\\', \\'a\\', \\'tweet\\', \\'from\\', \\'one\\', \\'of\\', \\'the\\', \\'Republican\\', \\'committee\\', \\'chairmen.\\', \\'As\\', \\'we\\', \\'now\\', \\'know,\\', \\'Comey\\', \\'notified\\', \\'the\\', \\'Republican\\', \\'chairmen\\', \\'and\\', \\'Democratic\\', \\'ranking\\', \\'members\\', \\'of\\', \\'the\\', \\'House\\', \\'Intelligence,\\', \\'Judiciary,\\', \\'and\\', \\'Oversight\\', \\'committees\\', \\'that\\', \\'his\\', \\'agency\\', \\'was\\', \\'reviewing\\', \\'emails\\', \\'it\\', \\'had\\', \\'recently\\', \\'discovered\\', \\'in\\', \\'order\\', \\'to\\', \\'see\\', \\'if\\', \\'they\\', \\'contained\\', \\'classified\\', \\'information.\\', \\'Not\\', \\'long\\', \\'after\\', \\'this\\', \\'letter\\', \\'went\\', \\'out,\\', \\'Oversight\\', \\'Committee\\', \\'Chairman\\', \\'Jason\\', \\'Chaffetz\\', \\'set\\', \\'the\\', \\'political\\', \\'world\\', \\'ablaze\\', \\'with\\', \\'this\\', \\'tweet.\\', \\'FBI\\', \\'Dir\\', \\'just\\', \\'informed\\', \\'me,\\', \\'\"The\\', \\'FBI\\', \\'has\\', \\'learned\\', \\'of\\', \\'the\\', \\'existence\\', \\'of\\', \\'emails\\', \\'that\\', \\'appear\\', \\'to\\', \\'be\\', \\'pertinent\\', \\'to\\', \\'the\\', \\'investigation.\"\\', \\'Case\\', \\'reopened\\', \\'—\\', \\'Jason\\', \\'Chaffetz\\', \\'(@jasoninthehouse)\\', \\'October\\', \\'28,\\', \\'2016\\', \\'Of\\', \\'course,\\', \\'we\\', \\'now\\', \\'know\\', \\'that\\', \\'this\\', \\'was\\', \\'not\\', \\'the\\', \\'case\\', \\'.\\', \\'Comey\\', \\'was\\', \\'actually\\', \\'saying\\', \\'that\\', \\'it\\', \\'was\\', \\'reviewing\\', \\'the\\', \\'emails\\', \\'in\\', \\'light\\', \\'of\\', \\'“an\\', \\'unrelated\\', \\'case”–which\\', \\'we\\', \\'now\\', \\'know\\', \\'to\\', \\'be\\', \\'Anthony\\', \\'Weiner’s\\', \\'sexting\\', \\'with\\', \\'a\\', \\'teenager.\\', \\'But\\', \\'apparently\\', \\'such\\', \\'little\\', \\'things\\', \\'as\\', \\'facts\\', \\'didn’t\\', \\'matter\\', \\'to\\', \\'Chaffetz.\\', \\'The\\', \\'Utah\\', \\'Republican\\', \\'had\\', \\'already\\', \\'vowed\\', \\'to\\', \\'initiate\\', \\'a\\', \\'raft\\', \\'of\\', \\'investigations\\', \\'if\\', \\'Hillary\\', \\'wins–at\\', \\'least\\', \\'two\\', \\'years’\\', \\'worth,\\', \\'and\\', \\'possibly\\', \\'an\\', \\'entire\\', \\'term’s\\', \\'worth\\', \\'of\\', \\'them.\\', \\'Apparently\\', \\'Chaffetz\\', \\'thought\\', \\'the\\', \\'FBI\\', \\'was\\', \\'already\\', \\'doing\\', \\'his\\', \\'work\\', \\'for\\', \\'him–resulting\\', \\'in\\', \\'a\\', \\'tweet\\', \\'that\\', \\'briefly\\', \\'roiled\\', \\'the\\', \\'nation\\', \\'before\\', \\'cooler\\', \\'heads\\', \\'realized\\', \\'it\\', \\'was\\', \\'a\\', \\'dud.\\', \\'But\\', \\'according\\', \\'to\\', \\'a\\', \\'senior\\', \\'House\\', \\'Democratic\\', \\'aide,\\', \\'misreading\\', \\'that\\', \\'letter\\', \\'may\\', \\'have\\', \\'been\\', \\'the\\', \\'least\\', \\'of\\', \\'Chaffetz’\\', \\'sins.\\', \\'That\\', \\'aide\\', \\'told\\', \\'Shareblue\\', \\'that\\', \\'his\\', \\'boss\\', \\'and\\', \\'other\\', \\'Democrats\\', \\'didn’t\\', \\'even\\', \\'know\\', \\'about\\', \\'Comey’s\\', \\'letter\\', \\'at\\', \\'the\\', \\'time–and\\', \\'only\\', \\'found\\', \\'out\\', \\'when\\', \\'they\\', \\'checked\\', \\'Twitter.\\', \\'“Democratic\\', \\'Ranking\\', \\'Members\\', \\'on\\', \\'the\\', \\'relevant\\', \\'committees\\', \\'didn’t\\', \\'receive\\', \\'Comey’s\\', \\'letter\\', \\'until\\', \\'after\\', \\'the\\', \\'Republican\\', \\'Chairmen.\\', \\'In\\', \\'fact,\\', \\'the\\', \\'Democratic\\', \\'Ranking\\', \\'Members\\', \\'didn’\\', \\'receive\\', \\'it\\', \\'until\\', \\'after\\', \\'the\\', \\'Chairman\\', \\'of\\', \\'the\\', \\'Oversight\\', \\'and\\', \\'Government\\', \\'Reform\\', \\'Committee,\\', \\'Jason\\', \\'Chaffetz,\\', \\'tweeted\\', \\'it\\', \\'out\\', \\'and\\', \\'made\\', \\'it\\', \\'public.”\\', \\'So\\', \\'let’s\\', \\'see\\', \\'if\\', \\'we’ve\\', \\'got\\', \\'this\\', \\'right.\\', \\'The\\', \\'FBI\\', \\'director\\', \\'tells\\', \\'Chaffetz\\', \\'and\\', \\'other\\', \\'GOP\\', \\'committee\\', \\'chairmen\\', \\'about\\', \\'a\\', \\'major\\', \\'development\\', \\'in\\', \\'a\\', \\'potentially\\', \\'politically\\', \\'explosive\\', \\'investigation,\\', \\'and\\', \\'neither\\', \\'Chaffetz\\', \\'nor\\', \\'his\\', \\'other\\', \\'colleagues\\', \\'had\\', \\'the\\', \\'courtesy\\', \\'to\\', \\'let\\', \\'their\\', \\'Democratic\\', \\'counterparts\\', \\'know\\', \\'about\\', \\'it.\\', \\'Instead,\\', \\'according\\', \\'to\\', \\'this\\', \\'aide,\\', \\'he\\', \\'made\\', \\'them\\', \\'find\\', \\'out\\', \\'about\\', \\'it\\', \\'on\\', \\'Twitter.\\', \\'There\\', \\'has\\', \\'already\\', \\'been\\', \\'talk\\', \\'on\\', \\'Daily\\', \\'Kos\\', \\'that\\', \\'Comey\\', \\'himself\\', \\'provided\\', \\'advance\\', \\'notice\\', \\'of\\', \\'this\\', \\'letter\\', \\'to\\', \\'Chaffetz\\', \\'and\\', \\'other\\', \\'Republicans,\\', \\'giving\\', \\'them\\', \\'time\\', \\'to\\', \\'turn\\', \\'on\\', \\'the\\', \\'spin\\', \\'machine.\\', \\'That\\', \\'may\\', \\'make\\', \\'for\\', \\'good\\', \\'theater,\\', \\'but\\', \\'there\\', \\'is\\', \\'nothing\\', \\'so\\', \\'far\\', \\'that\\', \\'even\\', \\'suggests\\', \\'this\\', \\'is\\', \\'the\\', \\'case.\\', \\'After\\', \\'all,\\', \\'there\\', \\'is\\', \\'nothing\\', \\'so\\', \\'far\\', \\'that\\', \\'suggests\\', \\'that\\', \\'Comey\\', \\'was\\', \\'anything\\', \\'other\\', \\'than\\', \\'grossly\\', \\'incompetent\\', \\'and\\', \\'tone-deaf.\\', \\'What\\', \\'it\\', \\'does\\', \\'suggest,\\', \\'however,\\', \\'is\\', \\'that\\', \\'Chaffetz\\', \\'is\\', \\'acting\\', \\'in\\', \\'a\\', \\'way\\', \\'that\\', \\'makes\\', \\'Dan\\', \\'Burton\\', \\'and\\', \\'Darrell\\', \\'Issa\\', \\'look\\', \\'like\\', \\'models\\', \\'of\\', \\'responsibility\\', \\'and\\', \\'bipartisanship.\\', \\'He\\', \\'didn’t\\', \\'even\\', \\'have\\', \\'the\\', \\'decency\\', \\'to\\', \\'notify\\', \\'ranking\\', \\'member\\', \\'Elijah\\', \\'Cummings\\', \\'about\\', \\'something\\', \\'this\\', \\'explosive.\\', \\'If\\', \\'that\\', \\'doesn’t\\', \\'trample\\', \\'on\\', \\'basic\\', \\'standards\\', \\'of\\', \\'fairness,\\', \\'I\\', \\'don’t\\', \\'know\\', \\'what\\', \\'does.\\', \\'Granted,\\', \\'it’s\\', \\'not\\', \\'likely\\', \\'that\\', \\'Chaffetz\\', \\'will\\', \\'have\\', \\'to\\', \\'answer\\', \\'for\\', \\'this.\\', \\'He\\', \\'sits\\', \\'in\\', \\'a\\', \\'ridiculously\\', \\'Republican\\', \\'district\\', \\'anchored\\', \\'in\\', \\'Provo\\', \\'and\\', \\'Orem;\\', \\'it\\', \\'has\\', \\'a\\', \\'Cook\\', \\'Partisan\\', \\'Voting\\', \\'Index\\', \\'of\\', \\'R+25,\\', \\'and\\', \\'gave\\', \\'Mitt\\', \\'Romney\\', \\'a\\', \\'punishing\\', \\'78\\', \\'percent\\', \\'of\\', \\'the\\', \\'vote\\', \\'in\\', \\'2012.\\', \\'Moreover,\\', \\'the\\', \\'Republican\\', \\'House\\', \\'leadership\\', \\'has\\', \\'given\\', \\'its\\', \\'full\\', \\'support\\', \\'to\\', \\'Chaffetz’\\', \\'planned\\', \\'fishing\\', \\'expedition.\\', \\'But\\', \\'that\\', \\'doesn’t\\', \\'mean\\', \\'we\\', \\'can’t\\', \\'turn\\', \\'the\\', \\'hot\\', \\'lights\\', \\'on\\', \\'him.\\', \\'After\\', \\'all,\\', \\'he\\', \\'is\\', \\'a\\', \\'textbook\\', \\'example\\', \\'of\\', \\'what\\', \\'the\\', \\'House\\', \\'has\\', \\'become\\', \\'under\\', \\'Republican\\', \\'control.\\', \\'And\\', \\'he\\', \\'is\\', \\'also\\', \\'the\\', \\'Second\\', \\'Worst\\', \\'Person\\', \\'in\\', \\'the\\', \\'World.\\', \\'About\\', \\'Darrell\\', \\'Lucus\\', \\'Darrell\\', \\'is\\', \\'a\\', \\'30-something\\', \\'graduate\\', \\'of\\', \\'the\\', \\'University\\', \\'of\\', \\'North\\', \\'Carolina\\', \\'who\\', \\'considers\\', \\'himself\\', \\'a\\', \\'journalist\\', \\'of\\', \\'the\\', \\'old\\', \\'school.\\', \\'An\\', \\'attempt\\', \\'to\\', \\'turn\\', \\'him\\', \\'into\\', \\'a\\', \\'member\\', \\'of\\', \\'the\\', \\'religious\\', \\'right\\', \\'in\\', \\'college\\', \\'only\\', \\'succeeded\\', \\'in\\', \\'turning\\', \\'him\\', \\'into\\', \\'the\\', \\'religious\\', \"right\\'s\", \\'worst\\', \\'nightmare--a\\', \\'charismatic\\', \\'Christian\\', \\'who\\', \\'is\\', \\'an\\', \\'unapologetic\\', \\'liberal.\\', \\'His\\', \\'desire\\', \\'to\\', \\'stand\\', \\'up\\', \\'for\\', \\'those\\', \\'who\\', \\'have\\', \\'been\\', \\'scared\\', \\'into\\', \\'silence\\', \\'only\\', \\'increased\\', \\'when\\', \\'he\\', \\'survived\\', \\'an\\', \\'abusive\\', \\'three-year\\', \\'marriage.\\', \\'You\\', \\'may\\', \\'know\\', \\'him\\', \\'on\\', \\'Daily\\', \\'Kos\\', \\'as\\', \\'Christian\\', \\'Dem\\', \\'in\\', \\'NC\\', \\'.\\', \\'Follow\\', \\'him\\', \\'on\\', \\'Twitter\\', \\'@DarrellLucus\\', \\'or\\', \\'connect\\', \\'with\\', \\'him\\', \\'on\\', \\'Facebook\\', \\'.\\', \\'Click\\', \\'here\\', \\'to\\', \\'buy\\', \\'Darrell\\', \\'a\\', \\'Mello\\', \\'Yello.\\', \\'Connect\\']'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = df['text'].str.split().astype(str)\n",
    "txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WASHINGTON', '—', 'Reduced', 'to', 'their', 'wea\n",
      "[256, 35, 3331, 3, 39, 100, 7, 6, 1, 241, 223, 511, 43, 7, 88, 1277, 28, 1808, 3, 3756, 1669, 5, 4008, 6, 58, 137, 992, 12, 2, 2735, 4, 2, 1980, 2450, 1, 30, 517, 241, 183, 8, 2, 27, 245, 46, 2997, 10, 89, 35, 18, 29]\n"
     ]
    }
   ],
   "source": [
    "# resplit data but ignore y\n",
    "X, y = np.array(txt), df.label.values\n",
    "txt_train, txt_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=7)\n",
    "\n",
    "num_words = 5000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(txt)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(txt_train)\n",
    "X_test = tokenizer.texts_to_sequences(txt_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(txt_train[2][:50])\n",
    "print(X_train[2][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 5000\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 2452, 4368, ...,    0,    0,    0],\n",
       "       [   1, 4146,   35, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14559, 5000)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2, 2452, 4368, ...,    0,    0,    0],\n",
       "       [   1, 4146,   35, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14559, 5000)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_252 (Dense)            (None, 5000)              25005000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5000)              20000     \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 2500)              12502500  \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 1000)              2501000   \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 250)               250250    \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 1000)              251000    \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 2500)              2502500   \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 5000)              12505000  \n",
      "=================================================================\n",
      "Total params: 55,537,250\n",
      "Trainable params: 55,527,250\n",
      "Non-trainable params: 10,000\n",
      "_________________________________________________________________\n",
      "Train on 14559 samples, validate on 6241 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "activation = 'relu'\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Embedding(input_dim=vocab_size, \n",
    "#                            output_dim=embedding_dim, \n",
    "#                            input_length=maxlen))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(maxlen, input_dim=maxlen, activation=activation))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2500, activation=activation))\n",
    "model.add(Dense(1000, activation=activation))\n",
    "model.add(Dense(250, activation=activation))\n",
    "model.add(Dense(1000, activation=activation))\n",
    "model.add(Dense(2500, activation=activation))\n",
    "model.add(Dense(maxlen, activation=activation))\n",
    "# model.add(Reshape((5000, 50)))\n",
    "# model.add(Reshape(((5000))))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "early = EarlyStopping(patience=2)\n",
    "\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=100,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early])\n",
    "\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "# plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early = EarlyStopping(patience=2)\n",
    "\n",
    "# txt = Tokenizer(df['text'].values)\n",
    "# #txt = pad_sequences(txt, maxlen=500)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(1000, 64))\n",
    "# model.compile('rmsprop', 'mse')\n",
    "# X_embedded = model.predict(txt)\n",
    "\n",
    "# activation = 'relu'\n",
    "\n",
    "# input_dim = 512\n",
    "# row_dim = 14559\n",
    "\n",
    "# input_i = Input(shape=(input_dim, 64))\n",
    "# encoded_h1 = Dense(256, activation=activation)(input_i)\n",
    "# encoded_h2 = Dense(128, activation=activation)(encoded_h1)\n",
    "# latent = Dense(64, activation='tanh')(encoded_h2)\n",
    "# decoder_h1 = Dense(128, activation=activation)(latent)\n",
    "# decoder_h2 = Dense(256, activation=activation)(decoder_h1)\n",
    "\n",
    "# output = Dense(input_dim, activation='tanh')(decoder_h2)\n",
    "\n",
    "# autoencoder = Model(input_i, output)\n",
    "\n",
    "# autoencoder.compile('adadelta','mse')\n",
    "# autencoder.summary()\n",
    "\n",
    "# #X_embedded = model.predict(np.array(X_train))\n",
    "# autoencoder.fit(X_embedded, X_embedded, epochs=50,\n",
    "#             batch_size=256, validation_split=.1, callbacks=[early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Into Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextCleaner import TextCleaner\n",
    "help(TextCleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalSentenceEmbeddingTransformer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def fetch_universal_sentence_embeddings(self, messages, verbose=0):\n",
    "        \"\"\"Fetches universal sentence embeddings from Google's\n",
    "        research paper https://arxiv.org/pdf/1803.11175.pdf.\n",
    "\n",
    "        INPUTS:\n",
    "        RETURNS:\n",
    "        \"\"\"\n",
    "        module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "\n",
    "        # Import the Universal Sentence Encoder's TF Hub module\n",
    "        embed = hub.Module(module_url)\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            message_embeddings = session.run(embed(messages))\n",
    "            embeddings = list()\n",
    "            for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "                if verbose:\n",
    "                    print(\"Message: {}\".format(messages[i]))\n",
    "                    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "                    message_embedding_snippet = \", \".join(\n",
    "                        (str(x) for x in message_embedding[:3]))\n",
    "                    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "                embeddings.append(message_embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"interface conforming, and allows use of fit_transform\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.fetch_universal_sentence_embeddings(messages=X)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df['title'].astype(str).values, df.label.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=.5, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6e39506a1871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m                                      n_candidates * n_splits))\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Final-Project-Fake-News/TextCleaner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, remove_stopwords, remove_urls, remove_puncts, lemmatize, extra_punct, custom_stopwords, custom_non_stopwords, verbose, parser)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Set up punctation tranlation table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_punct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not NoneType"
     ]
    }
   ],
   "source": [
    "# test LinearSVC model as baseline\n",
    "params = {'clean__lemmatize': [True, False],\n",
    "          'clean__lower': [True, False],\n",
    "          'clean__remove_punct': [True, False],\n",
    "          'clean__extra_punct': [''],\n",
    "          'clf__C':[1, 2, 3], # 1 best here  [.001, .01, .1, 1, 10, 100, 1000]\n",
    "          'clf__random_state': [777]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clean', TextCleaner()),\n",
    "    ('embed', UniversalSentenceEmbeddingTransformer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipeline, params, cv=5, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextCleaner import TextCleaner as tc\n",
    "help(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
